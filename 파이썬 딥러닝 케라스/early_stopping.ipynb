{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 557us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 261us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 268us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 281us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 270us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 268us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 316us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 270us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 261us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 268us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 270us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 234us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 260us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 284us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8197 - val_acc: 0.2200\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8336 - val_acc: 0.2433\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8350 - val_acc: 0.2267\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8396 - val_acc: 0.2367\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6134 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n",
      "Epoch 179/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 234us/step - loss: 1.6134 - acc: 0.3400 - val_loss: 1.8376 - val_acc: 0.2233\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8365 - val_acc: 0.2167\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6115 - acc: 0.3300 - val_loss: 1.8411 - val_acc: 0.2333\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6093 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2267\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8641 - val_acc: 0.2200\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8442 - val_acc: 0.2167\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8401 - val_acc: 0.2300\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.6029 - acc: 0.3357 - val_loss: 1.8539 - val_acc: 0.2267\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8470 - val_acc: 0.2267\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8488 - val_acc: 0.2300\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8591 - val_acc: 0.2200\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8461 - val_acc: 0.2067\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5903 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2233\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5905 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2267\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5881 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8581 - val_acc: 0.2267\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.5855 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8751 - val_acc: 0.2500\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5825 - acc: 0.3486 - val_loss: 1.8611 - val_acc: 0.2133\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5801 - acc: 0.3471 - val_loss: 1.8688 - val_acc: 0.2233\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8605 - val_acc: 0.2200\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.5809 - acc: 0.3514 - val_loss: 1.8730 - val_acc: 0.2133\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5796 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5777 - acc: 0.3571 - val_loss: 1.8693 - val_acc: 0.2100\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5778 - acc: 0.3443 - val_loss: 1.8664 - val_acc: 0.2133\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
      "Epoch 238/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 258us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8719 - val_acc: 0.2500\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8733 - val_acc: 0.2100\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8838 - val_acc: 0.2233\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8840 - val_acc: 0.2233\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5689 - acc: 0.3586 - val_loss: 1.8820 - val_acc: 0.2133\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5677 - acc: 0.3571 - val_loss: 1.8835 - val_acc: 0.2267\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8912 - val_acc: 0.2467\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5637 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8812 - val_acc: 0.2133\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5612 - acc: 0.3629 - val_loss: 1.8918 - val_acc: 0.2300\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8964 - val_acc: 0.2200\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5589 - acc: 0.3629 - val_loss: 1.8914 - val_acc: 0.2200\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8967 - val_acc: 0.2533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8909 - val_acc: 0.2167\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5541 - acc: 0.3586 - val_loss: 1.8906 - val_acc: 0.2333\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.5513 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9011 - val_acc: 0.2300\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9002 - val_acc: 0.2567\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n",
      "Epoch 297/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 236us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5469 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5464 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9066 - val_acc: 0.2200\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5432 - acc: 0.3643 - val_loss: 1.9140 - val_acc: 0.2267\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5458 - acc: 0.3600 - val_loss: 1.9100 - val_acc: 0.2233\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5436 - acc: 0.3671 - val_loss: 1.9064 - val_acc: 0.2267\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9129 - val_acc: 0.2333\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5435 - acc: 0.3643 - val_loss: 1.9120 - val_acc: 0.2367\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5448 - acc: 0.3671 - val_loss: 1.9110 - val_acc: 0.2167\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5426 - acc: 0.3586 - val_loss: 1.9058 - val_acc: 0.2300\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5423 - acc: 0.3729 - val_loss: 1.9273 - val_acc: 0.2367\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5387 - acc: 0.3657 - val_loss: 1.9056 - val_acc: 0.2633\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5433 - acc: 0.3686 - val_loss: 1.9131 - val_acc: 0.2300\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9118 - val_acc: 0.2233\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5404 - acc: 0.3614 - val_loss: 1.9141 - val_acc: 0.2233\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9213 - val_acc: 0.2333\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9096 - val_acc: 0.2300\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5390 - acc: 0.3614 - val_loss: 1.9092 - val_acc: 0.2300\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9278 - val_acc: 0.2233\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9258 - val_acc: 0.2300\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9181 - val_acc: 0.2533\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9197 - val_acc: 0.2300\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5373 - acc: 0.3657 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5387 - acc: 0.3600 - val_loss: 1.9178 - val_acc: 0.2133\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5365 - acc: 0.3614 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5359 - acc: 0.3743 - val_loss: 1.9378 - val_acc: 0.2333\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5366 - acc: 0.3657 - val_loss: 1.9307 - val_acc: 0.2233\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5354 - acc: 0.3714 - val_loss: 1.9147 - val_acc: 0.2300\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5351 - acc: 0.3600 - val_loss: 1.9222 - val_acc: 0.2333\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5338 - acc: 0.3714 - val_loss: 1.9155 - val_acc: 0.2200\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5346 - acc: 0.3571 - val_loss: 1.9340 - val_acc: 0.2500\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5358 - acc: 0.3671 - val_loss: 1.9234 - val_acc: 0.2233\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9289 - val_acc: 0.2233\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5327 - acc: 0.3757 - val_loss: 1.9246 - val_acc: 0.2567\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5335 - acc: 0.3786 - val_loss: 1.9184 - val_acc: 0.2300\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5330 - acc: 0.3757 - val_loss: 1.9324 - val_acc: 0.2300\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9238 - val_acc: 0.2133\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9157 - val_acc: 0.2167\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9403 - val_acc: 0.2267\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5317 - acc: 0.3757 - val_loss: 1.9258 - val_acc: 0.2267\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9441 - val_acc: 0.2167\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5310 - acc: 0.3686 - val_loss: 1.9333 - val_acc: 0.2267\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9431 - val_acc: 0.2300\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9443 - val_acc: 0.2567\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9314 - val_acc: 0.2267\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5277 - acc: 0.3800 - val_loss: 1.9199 - val_acc: 0.2200\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9294 - val_acc: 0.2167\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5281 - acc: 0.3700 - val_loss: 1.9273 - val_acc: 0.2133\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5282 - acc: 0.3657 - val_loss: 1.9311 - val_acc: 0.2300\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5264 - acc: 0.3757 - val_loss: 1.9309 - val_acc: 0.2333\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9282 - val_acc: 0.2300\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2300\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5279 - acc: 0.3700 - val_loss: 1.9350 - val_acc: 0.2167\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9553 - val_acc: 0.2267\n",
      "Epoch 356/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/step - loss: 1.5260 - acc: 0.3700 - val_loss: 1.9442 - val_acc: 0.2433\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5259 - acc: 0.3743 - val_loss: 1.9355 - val_acc: 0.2267\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9494 - val_acc: 0.2233\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9450 - val_acc: 0.2133\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5232 - acc: 0.3743 - val_loss: 1.9454 - val_acc: 0.2233\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5232 - acc: 0.3686 - val_loss: 1.9485 - val_acc: 0.2300\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5240 - acc: 0.3643 - val_loss: 1.9508 - val_acc: 0.2267\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5215 - acc: 0.3757 - val_loss: 1.9527 - val_acc: 0.2333\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9381 - val_acc: 0.2300\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5224 - acc: 0.3771 - val_loss: 1.9524 - val_acc: 0.2267\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5222 - acc: 0.3686 - val_loss: 1.9406 - val_acc: 0.2133\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5221 - acc: 0.3757 - val_loss: 1.9567 - val_acc: 0.2300\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9551 - val_acc: 0.2367\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5207 - acc: 0.3629 - val_loss: 1.9321 - val_acc: 0.2367\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9534 - val_acc: 0.2400\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5209 - acc: 0.3671 - val_loss: 1.9508 - val_acc: 0.2233\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9590 - val_acc: 0.2333\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9453 - val_acc: 0.2133\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5197 - acc: 0.3686 - val_loss: 1.9514 - val_acc: 0.2267\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9386 - val_acc: 0.2267\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5182 - acc: 0.3800 - val_loss: 1.9488 - val_acc: 0.2167\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9760 - val_acc: 0.2267\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5182 - acc: 0.3743 - val_loss: 1.9761 - val_acc: 0.2367\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5188 - acc: 0.3700 - val_loss: 1.9516 - val_acc: 0.2367\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5166 - acc: 0.3671 - val_loss: 1.9602 - val_acc: 0.2567\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.5180 - acc: 0.3786 - val_loss: 1.9711 - val_acc: 0.2167\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5161 - acc: 0.3743 - val_loss: 1.9585 - val_acc: 0.2267\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9714 - val_acc: 0.2433\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9509 - val_acc: 0.2233\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5163 - acc: 0.3743 - val_loss: 1.9579 - val_acc: 0.2267\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5156 - acc: 0.3714 - val_loss: 1.9502 - val_acc: 0.2333\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5153 - acc: 0.3743 - val_loss: 1.9578 - val_acc: 0.2300\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5143 - acc: 0.3714 - val_loss: 1.9668 - val_acc: 0.2467\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5158 - acc: 0.3800 - val_loss: 1.9490 - val_acc: 0.2267\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9572 - val_acc: 0.2400\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.5132 - acc: 0.3757 - val_loss: 1.9539 - val_acc: 0.2367\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9599 - val_acc: 0.2233\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5137 - acc: 0.3757 - val_loss: 1.9730 - val_acc: 0.2233\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9565 - val_acc: 0.2267\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5132 - acc: 0.3771 - val_loss: 1.9565 - val_acc: 0.2167\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5124 - acc: 0.3771 - val_loss: 1.9619 - val_acc: 0.2167\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5111 - acc: 0.3857 - val_loss: 1.9755 - val_acc: 0.2367\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5124 - acc: 0.3643 - val_loss: 1.9588 - val_acc: 0.2200\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5107 - acc: 0.3743 - val_loss: 1.9872 - val_acc: 0.2333\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5113 - acc: 0.3643 - val_loss: 1.9599 - val_acc: 0.2167\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9650 - val_acc: 0.2233\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.5068 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2200\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9678 - val_acc: 0.2333\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5074 - acc: 0.3800 - val_loss: 1.9811 - val_acc: 0.2300\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5085 - acc: 0.3771 - val_loss: 1.9745 - val_acc: 0.2200\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5080 - acc: 0.3714 - val_loss: 1.9792 - val_acc: 0.2267\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9706 - val_acc: 0.2267\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9783 - val_acc: 0.2367\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5058 - acc: 0.3771 - val_loss: 1.9611 - val_acc: 0.2267\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5056 - acc: 0.3714 - val_loss: 1.9817 - val_acc: 0.2300\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5048 - acc: 0.3843 - val_loss: 1.9719 - val_acc: 0.2233\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5033 - acc: 0.3771 - val_loss: 1.9760 - val_acc: 0.2333\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5043 - acc: 0.3786 - val_loss: 1.9842 - val_acc: 0.2333\n",
      "Epoch 415/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/step - loss: 1.5015 - acc: 0.3786 - val_loss: 1.9778 - val_acc: 0.2333\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9889 - val_acc: 0.2267\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9804 - val_acc: 0.2200\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9744 - val_acc: 0.2333\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.5019 - acc: 0.3786 - val_loss: 1.9663 - val_acc: 0.2200\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9877 - val_acc: 0.2300\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5011 - acc: 0.3829 - val_loss: 1.9692 - val_acc: 0.2433\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.5004 - acc: 0.3743 - val_loss: 1.9747 - val_acc: 0.2433\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9792 - val_acc: 0.2333\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.5001 - acc: 0.3757 - val_loss: 1.9678 - val_acc: 0.2200\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9619 - val_acc: 0.2400\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9792 - val_acc: 0.2167\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4983 - acc: 0.3814 - val_loss: 1.9833 - val_acc: 0.2533\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0046 - val_acc: 0.2300\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9696 - val_acc: 0.2300\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4977 - acc: 0.3814 - val_loss: 1.9811 - val_acc: 0.2467\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4990 - acc: 0.3786 - val_loss: 1.9880 - val_acc: 0.2333\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4974 - acc: 0.3843 - val_loss: 1.9760 - val_acc: 0.2233\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4967 - acc: 0.3814 - val_loss: 1.9850 - val_acc: 0.2367\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4976 - acc: 0.3743 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4957 - acc: 0.3900 - val_loss: 1.9819 - val_acc: 0.2267\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9691 - val_acc: 0.2233\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4957 - acc: 0.3943 - val_loss: 1.9951 - val_acc: 0.2200\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4948 - acc: 0.3857 - val_loss: 1.9635 - val_acc: 0.2300\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4946 - acc: 0.3771 - val_loss: 1.9781 - val_acc: 0.2233\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4960 - acc: 0.3800 - val_loss: 1.9796 - val_acc: 0.2300\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4951 - acc: 0.3886 - val_loss: 1.9825 - val_acc: 0.2300\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.4944 - acc: 0.3829 - val_loss: 1.9939 - val_acc: 0.2233\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9899 - val_acc: 0.2400\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4946 - acc: 0.3829 - val_loss: 1.9926 - val_acc: 0.2233\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4942 - acc: 0.3829 - val_loss: 1.9955 - val_acc: 0.2300\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4931 - acc: 0.3886 - val_loss: 2.0029 - val_acc: 0.2267\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4926 - acc: 0.3800 - val_loss: 2.0142 - val_acc: 0.2300\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 1.9924 - val_acc: 0.2267\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0006 - val_acc: 0.2333\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4929 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2233\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4919 - acc: 0.3843 - val_loss: 1.9986 - val_acc: 0.2233\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 1.9947 - val_acc: 0.2300\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4910 - acc: 0.3871 - val_loss: 1.9899 - val_acc: 0.2333\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9967 - val_acc: 0.2333\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9915 - val_acc: 0.2467\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4899 - acc: 0.3871 - val_loss: 1.9972 - val_acc: 0.2333\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4902 - acc: 0.3857 - val_loss: 1.9926 - val_acc: 0.2267\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4881 - acc: 0.3943 - val_loss: 1.9909 - val_acc: 0.2433\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4900 - acc: 0.3886 - val_loss: 2.0007 - val_acc: 0.2300\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4883 - acc: 0.3957 - val_loss: 2.0033 - val_acc: 0.2300\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9937 - val_acc: 0.2267\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4872 - acc: 0.3857 - val_loss: 2.0002 - val_acc: 0.2467\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 1.9888 - val_acc: 0.2333\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9972 - val_acc: 0.2233\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0004 - val_acc: 0.2267\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2300\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4865 - acc: 0.3829 - val_loss: 1.9905 - val_acc: 0.2267\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0313 - val_acc: 0.2333\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 2.0096 - val_acc: 0.2233\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4859 - acc: 0.3957 - val_loss: 2.0055 - val_acc: 0.2267\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4845 - acc: 0.3971 - val_loss: 2.0080 - val_acc: 0.2367\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4850 - acc: 0.3914 - val_loss: 2.0121 - val_acc: 0.2367\n",
      "Epoch 474/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 234us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9976 - val_acc: 0.2267\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0047 - val_acc: 0.2233\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4835 - acc: 0.3900 - val_loss: 2.0056 - val_acc: 0.2267\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4839 - acc: 0.3900 - val_loss: 2.0095 - val_acc: 0.2267\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4838 - acc: 0.3929 - val_loss: 2.0056 - val_acc: 0.2333\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4833 - acc: 0.3900 - val_loss: 2.0015 - val_acc: 0.2300\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4824 - acc: 0.3957 - val_loss: 2.0102 - val_acc: 0.2367\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4821 - acc: 0.3871 - val_loss: 2.0187 - val_acc: 0.2400\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4810 - acc: 0.3986 - val_loss: 2.0164 - val_acc: 0.2300\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4821 - acc: 0.4000 - val_loss: 2.0144 - val_acc: 0.2367\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4815 - acc: 0.3986 - val_loss: 2.0162 - val_acc: 0.2400\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4811 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.4808 - acc: 0.3857 - val_loss: 2.0074 - val_acc: 0.2467\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4811 - acc: 0.3957 - val_loss: 2.0075 - val_acc: 0.2500\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0157 - val_acc: 0.2500\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4804 - acc: 0.3886 - val_loss: 2.0031 - val_acc: 0.2267\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4809 - acc: 0.3900 - val_loss: 2.0000 - val_acc: 0.2333\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4808 - acc: 0.3871 - val_loss: 2.0215 - val_acc: 0.2300\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4800 - acc: 0.3914 - val_loss: 2.0007 - val_acc: 0.2267\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4799 - acc: 0.4014 - val_loss: 2.0076 - val_acc: 0.2333\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4802 - acc: 0.3900 - val_loss: 2.0072 - val_acc: 0.2233\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4792 - acc: 0.4029 - val_loss: 2.0260 - val_acc: 0.2333\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0112 - val_acc: 0.2433\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4773 - acc: 0.3929 - val_loss: 2.0122 - val_acc: 0.2467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0468 - val_acc: 0.2367\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4775 - acc: 0.4014 - val_loss: 2.0281 - val_acc: 0.2367\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4780 - acc: 0.3929 - val_loss: 2.0262 - val_acc: 0.2367\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4782 - acc: 0.4000 - val_loss: 2.0258 - val_acc: 0.2300\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4760 - acc: 0.3943 - val_loss: 2.0261 - val_acc: 0.2267\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4766 - acc: 0.3957 - val_loss: 2.0202 - val_acc: 0.2267\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4757 - acc: 0.3971 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0196 - val_acc: 0.2400\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4754 - acc: 0.3986 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2233\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4750 - acc: 0.3900 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0373 - val_acc: 0.2333\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2233\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4737 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2267\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4739 - acc: 0.3971 - val_loss: 2.0106 - val_acc: 0.2467\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4732 - acc: 0.3986 - val_loss: 2.0137 - val_acc: 0.2433\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4727 - acc: 0.4000 - val_loss: 2.0268 - val_acc: 0.2267\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.4734 - acc: 0.4014 - val_loss: 2.0250 - val_acc: 0.2300\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0273 - val_acc: 0.2267\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4706 - acc: 0.3929 - val_loss: 2.0338 - val_acc: 0.2500\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4740 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2267\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4727 - acc: 0.4043 - val_loss: 2.0238 - val_acc: 0.2300\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0307 - val_acc: 0.2400\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4713 - acc: 0.4129 - val_loss: 2.0126 - val_acc: 0.2333\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4725 - acc: 0.3986 - val_loss: 2.0341 - val_acc: 0.2267\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4721 - acc: 0.3929 - val_loss: 2.0293 - val_acc: 0.2267\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0230 - val_acc: 0.2333\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0285 - val_acc: 0.2467\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4711 - acc: 0.4029 - val_loss: 2.0247 - val_acc: 0.2267\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4702 - acc: 0.3929 - val_loss: 2.0259 - val_acc: 0.2300\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0291 - val_acc: 0.2267\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4681 - acc: 0.3943 - val_loss: 2.0337 - val_acc: 0.2267\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4686 - acc: 0.4000 - val_loss: 2.0412 - val_acc: 0.2267\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4690 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
      "Epoch 533/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 234us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0311 - val_acc: 0.2300\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4688 - acc: 0.3971 - val_loss: 2.0267 - val_acc: 0.2300\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0499 - val_acc: 0.2433\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4671 - acc: 0.4043 - val_loss: 2.0468 - val_acc: 0.2267\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4676 - acc: 0.4029 - val_loss: 2.0293 - val_acc: 0.2300\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4672 - acc: 0.3957 - val_loss: 2.0361 - val_acc: 0.2367\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0313 - val_acc: 0.2267\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4678 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2267\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4667 - acc: 0.4014 - val_loss: 2.0371 - val_acc: 0.2267\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4665 - acc: 0.4057 - val_loss: 2.0430 - val_acc: 0.2433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4670 - acc: 0.4000 - val_loss: 2.0292 - val_acc: 0.2333\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0243 - val_acc: 0.2367\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0327 - val_acc: 0.2300\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4635 - acc: 0.4000 - val_loss: 2.0464 - val_acc: 0.2533\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4657 - acc: 0.4000 - val_loss: 2.0517 - val_acc: 0.2400\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0295 - val_acc: 0.2300\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4647 - acc: 0.4043 - val_loss: 2.0262 - val_acc: 0.2333\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4638 - acc: 0.4000 - val_loss: 2.0388 - val_acc: 0.2300\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4647 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2300\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4632 - acc: 0.4086 - val_loss: 2.0365 - val_acc: 0.2333\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4654 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2300\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4630 - acc: 0.3986 - val_loss: 2.0435 - val_acc: 0.2300\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0446 - val_acc: 0.2400\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4621 - acc: 0.4000 - val_loss: 2.0385 - val_acc: 0.2467\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 278us/step - loss: 1.4614 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2500\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 287us/step - loss: 1.4631 - acc: 0.4029 - val_loss: 2.0380 - val_acc: 0.2333\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4614 - acc: 0.4029 - val_loss: 2.0413 - val_acc: 0.2533\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0446 - val_acc: 0.2567\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0394 - val_acc: 0.2267\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4619 - acc: 0.4029 - val_loss: 2.0325 - val_acc: 0.2300\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4613 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2267\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4611 - acc: 0.4071 - val_loss: 2.0515 - val_acc: 0.2300\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.4603 - acc: 0.4043 - val_loss: 2.0375 - val_acc: 0.2333\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0473 - val_acc: 0.2300\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0504 - val_acc: 0.2300\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4598 - acc: 0.4057 - val_loss: 2.0486 - val_acc: 0.2433\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4594 - acc: 0.4057 - val_loss: 2.0432 - val_acc: 0.2533\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4586 - acc: 0.4114 - val_loss: 2.0507 - val_acc: 0.2333\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0480 - val_acc: 0.2300\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2333\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0551 - val_acc: 0.2533\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0408 - val_acc: 0.2500\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4597 - acc: 0.4114 - val_loss: 2.0449 - val_acc: 0.2267\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4586 - acc: 0.3957 - val_loss: 2.0468 - val_acc: 0.2300\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4583 - acc: 0.4014 - val_loss: 2.0449 - val_acc: 0.2300\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4577 - acc: 0.4071 - val_loss: 2.0453 - val_acc: 0.2367\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4584 - acc: 0.4057 - val_loss: 2.0428 - val_acc: 0.2267\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4574 - acc: 0.4086 - val_loss: 2.0531 - val_acc: 0.2367\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4570 - acc: 0.4071 - val_loss: 2.0488 - val_acc: 0.2567\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0513 - val_acc: 0.2267\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4563 - acc: 0.4014 - val_loss: 2.0529 - val_acc: 0.2267\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2267\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4558 - acc: 0.4100 - val_loss: 2.0556 - val_acc: 0.2300\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4549 - acc: 0.4043 - val_loss: 2.0555 - val_acc: 0.2500\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4560 - acc: 0.4043 - val_loss: 2.0581 - val_acc: 0.2300\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4553 - acc: 0.4057 - val_loss: 2.0576 - val_acc: 0.2267\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4553 - acc: 0.4014 - val_loss: 2.0520 - val_acc: 0.2300\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4554 - acc: 0.4086 - val_loss: 2.0605 - val_acc: 0.2267\n",
      "Epoch 592/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/step - loss: 1.4544 - acc: 0.4086 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4546 - acc: 0.4057 - val_loss: 2.0498 - val_acc: 0.2267\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4540 - acc: 0.4129 - val_loss: 2.0513 - val_acc: 0.2333\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4543 - acc: 0.4057 - val_loss: 2.0569 - val_acc: 0.2433\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0472 - val_acc: 0.2300\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0491 - val_acc: 0.2500\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4537 - acc: 0.3986 - val_loss: 2.0563 - val_acc: 0.2267\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4541 - acc: 0.4043 - val_loss: 2.0478 - val_acc: 0.2333\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0625 - val_acc: 0.2300\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4523 - acc: 0.4129 - val_loss: 2.0623 - val_acc: 0.2433\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4526 - acc: 0.4029 - val_loss: 2.0585 - val_acc: 0.2333\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4527 - acc: 0.4114 - val_loss: 2.0504 - val_acc: 0.2400\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4525 - acc: 0.4029 - val_loss: 2.0489 - val_acc: 0.2433\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4516 - acc: 0.4057 - val_loss: 2.0553 - val_acc: 0.2367\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4517 - acc: 0.4100 - val_loss: 2.0474 - val_acc: 0.2333\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4518 - acc: 0.4100 - val_loss: 2.0580 - val_acc: 0.2300\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2367\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4500 - acc: 0.4157 - val_loss: 2.0635 - val_acc: 0.2567\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4507 - acc: 0.4129 - val_loss: 2.0636 - val_acc: 0.2333\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0608 - val_acc: 0.2367\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0591 - val_acc: 0.2433\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4505 - acc: 0.4086 - val_loss: 2.0601 - val_acc: 0.2300\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0686 - val_acc: 0.2500\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4502 - acc: 0.4129 - val_loss: 2.0535 - val_acc: 0.2533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4495 - acc: 0.4129 - val_loss: 2.0732 - val_acc: 0.2333\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0653 - val_acc: 0.2533\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4491 - acc: 0.4014 - val_loss: 2.0597 - val_acc: 0.2400\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4479 - acc: 0.4114 - val_loss: 2.0671 - val_acc: 0.2333\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4488 - acc: 0.4171 - val_loss: 2.0564 - val_acc: 0.2300\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4487 - acc: 0.4129 - val_loss: 2.0741 - val_acc: 0.2333\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4476 - acc: 0.4114 - val_loss: 2.0741 - val_acc: 0.2367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0690 - val_acc: 0.2267\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4480 - acc: 0.4171 - val_loss: 2.0689 - val_acc: 0.2367\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4479 - acc: 0.4029 - val_loss: 2.0724 - val_acc: 0.2367\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4471 - acc: 0.4086 - val_loss: 2.0535 - val_acc: 0.2367\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4478 - acc: 0.4257 - val_loss: 2.0632 - val_acc: 0.2333\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4459 - acc: 0.4157 - val_loss: 2.0503 - val_acc: 0.2400\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4475 - acc: 0.4100 - val_loss: 2.0615 - val_acc: 0.2333\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4460 - acc: 0.4114 - val_loss: 2.0542 - val_acc: 0.2333\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0818 - val_acc: 0.2400\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0750 - val_acc: 0.2400\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4455 - acc: 0.4143 - val_loss: 2.0829 - val_acc: 0.2367\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4457 - acc: 0.4129 - val_loss: 2.0715 - val_acc: 0.2333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0653 - val_acc: 0.2567\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4463 - acc: 0.4129 - val_loss: 2.0669 - val_acc: 0.2333\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4451 - acc: 0.4114 - val_loss: 2.0764 - val_acc: 0.2367\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4452 - acc: 0.4114 - val_loss: 2.0816 - val_acc: 0.2300\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0820 - val_acc: 0.2233\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4441 - acc: 0.4157 - val_loss: 2.0581 - val_acc: 0.2367\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4437 - acc: 0.4143 - val_loss: 2.0742 - val_acc: 0.2467\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4448 - acc: 0.4100 - val_loss: 2.0819 - val_acc: 0.2433\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0856 - val_acc: 0.2300\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4440 - acc: 0.4129 - val_loss: 2.0722 - val_acc: 0.2367\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0797 - val_acc: 0.2333\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0734 - val_acc: 0.2567\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4423 - acc: 0.4114 - val_loss: 2.0704 - val_acc: 0.2367\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0860 - val_acc: 0.2333\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0823 - val_acc: 0.2333\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4432 - acc: 0.4143 - val_loss: 2.0725 - val_acc: 0.2333\n",
      "Epoch 651/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 247us/step - loss: 1.4418 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4430 - acc: 0.4114 - val_loss: 2.0737 - val_acc: 0.2333\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4415 - acc: 0.4171 - val_loss: 2.0781 - val_acc: 0.2433\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4414 - acc: 0.4143 - val_loss: 2.0641 - val_acc: 0.2467\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4406 - acc: 0.4100 - val_loss: 2.0746 - val_acc: 0.2533\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0850 - val_acc: 0.2433\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4409 - acc: 0.4186 - val_loss: 2.0809 - val_acc: 0.2300\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4409 - acc: 0.4143 - val_loss: 2.0781 - val_acc: 0.2367\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4404 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2467\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4409 - acc: 0.4100 - val_loss: 2.0796 - val_acc: 0.2367\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4418 - acc: 0.4086 - val_loss: 2.0753 - val_acc: 0.2367\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4410 - acc: 0.4000 - val_loss: 2.0794 - val_acc: 0.2367\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4402 - acc: 0.4157 - val_loss: 2.0953 - val_acc: 0.2400\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4394 - acc: 0.4186 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4396 - acc: 0.4114 - val_loss: 2.0887 - val_acc: 0.2333\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4390 - acc: 0.4200 - val_loss: 2.0808 - val_acc: 0.2533\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0751 - val_acc: 0.2367\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4375 - acc: 0.4157 - val_loss: 2.0902 - val_acc: 0.2567\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4382 - acc: 0.4157 - val_loss: 2.0931 - val_acc: 0.2333\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4393 - acc: 0.4171 - val_loss: 2.0815 - val_acc: 0.2333\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0801 - val_acc: 0.2533\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4382 - acc: 0.4100 - val_loss: 2.0893 - val_acc: 0.2367\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4384 - acc: 0.4186 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4374 - acc: 0.4086 - val_loss: 2.1027 - val_acc: 0.2433\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4366 - acc: 0.4214 - val_loss: 2.1019 - val_acc: 0.2533\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2567\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0972 - val_acc: 0.2300\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4355 - acc: 0.4200 - val_loss: 2.0724 - val_acc: 0.2333\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4369 - acc: 0.4257 - val_loss: 2.0890 - val_acc: 0.2367\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0805 - val_acc: 0.2400\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.4360 - acc: 0.4214 - val_loss: 2.0854 - val_acc: 0.2567\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0779 - val_acc: 0.2500\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0887 - val_acc: 0.2600\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4356 - acc: 0.4143 - val_loss: 2.0846 - val_acc: 0.2567\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4352 - acc: 0.4200 - val_loss: 2.1067 - val_acc: 0.2533\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.0772 - val_acc: 0.2367\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4355 - acc: 0.4157 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0925 - val_acc: 0.2367\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4345 - acc: 0.4143 - val_loss: 2.0995 - val_acc: 0.2333\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4337 - acc: 0.4229 - val_loss: 2.0944 - val_acc: 0.2333\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4339 - acc: 0.4186 - val_loss: 2.0823 - val_acc: 0.2400\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4345 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4335 - acc: 0.4186 - val_loss: 2.1067 - val_acc: 0.2467\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4348 - acc: 0.4171 - val_loss: 2.0871 - val_acc: 0.2567\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0991 - val_acc: 0.2333\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4337 - acc: 0.4186 - val_loss: 2.1061 - val_acc: 0.2467\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4333 - acc: 0.4257 - val_loss: 2.0948 - val_acc: 0.2433\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4328 - acc: 0.4214 - val_loss: 2.0957 - val_acc: 0.2400\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4329 - acc: 0.4200 - val_loss: 2.0952 - val_acc: 0.2467\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4316 - acc: 0.4171 - val_loss: 2.0921 - val_acc: 0.2433\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0981 - val_acc: 0.2367\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.1061 - val_acc: 0.2333\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4325 - acc: 0.4214 - val_loss: 2.0935 - val_acc: 0.2433\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4320 - acc: 0.4157 - val_loss: 2.0879 - val_acc: 0.2400\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4321 - acc: 0.4214 - val_loss: 2.0806 - val_acc: 0.2400\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.0931 - val_acc: 0.2367\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4316 - acc: 0.4214 - val_loss: 2.0923 - val_acc: 0.2333\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4296 - acc: 0.4186 - val_loss: 2.1160 - val_acc: 0.2533\n",
      "Epoch 710/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/step - loss: 1.4314 - acc: 0.4229 - val_loss: 2.0957 - val_acc: 0.2467\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4304 - acc: 0.4186 - val_loss: 2.0964 - val_acc: 0.2367\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4300 - acc: 0.4214 - val_loss: 2.1035 - val_acc: 0.2567\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4310 - acc: 0.4186 - val_loss: 2.0861 - val_acc: 0.2400\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4305 - acc: 0.4243 - val_loss: 2.0996 - val_acc: 0.2367\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4282 - acc: 0.4243 - val_loss: 2.0936 - val_acc: 0.2600\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4305 - acc: 0.4157 - val_loss: 2.1060 - val_acc: 0.2367\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1014 - val_acc: 0.2367\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4289 - acc: 0.4186 - val_loss: 2.1246 - val_acc: 0.2533\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4303 - acc: 0.4186 - val_loss: 2.1100 - val_acc: 0.2400\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4295 - acc: 0.4214 - val_loss: 2.1052 - val_acc: 0.2367\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4291 - acc: 0.4200 - val_loss: 2.1038 - val_acc: 0.2433\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4286 - acc: 0.4200 - val_loss: 2.1045 - val_acc: 0.2367\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4282 - acc: 0.4214 - val_loss: 2.0911 - val_acc: 0.2400\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4281 - acc: 0.4257 - val_loss: 2.1101 - val_acc: 0.2367\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4277 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2433\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4278 - acc: 0.4257 - val_loss: 2.0962 - val_acc: 0.2367\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4273 - acc: 0.4214 - val_loss: 2.1264 - val_acc: 0.2333\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.4276 - acc: 0.4200 - val_loss: 2.0961 - val_acc: 0.2400\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4269 - acc: 0.4229 - val_loss: 2.1197 - val_acc: 0.2467\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4269 - acc: 0.4257 - val_loss: 2.1247 - val_acc: 0.2400\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4277 - acc: 0.4143 - val_loss: 2.1096 - val_acc: 0.2367\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.4261 - acc: 0.4243 - val_loss: 2.1076 - val_acc: 0.2400\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4263 - acc: 0.4286 - val_loss: 2.1008 - val_acc: 0.2400\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4271 - acc: 0.4214 - val_loss: 2.1178 - val_acc: 0.2400\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4261 - acc: 0.4286 - val_loss: 2.1092 - val_acc: 0.2367\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4249 - acc: 0.4300 - val_loss: 2.1022 - val_acc: 0.2400\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4265 - acc: 0.4229 - val_loss: 2.1194 - val_acc: 0.2433\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4265 - acc: 0.4200 - val_loss: 2.1078 - val_acc: 0.2467\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4251 - acc: 0.4271 - val_loss: 2.1167 - val_acc: 0.2367\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4250 - acc: 0.4314 - val_loss: 2.1048 - val_acc: 0.2400\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1189 - val_acc: 0.2567\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4252 - acc: 0.4143 - val_loss: 2.1010 - val_acc: 0.2533\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1042 - val_acc: 0.2533\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4257 - acc: 0.4186 - val_loss: 2.1045 - val_acc: 0.2433\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4221 - acc: 0.4329 - val_loss: 2.1158 - val_acc: 0.2533\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1062 - val_acc: 0.2400\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4251 - acc: 0.4157 - val_loss: 2.1123 - val_acc: 0.2433\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 281us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1289 - val_acc: 0.2600\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.0960 - val_acc: 0.2333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4239 - acc: 0.4329 - val_loss: 2.1004 - val_acc: 0.2300\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4224 - acc: 0.4171 - val_loss: 2.1130 - val_acc: 0.2400\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4233 - acc: 0.4243 - val_loss: 2.1173 - val_acc: 0.2367\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4223 - acc: 0.4257 - val_loss: 2.1337 - val_acc: 0.2333\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4235 - acc: 0.4271 - val_loss: 2.1186 - val_acc: 0.2333\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.4221 - acc: 0.4386 - val_loss: 2.1169 - val_acc: 0.2467\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1151 - val_acc: 0.2400\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4233 - acc: 0.4200 - val_loss: 2.1210 - val_acc: 0.2433\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4220 - acc: 0.4300 - val_loss: 2.1190 - val_acc: 0.2433\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4221 - acc: 0.4271 - val_loss: 2.1112 - val_acc: 0.2400\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4218 - acc: 0.4329 - val_loss: 2.1117 - val_acc: 0.2400\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4215 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2500\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4225 - acc: 0.4257 - val_loss: 2.1261 - val_acc: 0.2400\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4215 - acc: 0.4200 - val_loss: 2.1152 - val_acc: 0.2400\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4227 - acc: 0.4300 - val_loss: 2.1314 - val_acc: 0.2433\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4203 - acc: 0.4214 - val_loss: 2.1405 - val_acc: 0.2333\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4217 - acc: 0.4214 - val_loss: 2.1154 - val_acc: 0.2400\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1160 - val_acc: 0.2367\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4205 - acc: 0.4257 - val_loss: 2.1068 - val_acc: 0.2400\n",
      "Epoch 769/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 238us/step - loss: 1.4207 - acc: 0.4243 - val_loss: 2.1165 - val_acc: 0.2367\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4200 - acc: 0.4214 - val_loss: 2.1088 - val_acc: 0.2333\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1229 - val_acc: 0.2367\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4202 - acc: 0.4229 - val_loss: 2.1255 - val_acc: 0.2433\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4200 - acc: 0.4229 - val_loss: 2.1326 - val_acc: 0.2500\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1295 - val_acc: 0.2400\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4182 - acc: 0.4286 - val_loss: 2.1295 - val_acc: 0.2533\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4193 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4177 - acc: 0.4314 - val_loss: 2.1345 - val_acc: 0.2333\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4190 - acc: 0.4214 - val_loss: 2.1203 - val_acc: 0.2333\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4191 - acc: 0.4300 - val_loss: 2.1231 - val_acc: 0.2333\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4190 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2400\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1239 - val_acc: 0.2467\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4184 - acc: 0.4257 - val_loss: 2.1057 - val_acc: 0.2400\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4186 - acc: 0.4329 - val_loss: 2.1295 - val_acc: 0.2433\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4181 - acc: 0.4300 - val_loss: 2.1362 - val_acc: 0.2400\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1419 - val_acc: 0.2367\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4180 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4184 - acc: 0.4243 - val_loss: 2.1135 - val_acc: 0.2500\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1248 - val_acc: 0.2400\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1256 - val_acc: 0.2400\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4174 - acc: 0.4314 - val_loss: 2.1284 - val_acc: 0.2400\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4164 - acc: 0.4286 - val_loss: 2.1302 - val_acc: 0.2500\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4171 - acc: 0.4229 - val_loss: 2.1204 - val_acc: 0.2367\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4166 - acc: 0.4257 - val_loss: 2.1365 - val_acc: 0.2500\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4169 - acc: 0.4271 - val_loss: 2.1308 - val_acc: 0.2367\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4164 - acc: 0.4314 - val_loss: 2.1278 - val_acc: 0.2400\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4160 - acc: 0.4300 - val_loss: 2.1290 - val_acc: 0.2367\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1355 - val_acc: 0.2367\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4162 - acc: 0.4386 - val_loss: 2.1362 - val_acc: 0.2400\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.4152 - acc: 0.4329 - val_loss: 2.1291 - val_acc: 0.2567\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4159 - acc: 0.4200 - val_loss: 2.1378 - val_acc: 0.2333\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4159 - acc: 0.4329 - val_loss: 2.1350 - val_acc: 0.2333\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1718 - val_acc: 0.2400\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4146 - acc: 0.4271 - val_loss: 2.1338 - val_acc: 0.2600\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4148 - acc: 0.4243 - val_loss: 2.1272 - val_acc: 0.2433\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1285 - val_acc: 0.2467\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4148 - acc: 0.4357 - val_loss: 2.1285 - val_acc: 0.2400\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4148 - acc: 0.4386 - val_loss: 2.1343 - val_acc: 0.2500\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4143 - acc: 0.4314 - val_loss: 2.1340 - val_acc: 0.2400\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2467\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4139 - acc: 0.4357 - val_loss: 2.1360 - val_acc: 0.2367\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1368 - val_acc: 0.2400\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4141 - acc: 0.4271 - val_loss: 2.1261 - val_acc: 0.2400\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1430 - val_acc: 0.2400\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.4131 - acc: 0.4286 - val_loss: 2.1356 - val_acc: 0.2533\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4139 - acc: 0.4314 - val_loss: 2.1410 - val_acc: 0.2467\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4136 - acc: 0.4300 - val_loss: 2.1348 - val_acc: 0.2367\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4116 - acc: 0.4300 - val_loss: 2.1359 - val_acc: 0.2367\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1431 - val_acc: 0.2367\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4110 - acc: 0.4357 - val_loss: 2.1535 - val_acc: 0.2600\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4131 - acc: 0.4329 - val_loss: 2.1379 - val_acc: 0.2567\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1497 - val_acc: 0.2467\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1381 - val_acc: 0.2367\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4114 - acc: 0.4271 - val_loss: 2.1430 - val_acc: 0.2433\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4110 - acc: 0.4300 - val_loss: 2.1438 - val_acc: 0.2433\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4112 - acc: 0.4314 - val_loss: 2.1583 - val_acc: 0.2467\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4122 - acc: 0.4271 - val_loss: 2.1483 - val_acc: 0.2467\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4112 - acc: 0.4300 - val_loss: 2.1481 - val_acc: 0.2400\n",
      "Epoch 828/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/step - loss: 1.4118 - acc: 0.4343 - val_loss: 2.1369 - val_acc: 0.2367\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4111 - acc: 0.4314 - val_loss: 2.1411 - val_acc: 0.2433\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4104 - acc: 0.4271 - val_loss: 2.1457 - val_acc: 0.2400\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.4105 - acc: 0.4443 - val_loss: 2.1591 - val_acc: 0.2467\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4111 - acc: 0.4343 - val_loss: 2.1598 - val_acc: 0.2500\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4110 - acc: 0.4243 - val_loss: 2.1645 - val_acc: 0.2467\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4106 - acc: 0.4329 - val_loss: 2.1743 - val_acc: 0.2433\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4095 - acc: 0.4300 - val_loss: 2.1435 - val_acc: 0.2367\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1518 - val_acc: 0.2500\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1380 - val_acc: 0.2433\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1500 - val_acc: 0.2367\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4088 - acc: 0.4300 - val_loss: 2.1492 - val_acc: 0.2367\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4081 - acc: 0.4343 - val_loss: 2.1386 - val_acc: 0.2433\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4092 - acc: 0.4371 - val_loss: 2.1470 - val_acc: 0.2367\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1594 - val_acc: 0.2500\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4090 - acc: 0.4314 - val_loss: 2.1468 - val_acc: 0.2367\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4082 - acc: 0.4300 - val_loss: 2.1617 - val_acc: 0.2367\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4088 - acc: 0.4314 - val_loss: 2.1402 - val_acc: 0.2367\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4092 - acc: 0.4357 - val_loss: 2.1484 - val_acc: 0.2400\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4075 - acc: 0.4229 - val_loss: 2.1584 - val_acc: 0.2433\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4079 - acc: 0.4371 - val_loss: 2.1529 - val_acc: 0.2533\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4086 - acc: 0.4300 - val_loss: 2.1555 - val_acc: 0.2433\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4071 - acc: 0.4314 - val_loss: 2.1484 - val_acc: 0.2367\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4071 - acc: 0.4229 - val_loss: 2.1482 - val_acc: 0.2333\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4086 - acc: 0.4371 - val_loss: 2.1509 - val_acc: 0.2433\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4066 - acc: 0.4329 - val_loss: 2.1501 - val_acc: 0.2367\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4046 - acc: 0.4371 - val_loss: 2.1745 - val_acc: 0.2600\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4074 - acc: 0.4271 - val_loss: 2.1510 - val_acc: 0.2333\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4074 - acc: 0.4357 - val_loss: 2.1598 - val_acc: 0.2500\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.4067 - acc: 0.4286 - val_loss: 2.1580 - val_acc: 0.2467\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4066 - acc: 0.4343 - val_loss: 2.1567 - val_acc: 0.2367\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1554 - val_acc: 0.2367\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.4057 - acc: 0.4357 - val_loss: 2.1783 - val_acc: 0.2533\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4064 - acc: 0.4343 - val_loss: 2.1655 - val_acc: 0.2433\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4071 - acc: 0.4271 - val_loss: 2.1672 - val_acc: 0.2533\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4055 - acc: 0.4329 - val_loss: 2.1677 - val_acc: 0.2500\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.4053 - acc: 0.4329 - val_loss: 2.1628 - val_acc: 0.2533\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4047 - acc: 0.4386 - val_loss: 2.1682 - val_acc: 0.2633\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4049 - acc: 0.4314 - val_loss: 2.1387 - val_acc: 0.2433\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1681 - val_acc: 0.2433\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4054 - acc: 0.4357 - val_loss: 2.1608 - val_acc: 0.2467\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4050 - acc: 0.4386 - val_loss: 2.1594 - val_acc: 0.2400\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.4034 - acc: 0.4357 - val_loss: 2.1720 - val_acc: 0.2467\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4048 - acc: 0.4314 - val_loss: 2.1759 - val_acc: 0.2467\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4037 - acc: 0.4357 - val_loss: 2.1607 - val_acc: 0.2567\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1424 - val_acc: 0.2367\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4048 - acc: 0.4329 - val_loss: 2.1525 - val_acc: 0.2367\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4038 - acc: 0.4329 - val_loss: 2.1739 - val_acc: 0.2467\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4035 - acc: 0.4314 - val_loss: 2.1520 - val_acc: 0.2433\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4037 - acc: 0.4271 - val_loss: 2.1733 - val_acc: 0.2367\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2400\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4012 - acc: 0.4371 - val_loss: 2.1696 - val_acc: 0.2400\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4051 - acc: 0.4329 - val_loss: 2.1589 - val_acc: 0.2400\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4035 - acc: 0.4429 - val_loss: 2.1855 - val_acc: 0.2500\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4035 - acc: 0.4371 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4044 - acc: 0.4286 - val_loss: 2.1476 - val_acc: 0.2400\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4027 - acc: 0.4314 - val_loss: 2.1799 - val_acc: 0.2533\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4031 - acc: 0.4314 - val_loss: 2.1444 - val_acc: 0.2433\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4036 - acc: 0.4386 - val_loss: 2.1664 - val_acc: 0.2467\n",
      "Epoch 887/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 234us/step - loss: 1.4026 - acc: 0.4371 - val_loss: 2.1546 - val_acc: 0.2367\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4027 - acc: 0.4357 - val_loss: 2.1653 - val_acc: 0.2400\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4010 - acc: 0.4443 - val_loss: 2.1763 - val_acc: 0.2600\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4028 - acc: 0.4386 - val_loss: 2.1675 - val_acc: 0.2567\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4024 - acc: 0.4271 - val_loss: 2.1707 - val_acc: 0.2433\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4024 - acc: 0.4357 - val_loss: 2.1736 - val_acc: 0.2433\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4018 - acc: 0.4357 - val_loss: 2.1794 - val_acc: 0.2433\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.4020 - acc: 0.4429 - val_loss: 2.1670 - val_acc: 0.2400\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.4012 - acc: 0.4343 - val_loss: 2.1696 - val_acc: 0.2467\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.4014 - acc: 0.4357 - val_loss: 2.1745 - val_acc: 0.2600\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4017 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2533\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.4011 - acc: 0.4386 - val_loss: 2.1869 - val_acc: 0.2467\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.4015 - acc: 0.4343 - val_loss: 2.1634 - val_acc: 0.2467\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.4001 - acc: 0.4471 - val_loss: 2.1660 - val_acc: 0.2467\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3999 - acc: 0.4400 - val_loss: 2.1780 - val_acc: 0.2533\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.4001 - acc: 0.4343 - val_loss: 2.1718 - val_acc: 0.2467\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3992 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2633\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3991 - acc: 0.4357 - val_loss: 2.1637 - val_acc: 0.2400\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.4010 - acc: 0.4400 - val_loss: 2.1595 - val_acc: 0.2400\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3998 - acc: 0.4371 - val_loss: 2.1560 - val_acc: 0.2367\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 281us/step - loss: 1.4003 - acc: 0.4386 - val_loss: 2.1815 - val_acc: 0.2467\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1730 - val_acc: 0.2433\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 260us/step - loss: 1.3993 - acc: 0.4329 - val_loss: 2.1789 - val_acc: 0.2500\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.4004 - acc: 0.4357 - val_loss: 2.1613 - val_acc: 0.2400\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3991 - acc: 0.4371 - val_loss: 2.1790 - val_acc: 0.2367\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3995 - acc: 0.4400 - val_loss: 2.1687 - val_acc: 0.2367\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 278us/step - loss: 1.4000 - acc: 0.4371 - val_loss: 2.1881 - val_acc: 0.2433\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1862 - val_acc: 0.2567\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3990 - acc: 0.4343 - val_loss: 2.1746 - val_acc: 0.2467\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3987 - acc: 0.4386 - val_loss: 2.1795 - val_acc: 0.2400\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3978 - acc: 0.4400 - val_loss: 2.1797 - val_acc: 0.2400\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3970 - acc: 0.4386 - val_loss: 2.1789 - val_acc: 0.2533\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3984 - acc: 0.4329 - val_loss: 2.1871 - val_acc: 0.2433\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3988 - acc: 0.4343 - val_loss: 2.1695 - val_acc: 0.2500\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3984 - acc: 0.4357 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3967 - acc: 0.4400 - val_loss: 2.1838 - val_acc: 0.2500\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.3966 - acc: 0.4386 - val_loss: 2.1709 - val_acc: 0.2567\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3988 - acc: 0.4414 - val_loss: 2.1766 - val_acc: 0.2467\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3970 - acc: 0.4343 - val_loss: 2.1822 - val_acc: 0.2367\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.3972 - acc: 0.4443 - val_loss: 2.1771 - val_acc: 0.2467\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.3975 - acc: 0.4357 - val_loss: 2.1778 - val_acc: 0.2400\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3971 - acc: 0.4400 - val_loss: 2.1921 - val_acc: 0.2433\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3971 - acc: 0.4414 - val_loss: 2.1917 - val_acc: 0.2400\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3971 - acc: 0.4357 - val_loss: 2.1789 - val_acc: 0.2467\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3967 - acc: 0.4329 - val_loss: 2.1803 - val_acc: 0.2467\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1716 - val_acc: 0.2500\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3966 - acc: 0.4314 - val_loss: 2.1818 - val_acc: 0.2467\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3958 - acc: 0.4414 - val_loss: 2.1874 - val_acc: 0.2500\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3966 - acc: 0.4414 - val_loss: 2.1846 - val_acc: 0.2500\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3965 - acc: 0.4429 - val_loss: 2.1883 - val_acc: 0.2500\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3960 - acc: 0.4400 - val_loss: 2.1831 - val_acc: 0.2367\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3953 - acc: 0.4443 - val_loss: 2.1899 - val_acc: 0.2500\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.3953 - acc: 0.4386 - val_loss: 2.1980 - val_acc: 0.2500\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.1790 - val_acc: 0.2400\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3957 - acc: 0.4343 - val_loss: 2.1841 - val_acc: 0.2400\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.3947 - acc: 0.4357 - val_loss: 2.1692 - val_acc: 0.2333\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3955 - acc: 0.4414 - val_loss: 2.1922 - val_acc: 0.2433\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3944 - acc: 0.4371 - val_loss: 2.1942 - val_acc: 0.2433\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1898 - val_acc: 0.2500\n",
      "Epoch 946/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 231us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1833 - val_acc: 0.2467\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3939 - acc: 0.4414 - val_loss: 2.1935 - val_acc: 0.2533\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 1.3940 - acc: 0.4300 - val_loss: 2.1744 - val_acc: 0.2367\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3938 - acc: 0.4471 - val_loss: 2.1834 - val_acc: 0.2400\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.3929 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2367\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3940 - acc: 0.4429 - val_loss: 2.1889 - val_acc: 0.2500\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3938 - acc: 0.4414 - val_loss: 2.1852 - val_acc: 0.2467\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3935 - acc: 0.4371 - val_loss: 2.1988 - val_acc: 0.2533\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3940 - acc: 0.4471 - val_loss: 2.1858 - val_acc: 0.2567\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3936 - acc: 0.4429 - val_loss: 2.1951 - val_acc: 0.2500\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3928 - acc: 0.4386 - val_loss: 2.2024 - val_acc: 0.2433\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2433\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3938 - acc: 0.4343 - val_loss: 2.2130 - val_acc: 0.2467\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3936 - acc: 0.4414 - val_loss: 2.1808 - val_acc: 0.2467\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.1918 - val_acc: 0.2467\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1688 - val_acc: 0.2467\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3931 - acc: 0.4400 - val_loss: 2.1895 - val_acc: 0.2467\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3926 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2500\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3919 - acc: 0.4357 - val_loss: 2.1782 - val_acc: 0.2433\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.1849 - val_acc: 0.2533\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.1969 - val_acc: 0.2567\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1947 - val_acc: 0.2467\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1865 - val_acc: 0.2433\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3917 - acc: 0.4414 - val_loss: 2.1907 - val_acc: 0.2433\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3916 - acc: 0.4400 - val_loss: 2.2006 - val_acc: 0.2400\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1862 - val_acc: 0.2467\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.2011 - val_acc: 0.2333\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3901 - acc: 0.4400 - val_loss: 2.1959 - val_acc: 0.2500\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3908 - acc: 0.4386 - val_loss: 2.1971 - val_acc: 0.2500\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3907 - acc: 0.4443 - val_loss: 2.2058 - val_acc: 0.2500\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.1920 - val_acc: 0.2500\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3905 - acc: 0.4343 - val_loss: 2.1915 - val_acc: 0.2400\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3904 - acc: 0.4486 - val_loss: 2.1936 - val_acc: 0.2533\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.1917 - val_acc: 0.2467\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3894 - acc: 0.4371 - val_loss: 2.2124 - val_acc: 0.2500\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3902 - acc: 0.4400 - val_loss: 2.1965 - val_acc: 0.2533\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3897 - acc: 0.4357 - val_loss: 2.2004 - val_acc: 0.2500\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1945 - val_acc: 0.2500\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3891 - acc: 0.4400 - val_loss: 2.2033 - val_acc: 0.2367\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3891 - acc: 0.4414 - val_loss: 2.2010 - val_acc: 0.2500\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3887 - acc: 0.4414 - val_loss: 2.1880 - val_acc: 0.2400\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3886 - acc: 0.4429 - val_loss: 2.2116 - val_acc: 0.2633\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3903 - acc: 0.4357 - val_loss: 2.2104 - val_acc: 0.2533\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3887 - acc: 0.4443 - val_loss: 2.2221 - val_acc: 0.2533\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3890 - acc: 0.4471 - val_loss: 2.1938 - val_acc: 0.2433\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2048 - val_acc: 0.2400\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3885 - acc: 0.4457 - val_loss: 2.2089 - val_acc: 0.2533\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3885 - acc: 0.4357 - val_loss: 2.1919 - val_acc: 0.2367\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3890 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3877 - acc: 0.4457 - val_loss: 2.2035 - val_acc: 0.2467\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3879 - acc: 0.4429 - val_loss: 2.2026 - val_acc: 0.2533\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3887 - acc: 0.4386 - val_loss: 2.2113 - val_acc: 0.2533\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3881 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2500\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3879 - acc: 0.4386 - val_loss: 2.2080 - val_acc: 0.2500\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3864 - acc: 0.4457 - val_loss: 2.2066 - val_acc: 0.2600\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3883 - acc: 0.4371 - val_loss: 2.2040 - val_acc: 0.2500\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3865 - acc: 0.4457 - val_loss: 2.2098 - val_acc: 0.2567\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3885 - acc: 0.4414 - val_loss: 2.2183 - val_acc: 0.2500\n",
      "Epoch 1005/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.3874 - acc: 0.4386 - val_loss: 2.2037 - val_acc: 0.2467\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3869 - acc: 0.4371 - val_loss: 2.2217 - val_acc: 0.2500\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3865 - acc: 0.4414 - val_loss: 2.2156 - val_acc: 0.2567\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3868 - acc: 0.4386 - val_loss: 2.1980 - val_acc: 0.2500\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3864 - acc: 0.4457 - val_loss: 2.2222 - val_acc: 0.2533\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3865 - acc: 0.4486 - val_loss: 2.2001 - val_acc: 0.2500\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3859 - acc: 0.4414 - val_loss: 2.2110 - val_acc: 0.2533\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3852 - acc: 0.4414 - val_loss: 2.2121 - val_acc: 0.2533\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3852 - acc: 0.4457 - val_loss: 2.1997 - val_acc: 0.2400\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3853 - acc: 0.4414 - val_loss: 2.1992 - val_acc: 0.2567\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.3842 - acc: 0.4457 - val_loss: 2.2054 - val_acc: 0.2400\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3867 - acc: 0.4414 - val_loss: 2.2084 - val_acc: 0.2500\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3863 - acc: 0.4357 - val_loss: 2.2066 - val_acc: 0.2500\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3861 - acc: 0.4486 - val_loss: 2.2147 - val_acc: 0.2500\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3851 - acc: 0.4386 - val_loss: 2.2054 - val_acc: 0.2467\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3845 - acc: 0.4529 - val_loss: 2.2020 - val_acc: 0.2500\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3853 - acc: 0.4429 - val_loss: 2.2082 - val_acc: 0.2533\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3842 - acc: 0.4514 - val_loss: 2.2098 - val_acc: 0.2400\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3855 - acc: 0.4414 - val_loss: 2.2026 - val_acc: 0.2467\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3850 - acc: 0.4529 - val_loss: 2.2013 - val_acc: 0.2433\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3844 - acc: 0.4443 - val_loss: 2.2053 - val_acc: 0.2533\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3848 - acc: 0.4457 - val_loss: 2.1894 - val_acc: 0.2433\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3841 - acc: 0.4457 - val_loss: 2.2116 - val_acc: 0.2500\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3842 - acc: 0.4386 - val_loss: 2.2037 - val_acc: 0.2433\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3844 - acc: 0.4443 - val_loss: 2.2034 - val_acc: 0.2467\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3835 - acc: 0.4500 - val_loss: 2.2144 - val_acc: 0.2500\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3834 - acc: 0.4443 - val_loss: 2.2164 - val_acc: 0.2567\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3846 - acc: 0.4443 - val_loss: 2.2146 - val_acc: 0.2433\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3843 - acc: 0.4429 - val_loss: 2.2287 - val_acc: 0.2467\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3822 - acc: 0.4443 - val_loss: 2.2093 - val_acc: 0.2333\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3842 - acc: 0.4443 - val_loss: 2.2127 - val_acc: 0.2533\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3837 - acc: 0.4486 - val_loss: 2.2104 - val_acc: 0.2500\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3830 - acc: 0.4429 - val_loss: 2.2100 - val_acc: 0.2400\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3838 - acc: 0.4443 - val_loss: 2.2310 - val_acc: 0.2567\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3835 - acc: 0.4443 - val_loss: 2.2170 - val_acc: 0.2467\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3832 - acc: 0.4414 - val_loss: 2.2157 - val_acc: 0.2467\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3825 - acc: 0.4414 - val_loss: 2.2257 - val_acc: 0.2500\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3814 - acc: 0.4400 - val_loss: 2.2029 - val_acc: 0.2467\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3835 - acc: 0.4400 - val_loss: 2.2207 - val_acc: 0.2533\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3825 - acc: 0.4429 - val_loss: 2.2144 - val_acc: 0.2467\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3802 - acc: 0.4386 - val_loss: 2.2106 - val_acc: 0.2333\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3831 - acc: 0.4514 - val_loss: 2.2169 - val_acc: 0.2433\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3808 - acc: 0.4457 - val_loss: 2.2106 - val_acc: 0.2367\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3824 - acc: 0.4400 - val_loss: 2.2060 - val_acc: 0.2433\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3818 - acc: 0.4414 - val_loss: 2.2126 - val_acc: 0.2500\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3808 - acc: 0.4471 - val_loss: 2.2207 - val_acc: 0.2433\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3821 - acc: 0.4471 - val_loss: 2.2123 - val_acc: 0.2467\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3810 - acc: 0.4357 - val_loss: 2.2241 - val_acc: 0.2433\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3814 - acc: 0.4443 - val_loss: 2.2187 - val_acc: 0.2467\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3808 - acc: 0.4486 - val_loss: 2.2117 - val_acc: 0.2500\n",
      "Epoch 1055/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3807 - acc: 0.4471 - val_loss: 2.2092 - val_acc: 0.2500\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3805 - acc: 0.4400 - val_loss: 2.2246 - val_acc: 0.2500\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3799 - acc: 0.4343 - val_loss: 2.2335 - val_acc: 0.2433\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3813 - acc: 0.4414 - val_loss: 2.2224 - val_acc: 0.2533\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3797 - acc: 0.4486 - val_loss: 2.2256 - val_acc: 0.2500\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3802 - acc: 0.4443 - val_loss: 2.2176 - val_acc: 0.2500\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3807 - acc: 0.4457 - val_loss: 2.2299 - val_acc: 0.2533\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3811 - acc: 0.4386 - val_loss: 2.2117 - val_acc: 0.2500\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3797 - acc: 0.4429 - val_loss: 2.2154 - val_acc: 0.2533\n",
      "Epoch 1064/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 231us/step - loss: 1.3799 - acc: 0.4429 - val_loss: 2.2242 - val_acc: 0.2500\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3800 - acc: 0.4400 - val_loss: 2.2143 - val_acc: 0.2467\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3800 - acc: 0.4429 - val_loss: 2.2151 - val_acc: 0.2400\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3799 - acc: 0.4514 - val_loss: 2.2341 - val_acc: 0.2567\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3793 - acc: 0.4443 - val_loss: 2.2361 - val_acc: 0.2500\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3795 - acc: 0.4414 - val_loss: 2.2306 - val_acc: 0.2500\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3789 - acc: 0.4471 - val_loss: 2.2188 - val_acc: 0.2367\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3783 - acc: 0.4457 - val_loss: 2.2395 - val_acc: 0.2267\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3789 - acc: 0.4514 - val_loss: 2.2240 - val_acc: 0.2533\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3784 - acc: 0.4443 - val_loss: 2.2148 - val_acc: 0.2500\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3788 - acc: 0.4514 - val_loss: 2.2086 - val_acc: 0.2500\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3787 - acc: 0.4500 - val_loss: 2.2178 - val_acc: 0.2367\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3789 - acc: 0.4429 - val_loss: 2.2176 - val_acc: 0.2500\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3785 - acc: 0.4457 - val_loss: 2.2122 - val_acc: 0.2367\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3785 - acc: 0.4443 - val_loss: 2.2300 - val_acc: 0.2400\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3779 - acc: 0.4443 - val_loss: 2.2217 - val_acc: 0.2400\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3780 - acc: 0.4414 - val_loss: 2.2196 - val_acc: 0.2533\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3782 - acc: 0.4471 - val_loss: 2.2224 - val_acc: 0.2400\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3770 - acc: 0.4471 - val_loss: 2.2332 - val_acc: 0.2533\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3782 - acc: 0.4429 - val_loss: 2.2194 - val_acc: 0.2333\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3784 - acc: 0.4471 - val_loss: 2.2361 - val_acc: 0.2433\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3771 - acc: 0.4414 - val_loss: 2.2262 - val_acc: 0.2533\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3776 - acc: 0.4471 - val_loss: 2.2408 - val_acc: 0.2400\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3771 - acc: 0.4486 - val_loss: 2.2275 - val_acc: 0.2333\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3769 - acc: 0.4543 - val_loss: 2.2215 - val_acc: 0.2500\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3781 - acc: 0.4457 - val_loss: 2.2246 - val_acc: 0.2500\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3766 - acc: 0.4471 - val_loss: 2.2321 - val_acc: 0.2533\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3766 - acc: 0.4486 - val_loss: 2.2212 - val_acc: 0.2400\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3765 - acc: 0.4514 - val_loss: 2.2326 - val_acc: 0.2500\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3769 - acc: 0.4457 - val_loss: 2.2310 - val_acc: 0.2467\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 288us/step - loss: 1.3753 - acc: 0.4571 - val_loss: 2.2186 - val_acc: 0.2433\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3779 - acc: 0.4429 - val_loss: 2.2295 - val_acc: 0.2533\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3761 - acc: 0.4429 - val_loss: 2.2273 - val_acc: 0.2367\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3762 - acc: 0.4557 - val_loss: 2.2363 - val_acc: 0.2533\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3767 - acc: 0.4457 - val_loss: 2.2485 - val_acc: 0.2500\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3767 - acc: 0.4471 - val_loss: 2.2508 - val_acc: 0.2467\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3761 - acc: 0.4500 - val_loss: 2.2319 - val_acc: 0.2467\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3756 - acc: 0.4471 - val_loss: 2.2334 - val_acc: 0.2500\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3750 - acc: 0.4400 - val_loss: 2.2350 - val_acc: 0.2367\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3754 - acc: 0.4414 - val_loss: 2.2393 - val_acc: 0.2533\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3758 - acc: 0.4414 - val_loss: 2.2227 - val_acc: 0.2533\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3752 - acc: 0.4500 - val_loss: 2.2251 - val_acc: 0.2533\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3748 - acc: 0.4500 - val_loss: 2.2386 - val_acc: 0.2533\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3758 - acc: 0.4471 - val_loss: 2.2124 - val_acc: 0.2500\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3755 - acc: 0.4471 - val_loss: 2.2374 - val_acc: 0.2467\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3755 - acc: 0.4500 - val_loss: 2.2455 - val_acc: 0.2500\n",
      "Epoch 1110/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3746 - acc: 0.4414 - val_loss: 2.2213 - val_acc: 0.2433\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3742 - acc: 0.4543 - val_loss: 2.2375 - val_acc: 0.2500\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3742 - acc: 0.4457 - val_loss: 2.2381 - val_acc: 0.2400\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3738 - acc: 0.4486 - val_loss: 2.2401 - val_acc: 0.2533\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3746 - acc: 0.4486 - val_loss: 2.2344 - val_acc: 0.2533\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3756 - acc: 0.4457 - val_loss: 2.2276 - val_acc: 0.2533\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3737 - acc: 0.4500 - val_loss: 2.2386 - val_acc: 0.2500\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3737 - acc: 0.4529 - val_loss: 2.2345 - val_acc: 0.2467\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3739 - acc: 0.4557 - val_loss: 2.2353 - val_acc: 0.2467\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3732 - acc: 0.4386 - val_loss: 2.2312 - val_acc: 0.2333\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3733 - acc: 0.4543 - val_loss: 2.2521 - val_acc: 0.2500\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3744 - acc: 0.4471 - val_loss: 2.2236 - val_acc: 0.2433\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3736 - acc: 0.4486 - val_loss: 2.2395 - val_acc: 0.2533\n",
      "Epoch 1123/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 231us/step - loss: 1.3730 - acc: 0.4514 - val_loss: 2.2359 - val_acc: 0.2467\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3739 - acc: 0.4500 - val_loss: 2.2343 - val_acc: 0.2400\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3735 - acc: 0.4471 - val_loss: 2.2286 - val_acc: 0.2533\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3722 - acc: 0.4529 - val_loss: 2.2357 - val_acc: 0.2533\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3730 - acc: 0.4586 - val_loss: 2.2398 - val_acc: 0.2533\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3737 - acc: 0.4457 - val_loss: 2.2597 - val_acc: 0.2500\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3720 - acc: 0.4457 - val_loss: 2.2440 - val_acc: 0.2333\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3727 - acc: 0.4429 - val_loss: 2.2399 - val_acc: 0.2433\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3709 - acc: 0.4457 - val_loss: 2.2517 - val_acc: 0.2533\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3738 - acc: 0.4514 - val_loss: 2.2409 - val_acc: 0.2467\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3715 - acc: 0.4514 - val_loss: 2.2492 - val_acc: 0.2467\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3717 - acc: 0.4457 - val_loss: 2.2419 - val_acc: 0.2333\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3726 - acc: 0.4514 - val_loss: 2.2394 - val_acc: 0.2467\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3718 - acc: 0.4514 - val_loss: 2.2319 - val_acc: 0.2467\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3726 - acc: 0.4500 - val_loss: 2.2376 - val_acc: 0.2467\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3716 - acc: 0.4471 - val_loss: 2.2385 - val_acc: 0.2433\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3717 - acc: 0.4557 - val_loss: 2.2339 - val_acc: 0.2467\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3701 - acc: 0.4557 - val_loss: 2.2266 - val_acc: 0.2300\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3715 - acc: 0.4500 - val_loss: 2.2566 - val_acc: 0.2500\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3718 - acc: 0.4557 - val_loss: 2.2502 - val_acc: 0.2500\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3707 - acc: 0.4457 - val_loss: 2.2485 - val_acc: 0.2433\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3686 - acc: 0.4443 - val_loss: 2.2591 - val_acc: 0.2367\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3718 - acc: 0.4529 - val_loss: 2.2451 - val_acc: 0.2467\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3705 - acc: 0.4514 - val_loss: 2.2479 - val_acc: 0.2333\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3702 - acc: 0.4529 - val_loss: 2.2359 - val_acc: 0.2333\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3715 - acc: 0.4543 - val_loss: 2.2493 - val_acc: 0.2467\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3712 - acc: 0.4457 - val_loss: 2.2479 - val_acc: 0.2367\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3713 - acc: 0.4486 - val_loss: 2.2256 - val_acc: 0.2400\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3712 - acc: 0.4514 - val_loss: 2.2325 - val_acc: 0.2433\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3697 - acc: 0.4529 - val_loss: 2.2417 - val_acc: 0.2533\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3711 - acc: 0.4471 - val_loss: 2.2495 - val_acc: 0.2467\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 266us/step - loss: 1.3699 - acc: 0.4543 - val_loss: 2.2222 - val_acc: 0.2367\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3697 - acc: 0.4514 - val_loss: 2.2439 - val_acc: 0.2433\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.3706 - acc: 0.4457 - val_loss: 2.2368 - val_acc: 0.2300\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3707 - acc: 0.4529 - val_loss: 2.2441 - val_acc: 0.2433\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3696 - acc: 0.4543 - val_loss: 2.2632 - val_acc: 0.2533\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3697 - acc: 0.4457 - val_loss: 2.2454 - val_acc: 0.2433\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3708 - acc: 0.4543 - val_loss: 2.2533 - val_acc: 0.2333\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3693 - acc: 0.4571 - val_loss: 2.2498 - val_acc: 0.2467\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 266us/step - loss: 1.3693 - acc: 0.4571 - val_loss: 2.2518 - val_acc: 0.2467\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 268us/step - loss: 1.3691 - acc: 0.4543 - val_loss: 2.2544 - val_acc: 0.2467\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3688 - acc: 0.4586 - val_loss: 2.2563 - val_acc: 0.2333\n",
      "Epoch 1165/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3701 - acc: 0.4571 - val_loss: 2.2257 - val_acc: 0.2367\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.3689 - acc: 0.4543 - val_loss: 2.2372 - val_acc: 0.2433\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3689 - acc: 0.4557 - val_loss: 2.2476 - val_acc: 0.2433\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3688 - acc: 0.4529 - val_loss: 2.2407 - val_acc: 0.2333\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 266us/step - loss: 1.3682 - acc: 0.4529 - val_loss: 2.2482 - val_acc: 0.2467\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 267us/step - loss: 1.3682 - acc: 0.4514 - val_loss: 2.2456 - val_acc: 0.2467\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3676 - acc: 0.4514 - val_loss: 2.2372 - val_acc: 0.2433\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3681 - acc: 0.4529 - val_loss: 2.2565 - val_acc: 0.2433\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3678 - acc: 0.4514 - val_loss: 2.2473 - val_acc: 0.2300\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 273us/step - loss: 1.3688 - acc: 0.4471 - val_loss: 2.2392 - val_acc: 0.2433\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 283us/step - loss: 1.3671 - acc: 0.4514 - val_loss: 2.2474 - val_acc: 0.2433\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3680 - acc: 0.4500 - val_loss: 2.2530 - val_acc: 0.2433\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 260us/step - loss: 1.3681 - acc: 0.4514 - val_loss: 2.2585 - val_acc: 0.2467\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3675 - acc: 0.4500 - val_loss: 2.2525 - val_acc: 0.2267\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3677 - acc: 0.4543 - val_loss: 2.2529 - val_acc: 0.2300\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3678 - acc: 0.4514 - val_loss: 2.2552 - val_acc: 0.2400\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.3672 - acc: 0.4571 - val_loss: 2.2626 - val_acc: 0.2500\n",
      "Epoch 1182/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 248us/step - loss: 1.3679 - acc: 0.4557 - val_loss: 2.2485 - val_acc: 0.2400\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3673 - acc: 0.4500 - val_loss: 2.2498 - val_acc: 0.2433\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3663 - acc: 0.4586 - val_loss: 2.2440 - val_acc: 0.2467\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.3675 - acc: 0.4557 - val_loss: 2.2456 - val_acc: 0.2400\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3671 - acc: 0.4471 - val_loss: 2.2624 - val_acc: 0.2467\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.3664 - acc: 0.4529 - val_loss: 2.2483 - val_acc: 0.2333\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.3665 - acc: 0.4543 - val_loss: 2.2648 - val_acc: 0.2467\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 273us/step - loss: 1.3656 - acc: 0.4600 - val_loss: 2.2545 - val_acc: 0.2467\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 268us/step - loss: 1.3665 - acc: 0.4500 - val_loss: 2.2675 - val_acc: 0.2500\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3668 - acc: 0.4486 - val_loss: 2.2574 - val_acc: 0.2333\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3664 - acc: 0.4600 - val_loss: 2.2426 - val_acc: 0.2433\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3669 - acc: 0.4557 - val_loss: 2.2553 - val_acc: 0.2400\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3660 - acc: 0.4500 - val_loss: 2.2483 - val_acc: 0.2300\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3666 - acc: 0.4543 - val_loss: 2.2449 - val_acc: 0.2267\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.3657 - acc: 0.4614 - val_loss: 2.2578 - val_acc: 0.2500\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.3658 - acc: 0.4557 - val_loss: 2.2434 - val_acc: 0.2433\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.3653 - acc: 0.4529 - val_loss: 2.2526 - val_acc: 0.2467\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 267us/step - loss: 1.3656 - acc: 0.4543 - val_loss: 2.2451 - val_acc: 0.2300\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.3662 - acc: 0.4500 - val_loss: 2.2559 - val_acc: 0.2400\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3651 - acc: 0.4600 - val_loss: 2.2589 - val_acc: 0.2433\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 267us/step - loss: 1.3660 - acc: 0.4529 - val_loss: 2.2649 - val_acc: 0.2467\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.3653 - acc: 0.4571 - val_loss: 2.2406 - val_acc: 0.2467\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3654 - acc: 0.4643 - val_loss: 2.2421 - val_acc: 0.2467\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 260us/step - loss: 1.3639 - acc: 0.4571 - val_loss: 2.2494 - val_acc: 0.2433\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3649 - acc: 0.4600 - val_loss: 2.2587 - val_acc: 0.2433\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 274us/step - loss: 1.3637 - acc: 0.4571 - val_loss: 2.2627 - val_acc: 0.2233\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3636 - acc: 0.4514 - val_loss: 2.2575 - val_acc: 0.2267\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3630 - acc: 0.4600 - val_loss: 2.2535 - val_acc: 0.2433\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3648 - acc: 0.4557 - val_loss: 2.2554 - val_acc: 0.2433\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3645 - acc: 0.4586 - val_loss: 2.2601 - val_acc: 0.2433\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3631 - acc: 0.4471 - val_loss: 2.2723 - val_acc: 0.2500\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3655 - acc: 0.4557 - val_loss: 2.2534 - val_acc: 0.2433\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3634 - acc: 0.4557 - val_loss: 2.2671 - val_acc: 0.2467\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3633 - acc: 0.4529 - val_loss: 2.2601 - val_acc: 0.2467\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3637 - acc: 0.4571 - val_loss: 2.2528 - val_acc: 0.2433\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3636 - acc: 0.4514 - val_loss: 2.2627 - val_acc: 0.2433\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3634 - acc: 0.4586 - val_loss: 2.2598 - val_acc: 0.2433\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3632 - acc: 0.4529 - val_loss: 2.2627 - val_acc: 0.2467\n",
      "Epoch 1220/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3642 - acc: 0.4529 - val_loss: 2.2458 - val_acc: 0.2433\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3633 - acc: 0.4614 - val_loss: 2.2634 - val_acc: 0.2300\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3633 - acc: 0.4586 - val_loss: 2.2696 - val_acc: 0.2433\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.3632 - acc: 0.4586 - val_loss: 2.2670 - val_acc: 0.2467\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3625 - acc: 0.4571 - val_loss: 2.2684 - val_acc: 0.2467\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3621 - acc: 0.4529 - val_loss: 2.2637 - val_acc: 0.2300\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3636 - acc: 0.4629 - val_loss: 2.2576 - val_acc: 0.2433\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3609 - acc: 0.4543 - val_loss: 2.2530 - val_acc: 0.2433\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3626 - acc: 0.4614 - val_loss: 2.2698 - val_acc: 0.2433\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3630 - acc: 0.4543 - val_loss: 2.2602 - val_acc: 0.2433\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3624 - acc: 0.4600 - val_loss: 2.2539 - val_acc: 0.2467\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3629 - acc: 0.4571 - val_loss: 2.2445 - val_acc: 0.2333\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3626 - acc: 0.4543 - val_loss: 2.2725 - val_acc: 0.2500\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3632 - acc: 0.4586 - val_loss: 2.2520 - val_acc: 0.2400\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3616 - acc: 0.4686 - val_loss: 2.2474 - val_acc: 0.2467\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3618 - acc: 0.4571 - val_loss: 2.2517 - val_acc: 0.2400\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3620 - acc: 0.4543 - val_loss: 2.2513 - val_acc: 0.2367\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3622 - acc: 0.4486 - val_loss: 2.2387 - val_acc: 0.2500\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3610 - acc: 0.4586 - val_loss: 2.2676 - val_acc: 0.2467\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3620 - acc: 0.4514 - val_loss: 2.2522 - val_acc: 0.2400\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3614 - acc: 0.4557 - val_loss: 2.2538 - val_acc: 0.2433\n",
      "Epoch 1241/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 236us/step - loss: 1.3614 - acc: 0.4557 - val_loss: 2.2632 - val_acc: 0.2400\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3609 - acc: 0.4514 - val_loss: 2.2598 - val_acc: 0.2433\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3612 - acc: 0.4614 - val_loss: 2.2727 - val_acc: 0.2467\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3611 - acc: 0.4529 - val_loss: 2.2490 - val_acc: 0.2467\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3607 - acc: 0.4614 - val_loss: 2.2530 - val_acc: 0.2433\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3603 - acc: 0.4600 - val_loss: 2.2741 - val_acc: 0.2433\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3601 - acc: 0.4614 - val_loss: 2.2670 - val_acc: 0.2433\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3607 - acc: 0.4557 - val_loss: 2.2692 - val_acc: 0.2400\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3611 - acc: 0.4557 - val_loss: 2.2617 - val_acc: 0.2400\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3596 - acc: 0.4571 - val_loss: 2.2906 - val_acc: 0.2300\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3608 - acc: 0.4586 - val_loss: 2.2676 - val_acc: 0.2400\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3597 - acc: 0.4643 - val_loss: 2.2755 - val_acc: 0.2433\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3609 - acc: 0.4500 - val_loss: 2.2626 - val_acc: 0.2400\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3600 - acc: 0.4614 - val_loss: 2.2568 - val_acc: 0.2433\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3602 - acc: 0.4571 - val_loss: 2.2595 - val_acc: 0.2433\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3592 - acc: 0.4586 - val_loss: 2.2743 - val_acc: 0.2333\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3599 - acc: 0.4586 - val_loss: 2.2791 - val_acc: 0.2467\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3600 - acc: 0.4686 - val_loss: 2.2549 - val_acc: 0.2433\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3597 - acc: 0.4600 - val_loss: 2.2523 - val_acc: 0.2433\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3592 - acc: 0.4600 - val_loss: 2.2723 - val_acc: 0.2467\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3599 - acc: 0.4586 - val_loss: 2.2643 - val_acc: 0.2400\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3597 - acc: 0.4571 - val_loss: 2.2677 - val_acc: 0.2400\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3590 - acc: 0.4700 - val_loss: 2.2659 - val_acc: 0.2400\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3593 - acc: 0.4586 - val_loss: 2.2587 - val_acc: 0.2333\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3593 - acc: 0.4614 - val_loss: 2.2626 - val_acc: 0.2367\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3591 - acc: 0.4571 - val_loss: 2.2522 - val_acc: 0.2467\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3586 - acc: 0.4571 - val_loss: 2.2577 - val_acc: 0.2400\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3596 - acc: 0.4629 - val_loss: 2.2683 - val_acc: 0.2433\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3588 - acc: 0.4643 - val_loss: 2.2802 - val_acc: 0.2500\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3584 - acc: 0.4614 - val_loss: 2.2724 - val_acc: 0.2433\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3589 - acc: 0.4557 - val_loss: 2.2625 - val_acc: 0.2400\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3581 - acc: 0.4629 - val_loss: 2.2678 - val_acc: 0.2433\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3584 - acc: 0.4571 - val_loss: 2.2686 - val_acc: 0.2433\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3586 - acc: 0.4614 - val_loss: 2.2654 - val_acc: 0.2433\n",
      "Epoch 1275/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3575 - acc: 0.4629 - val_loss: 2.2716 - val_acc: 0.2433\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3587 - acc: 0.4600 - val_loss: 2.2702 - val_acc: 0.2433\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3580 - acc: 0.4600 - val_loss: 2.2711 - val_acc: 0.2467\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3575 - acc: 0.4614 - val_loss: 2.2789 - val_acc: 0.2467\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3575 - acc: 0.4557 - val_loss: 2.2655 - val_acc: 0.2400\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3577 - acc: 0.4614 - val_loss: 2.2771 - val_acc: 0.2433\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3572 - acc: 0.4514 - val_loss: 2.2671 - val_acc: 0.2433\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 293us/step - loss: 1.3576 - acc: 0.4586 - val_loss: 2.2739 - val_acc: 0.2433\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3573 - acc: 0.4671 - val_loss: 2.2915 - val_acc: 0.2467\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3573 - acc: 0.4629 - val_loss: 2.2878 - val_acc: 0.2533\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3548 - acc: 0.4571 - val_loss: 2.2599 - val_acc: 0.2333\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3547 - acc: 0.4643 - val_loss: 2.2806 - val_acc: 0.2500\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3574 - acc: 0.4629 - val_loss: 2.2905 - val_acc: 0.2500\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3565 - acc: 0.4571 - val_loss: 2.2762 - val_acc: 0.2467\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3569 - acc: 0.4671 - val_loss: 2.2716 - val_acc: 0.2467\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3569 - acc: 0.4629 - val_loss: 2.2690 - val_acc: 0.2400\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3571 - acc: 0.4629 - val_loss: 2.2831 - val_acc: 0.2400\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.3563 - acc: 0.4600 - val_loss: 2.2876 - val_acc: 0.2533\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3565 - acc: 0.4614 - val_loss: 2.2762 - val_acc: 0.2400\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3566 - acc: 0.4643 - val_loss: 2.2786 - val_acc: 0.2367\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3556 - acc: 0.4671 - val_loss: 2.2734 - val_acc: 0.2433\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3567 - acc: 0.4671 - val_loss: 2.2744 - val_acc: 0.2400\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3561 - acc: 0.4700 - val_loss: 2.2689 - val_acc: 0.2433\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3563 - acc: 0.4643 - val_loss: 2.2695 - val_acc: 0.2400\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3549 - acc: 0.4657 - val_loss: 2.2853 - val_acc: 0.2400\n",
      "Epoch 1300/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 233us/step - loss: 1.3547 - acc: 0.4671 - val_loss: 2.2662 - val_acc: 0.2333\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3544 - acc: 0.4529 - val_loss: 2.2618 - val_acc: 0.2400\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3560 - acc: 0.4614 - val_loss: 2.2773 - val_acc: 0.2467\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3560 - acc: 0.4643 - val_loss: 2.2769 - val_acc: 0.2400\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3556 - acc: 0.4729 - val_loss: 2.2815 - val_acc: 0.2433\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3548 - acc: 0.4643 - val_loss: 2.2853 - val_acc: 0.2500\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3550 - acc: 0.4586 - val_loss: 2.2744 - val_acc: 0.2467\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3555 - acc: 0.4643 - val_loss: 2.2712 - val_acc: 0.2433\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3541 - acc: 0.4600 - val_loss: 2.2640 - val_acc: 0.2400\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3540 - acc: 0.4643 - val_loss: 2.2767 - val_acc: 0.2300\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3551 - acc: 0.4643 - val_loss: 2.2795 - val_acc: 0.2467\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3555 - acc: 0.4671 - val_loss: 2.2771 - val_acc: 0.2433\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3545 - acc: 0.4614 - val_loss: 2.2740 - val_acc: 0.2467\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3544 - acc: 0.4614 - val_loss: 2.2669 - val_acc: 0.2400\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3540 - acc: 0.4571 - val_loss: 2.2843 - val_acc: 0.2367\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3536 - acc: 0.4657 - val_loss: 2.2688 - val_acc: 0.2467\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3545 - acc: 0.4643 - val_loss: 2.2898 - val_acc: 0.2500\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3538 - acc: 0.4586 - val_loss: 2.2735 - val_acc: 0.2300\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3545 - acc: 0.4657 - val_loss: 2.2649 - val_acc: 0.2433\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3545 - acc: 0.4700 - val_loss: 2.2828 - val_acc: 0.2533\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3541 - acc: 0.4600 - val_loss: 2.2716 - val_acc: 0.2433\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3534 - acc: 0.4657 - val_loss: 2.2724 - val_acc: 0.2500\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3536 - acc: 0.4629 - val_loss: 2.2706 - val_acc: 0.2400\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3532 - acc: 0.4643 - val_loss: 2.3067 - val_acc: 0.2467\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3539 - acc: 0.4629 - val_loss: 2.2775 - val_acc: 0.2400\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3525 - acc: 0.4629 - val_loss: 2.2922 - val_acc: 0.2367\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3539 - acc: 0.4657 - val_loss: 2.2774 - val_acc: 0.2400\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3532 - acc: 0.4671 - val_loss: 2.2731 - val_acc: 0.2400\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3529 - acc: 0.4643 - val_loss: 2.3012 - val_acc: 0.2500\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3532 - acc: 0.4657 - val_loss: 2.2783 - val_acc: 0.2500\n",
      "Epoch 1330/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3533 - acc: 0.4600 - val_loss: 2.2962 - val_acc: 0.2400\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3532 - acc: 0.4643 - val_loss: 2.2916 - val_acc: 0.2533\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3528 - acc: 0.4671 - val_loss: 2.2892 - val_acc: 0.2433\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3525 - acc: 0.4643 - val_loss: 2.2739 - val_acc: 0.2400\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3520 - acc: 0.4657 - val_loss: 2.3003 - val_acc: 0.2500\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3530 - acc: 0.4586 - val_loss: 2.2702 - val_acc: 0.2400\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3532 - acc: 0.4714 - val_loss: 2.2900 - val_acc: 0.2433\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3524 - acc: 0.4629 - val_loss: 2.2780 - val_acc: 0.2433\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3520 - acc: 0.4586 - val_loss: 2.2842 - val_acc: 0.2400\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3520 - acc: 0.4671 - val_loss: 2.3073 - val_acc: 0.2467\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3526 - acc: 0.4643 - val_loss: 2.2821 - val_acc: 0.2467\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3521 - acc: 0.4714 - val_loss: 2.2882 - val_acc: 0.2467\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3523 - acc: 0.4700 - val_loss: 2.2818 - val_acc: 0.2433\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3514 - acc: 0.4629 - val_loss: 2.2842 - val_acc: 0.2467\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3517 - acc: 0.4629 - val_loss: 2.2902 - val_acc: 0.2500\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3512 - acc: 0.4714 - val_loss: 2.3031 - val_acc: 0.2500\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3513 - acc: 0.4600 - val_loss: 2.2687 - val_acc: 0.2400\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3523 - acc: 0.4700 - val_loss: 2.2824 - val_acc: 0.2467\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3506 - acc: 0.4643 - val_loss: 2.2828 - val_acc: 0.2433\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3508 - acc: 0.4643 - val_loss: 2.2906 - val_acc: 0.2467\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3514 - acc: 0.4657 - val_loss: 2.2906 - val_acc: 0.2433\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3512 - acc: 0.4686 - val_loss: 2.2934 - val_acc: 0.2500\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3513 - acc: 0.4714 - val_loss: 2.2751 - val_acc: 0.2400\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3507 - acc: 0.4686 - val_loss: 2.2912 - val_acc: 0.2433\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3513 - acc: 0.4629 - val_loss: 2.2730 - val_acc: 0.2400\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3500 - acc: 0.4700 - val_loss: 2.2899 - val_acc: 0.2433\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3512 - acc: 0.4643 - val_loss: 2.2908 - val_acc: 0.2400\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3517 - acc: 0.4686 - val_loss: 2.2940 - val_acc: 0.2467\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3506 - acc: 0.4643 - val_loss: 2.2796 - val_acc: 0.2433\n",
      "Epoch 1359/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 236us/step - loss: 1.3497 - acc: 0.4671 - val_loss: 2.2997 - val_acc: 0.2400\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3507 - acc: 0.4657 - val_loss: 2.2912 - val_acc: 0.2433\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3510 - acc: 0.4629 - val_loss: 2.2979 - val_acc: 0.2467\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3497 - acc: 0.4629 - val_loss: 2.2802 - val_acc: 0.2433\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3506 - acc: 0.4714 - val_loss: 2.2868 - val_acc: 0.2433\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3498 - acc: 0.4643 - val_loss: 2.2969 - val_acc: 0.2467\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3505 - acc: 0.4729 - val_loss: 2.2740 - val_acc: 0.2400\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3499 - acc: 0.4686 - val_loss: 2.2877 - val_acc: 0.2433\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3499 - acc: 0.4757 - val_loss: 2.2772 - val_acc: 0.2433\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3504 - acc: 0.4671 - val_loss: 2.2963 - val_acc: 0.2467\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3505 - acc: 0.4686 - val_loss: 2.3084 - val_acc: 0.2433\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3490 - acc: 0.4657 - val_loss: 2.3063 - val_acc: 0.2467\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3502 - acc: 0.4714 - val_loss: 2.2941 - val_acc: 0.2400\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3495 - acc: 0.4686 - val_loss: 2.2957 - val_acc: 0.2400\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3495 - acc: 0.4714 - val_loss: 2.2975 - val_acc: 0.2533\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3494 - acc: 0.4643 - val_loss: 2.3007 - val_acc: 0.2500\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3496 - acc: 0.4743 - val_loss: 2.2855 - val_acc: 0.2433\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3488 - acc: 0.4700 - val_loss: 2.2866 - val_acc: 0.2500\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3495 - acc: 0.4686 - val_loss: 2.2738 - val_acc: 0.2433\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3490 - acc: 0.4714 - val_loss: 2.3018 - val_acc: 0.2500\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3487 - acc: 0.4643 - val_loss: 2.3057 - val_acc: 0.2433\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3483 - acc: 0.4671 - val_loss: 2.2990 - val_acc: 0.2467\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3487 - acc: 0.4686 - val_loss: 2.2997 - val_acc: 0.2433\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3470 - acc: 0.4729 - val_loss: 2.3080 - val_acc: 0.2467\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3481 - acc: 0.4643 - val_loss: 2.3010 - val_acc: 0.2433\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3487 - acc: 0.4700 - val_loss: 2.2918 - val_acc: 0.2433\n",
      "Epoch 1385/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3475 - acc: 0.4743 - val_loss: 2.3021 - val_acc: 0.2467\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3480 - acc: 0.4600 - val_loss: 2.2933 - val_acc: 0.2333\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3478 - acc: 0.4700 - val_loss: 2.3064 - val_acc: 0.2300\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3481 - acc: 0.4657 - val_loss: 2.3019 - val_acc: 0.2433\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3471 - acc: 0.4671 - val_loss: 2.3066 - val_acc: 0.2467\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3481 - acc: 0.4657 - val_loss: 2.2985 - val_acc: 0.2433\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3483 - acc: 0.4657 - val_loss: 2.3057 - val_acc: 0.2467\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3483 - acc: 0.4600 - val_loss: 2.3085 - val_acc: 0.2400\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3475 - acc: 0.4700 - val_loss: 2.3095 - val_acc: 0.2467\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3463 - acc: 0.4586 - val_loss: 2.2998 - val_acc: 0.2267\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3475 - acc: 0.4671 - val_loss: 2.3084 - val_acc: 0.2300\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3483 - acc: 0.4643 - val_loss: 2.2923 - val_acc: 0.2500\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3462 - acc: 0.4657 - val_loss: 2.3013 - val_acc: 0.2467\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3474 - acc: 0.4657 - val_loss: 2.3108 - val_acc: 0.2500\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3466 - acc: 0.4757 - val_loss: 2.3273 - val_acc: 0.2500\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3460 - acc: 0.4657 - val_loss: 2.3375 - val_acc: 0.2467\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3471 - acc: 0.4714 - val_loss: 2.3078 - val_acc: 0.2500\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3464 - acc: 0.4714 - val_loss: 2.2972 - val_acc: 0.2433\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3450 - acc: 0.4671 - val_loss: 2.2947 - val_acc: 0.2467\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3467 - acc: 0.4586 - val_loss: 2.3195 - val_acc: 0.2467\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3465 - acc: 0.4614 - val_loss: 2.3040 - val_acc: 0.2467\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3466 - acc: 0.4671 - val_loss: 2.2931 - val_acc: 0.2400\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3464 - acc: 0.4714 - val_loss: 2.2984 - val_acc: 0.2433\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3459 - acc: 0.4686 - val_loss: 2.2992 - val_acc: 0.2467\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3458 - acc: 0.4657 - val_loss: 2.2892 - val_acc: 0.2467\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3464 - acc: 0.4686 - val_loss: 2.2883 - val_acc: 0.2467\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3458 - acc: 0.4714 - val_loss: 2.3230 - val_acc: 0.2467\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3462 - acc: 0.4729 - val_loss: 2.2965 - val_acc: 0.2467\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3458 - acc: 0.4643 - val_loss: 2.3157 - val_acc: 0.2400\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3466 - acc: 0.4657 - val_loss: 2.2892 - val_acc: 0.2433\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3458 - acc: 0.4743 - val_loss: 2.3052 - val_acc: 0.2500\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.3458 - acc: 0.4714 - val_loss: 2.3051 - val_acc: 0.2500\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3462 - acc: 0.4714 - val_loss: 2.2864 - val_acc: 0.2500\n",
      "Epoch 1418/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 238us/step - loss: 1.3449 - acc: 0.4629 - val_loss: 2.2970 - val_acc: 0.2467\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3457 - acc: 0.4686 - val_loss: 2.2787 - val_acc: 0.2433\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3458 - acc: 0.4714 - val_loss: 2.3189 - val_acc: 0.2433\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3458 - acc: 0.4657 - val_loss: 2.3065 - val_acc: 0.2433\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3439 - acc: 0.4700 - val_loss: 2.2985 - val_acc: 0.2467\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3447 - acc: 0.4643 - val_loss: 2.3143 - val_acc: 0.2400\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3454 - acc: 0.4700 - val_loss: 2.3053 - val_acc: 0.2433\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3439 - acc: 0.4614 - val_loss: 2.3120 - val_acc: 0.2333\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3446 - acc: 0.4714 - val_loss: 2.3097 - val_acc: 0.2467\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3441 - acc: 0.4686 - val_loss: 2.3230 - val_acc: 0.2467\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3446 - acc: 0.4729 - val_loss: 2.3041 - val_acc: 0.2467\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3446 - acc: 0.4657 - val_loss: 2.2878 - val_acc: 0.2433\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3445 - acc: 0.4671 - val_loss: 2.3202 - val_acc: 0.2467\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3437 - acc: 0.4771 - val_loss: 2.2895 - val_acc: 0.2400\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3444 - acc: 0.4714 - val_loss: 2.3161 - val_acc: 0.2433\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3449 - acc: 0.4686 - val_loss: 2.3074 - val_acc: 0.2467\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3447 - acc: 0.4686 - val_loss: 2.3015 - val_acc: 0.2467\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3447 - acc: 0.4643 - val_loss: 2.3070 - val_acc: 0.2433\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3424 - acc: 0.4643 - val_loss: 2.3181 - val_acc: 0.2467\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3446 - acc: 0.4743 - val_loss: 2.3092 - val_acc: 0.2467\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3442 - acc: 0.4643 - val_loss: 2.2985 - val_acc: 0.2433\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3439 - acc: 0.4729 - val_loss: 2.3137 - val_acc: 0.2500\n",
      "Epoch 1440/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3440 - acc: 0.4671 - val_loss: 2.3064 - val_acc: 0.2467\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3436 - acc: 0.4714 - val_loss: 2.3076 - val_acc: 0.2400\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3440 - acc: 0.4729 - val_loss: 2.3175 - val_acc: 0.2433\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3433 - acc: 0.4686 - val_loss: 2.3137 - val_acc: 0.2433\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3439 - acc: 0.4686 - val_loss: 2.3075 - val_acc: 0.2500\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3425 - acc: 0.4600 - val_loss: 2.3079 - val_acc: 0.2333\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3433 - acc: 0.4743 - val_loss: 2.3241 - val_acc: 0.2467\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3436 - acc: 0.4643 - val_loss: 2.3113 - val_acc: 0.2433\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3422 - acc: 0.4671 - val_loss: 2.3104 - val_acc: 0.2367\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3428 - acc: 0.4671 - val_loss: 2.2948 - val_acc: 0.2433\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3432 - acc: 0.4814 - val_loss: 2.2954 - val_acc: 0.2433\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3425 - acc: 0.4714 - val_loss: 2.3170 - val_acc: 0.2467\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3429 - acc: 0.4686 - val_loss: 2.3061 - val_acc: 0.2433\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3423 - acc: 0.4657 - val_loss: 2.3033 - val_acc: 0.2433\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3429 - acc: 0.4771 - val_loss: 2.3021 - val_acc: 0.2433\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3427 - acc: 0.4757 - val_loss: 2.3198 - val_acc: 0.2467\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3430 - acc: 0.4757 - val_loss: 2.3112 - val_acc: 0.2400\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3425 - acc: 0.4643 - val_loss: 2.3202 - val_acc: 0.2500\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3428 - acc: 0.4629 - val_loss: 2.3092 - val_acc: 0.2400\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3425 - acc: 0.4686 - val_loss: 2.3060 - val_acc: 0.2500\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3414 - acc: 0.4714 - val_loss: 2.3096 - val_acc: 0.2367\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3412 - acc: 0.4671 - val_loss: 2.3022 - val_acc: 0.2533\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3418 - acc: 0.4757 - val_loss: 2.3341 - val_acc: 0.2467\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3418 - acc: 0.4657 - val_loss: 2.3146 - val_acc: 0.2433\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3417 - acc: 0.4657 - val_loss: 2.3045 - val_acc: 0.2467\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3418 - acc: 0.4700 - val_loss: 2.3311 - val_acc: 0.2433\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3417 - acc: 0.4671 - val_loss: 2.3178 - val_acc: 0.2433\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3396 - acc: 0.4729 - val_loss: 2.3122 - val_acc: 0.2433\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3431 - acc: 0.4714 - val_loss: 2.3125 - val_acc: 0.2500\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3417 - acc: 0.4686 - val_loss: 2.3213 - val_acc: 0.2433\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3412 - acc: 0.4714 - val_loss: 2.3183 - val_acc: 0.2433\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3403 - acc: 0.4700 - val_loss: 2.3223 - val_acc: 0.2500\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3413 - acc: 0.4643 - val_loss: 2.3291 - val_acc: 0.2433\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3407 - acc: 0.4686 - val_loss: 2.3066 - val_acc: 0.2433\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3404 - acc: 0.4714 - val_loss: 2.3151 - val_acc: 0.2500\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3403 - acc: 0.4714 - val_loss: 2.3243 - val_acc: 0.2500\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3409 - acc: 0.4671 - val_loss: 2.3173 - val_acc: 0.2433\n",
      "Epoch 1477/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 240us/step - loss: 1.3411 - acc: 0.4657 - val_loss: 2.3218 - val_acc: 0.2400\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3401 - acc: 0.4729 - val_loss: 2.3014 - val_acc: 0.2533\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3403 - acc: 0.4629 - val_loss: 2.3114 - val_acc: 0.2433\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3408 - acc: 0.4700 - val_loss: 2.3174 - val_acc: 0.2433\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3400 - acc: 0.4657 - val_loss: 2.3164 - val_acc: 0.2367\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3401 - acc: 0.4714 - val_loss: 2.3381 - val_acc: 0.2500\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3409 - acc: 0.4743 - val_loss: 2.3231 - val_acc: 0.2433\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3397 - acc: 0.4686 - val_loss: 2.3145 - val_acc: 0.2367\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3396 - acc: 0.4657 - val_loss: 2.3300 - val_acc: 0.2267\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3402 - acc: 0.4700 - val_loss: 2.3171 - val_acc: 0.2500\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3396 - acc: 0.4686 - val_loss: 2.3281 - val_acc: 0.2467\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3391 - acc: 0.4629 - val_loss: 2.3011 - val_acc: 0.2400\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3399 - acc: 0.4700 - val_loss: 2.3318 - val_acc: 0.2367\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3390 - acc: 0.4686 - val_loss: 2.3373 - val_acc: 0.2467\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3395 - acc: 0.4714 - val_loss: 2.3343 - val_acc: 0.2433\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3378 - acc: 0.4714 - val_loss: 2.3268 - val_acc: 0.2367\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3412 - acc: 0.4614 - val_loss: 2.3188 - val_acc: 0.2500\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3398 - acc: 0.4743 - val_loss: 2.3189 - val_acc: 0.2500\n",
      "Epoch 1495/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3383 - acc: 0.4686 - val_loss: 2.3182 - val_acc: 0.2433\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3393 - acc: 0.4714 - val_loss: 2.3173 - val_acc: 0.2500\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3383 - acc: 0.4671 - val_loss: 2.3264 - val_acc: 0.2433\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3387 - acc: 0.4743 - val_loss: 2.3427 - val_acc: 0.2500\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3395 - acc: 0.4700 - val_loss: 2.3212 - val_acc: 0.2467\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3388 - acc: 0.4771 - val_loss: 2.3271 - val_acc: 0.2433\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3389 - acc: 0.4729 - val_loss: 2.3219 - val_acc: 0.2467\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3390 - acc: 0.4714 - val_loss: 2.3239 - val_acc: 0.2467\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3390 - acc: 0.4657 - val_loss: 2.3212 - val_acc: 0.2433\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3381 - acc: 0.4743 - val_loss: 2.3341 - val_acc: 0.2433\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3386 - acc: 0.4686 - val_loss: 2.3249 - val_acc: 0.2400\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3391 - acc: 0.4786 - val_loss: 2.3173 - val_acc: 0.2433\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3382 - acc: 0.4714 - val_loss: 2.3211 - val_acc: 0.2367\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3387 - acc: 0.4643 - val_loss: 2.3365 - val_acc: 0.2467\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3382 - acc: 0.4757 - val_loss: 2.3245 - val_acc: 0.2433\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3384 - acc: 0.4743 - val_loss: 2.3521 - val_acc: 0.2467\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3379 - acc: 0.4729 - val_loss: 2.3514 - val_acc: 0.2500\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3368 - acc: 0.4714 - val_loss: 2.3273 - val_acc: 0.2433\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3380 - acc: 0.4686 - val_loss: 2.3111 - val_acc: 0.2433\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3381 - acc: 0.4671 - val_loss: 2.3268 - val_acc: 0.2433\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3377 - acc: 0.4757 - val_loss: 2.3446 - val_acc: 0.2500\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3395 - acc: 0.4743 - val_loss: 2.3372 - val_acc: 0.2467\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3373 - acc: 0.4743 - val_loss: 2.3210 - val_acc: 0.2467\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3371 - acc: 0.4757 - val_loss: 2.3141 - val_acc: 0.2500\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3370 - acc: 0.4757 - val_loss: 2.3141 - val_acc: 0.2367\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3373 - acc: 0.4700 - val_loss: 2.3364 - val_acc: 0.2467\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3368 - acc: 0.4800 - val_loss: 2.3132 - val_acc: 0.2433\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3379 - acc: 0.4714 - val_loss: 2.3239 - val_acc: 0.2467\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3371 - acc: 0.4743 - val_loss: 2.3179 - val_acc: 0.2467\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3374 - acc: 0.4714 - val_loss: 2.3353 - val_acc: 0.2467\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3370 - acc: 0.4729 - val_loss: 2.3244 - val_acc: 0.2467\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3369 - acc: 0.4743 - val_loss: 2.3571 - val_acc: 0.2467\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3354 - acc: 0.4686 - val_loss: 2.3230 - val_acc: 0.2333\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3370 - acc: 0.4786 - val_loss: 2.3365 - val_acc: 0.2467\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3375 - acc: 0.4657 - val_loss: 2.3361 - val_acc: 0.2433\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3369 - acc: 0.4643 - val_loss: 2.3257 - val_acc: 0.2433\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3366 - acc: 0.4757 - val_loss: 2.3283 - val_acc: 0.2433\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3364 - acc: 0.4800 - val_loss: 2.3169 - val_acc: 0.2500\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3365 - acc: 0.4729 - val_loss: 2.3271 - val_acc: 0.2433\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3370 - acc: 0.4700 - val_loss: 2.3188 - val_acc: 0.2500\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3368 - acc: 0.4771 - val_loss: 2.3411 - val_acc: 0.2400\n",
      "Epoch 1536/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 238us/step - loss: 1.3360 - acc: 0.4757 - val_loss: 2.3282 - val_acc: 0.2400\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3359 - acc: 0.4743 - val_loss: 2.3294 - val_acc: 0.2467\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3354 - acc: 0.4729 - val_loss: 2.3215 - val_acc: 0.2433\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3354 - acc: 0.4671 - val_loss: 2.3125 - val_acc: 0.2500\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3358 - acc: 0.4714 - val_loss: 2.3143 - val_acc: 0.2500\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3362 - acc: 0.4714 - val_loss: 2.3316 - val_acc: 0.2433\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3357 - acc: 0.4729 - val_loss: 2.3322 - val_acc: 0.2367\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3357 - acc: 0.4757 - val_loss: 2.3253 - val_acc: 0.2433\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3362 - acc: 0.4800 - val_loss: 2.3308 - val_acc: 0.2433\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3352 - acc: 0.4729 - val_loss: 2.3152 - val_acc: 0.2433\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3357 - acc: 0.4800 - val_loss: 2.3325 - val_acc: 0.2367\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.3356 - acc: 0.4757 - val_loss: 2.3451 - val_acc: 0.2433\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3358 - acc: 0.4714 - val_loss: 2.3438 - val_acc: 0.2500\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3343 - acc: 0.4729 - val_loss: 2.3494 - val_acc: 0.2433\n",
      "Epoch 1550/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3352 - acc: 0.4700 - val_loss: 2.3477 - val_acc: 0.2433\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3351 - acc: 0.4743 - val_loss: 2.3245 - val_acc: 0.2367\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3348 - acc: 0.4729 - val_loss: 2.3448 - val_acc: 0.2500\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3348 - acc: 0.4771 - val_loss: 2.3444 - val_acc: 0.2467\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3352 - acc: 0.4700 - val_loss: 2.3333 - val_acc: 0.2367\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3350 - acc: 0.4714 - val_loss: 2.3352 - val_acc: 0.2400\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3342 - acc: 0.4729 - val_loss: 2.3308 - val_acc: 0.2467\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3339 - acc: 0.4729 - val_loss: 2.3351 - val_acc: 0.2433\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3342 - acc: 0.4743 - val_loss: 2.3116 - val_acc: 0.2533\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3345 - acc: 0.4757 - val_loss: 2.3426 - val_acc: 0.2467\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3347 - acc: 0.4729 - val_loss: 2.3320 - val_acc: 0.2433\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3337 - acc: 0.4714 - val_loss: 2.3370 - val_acc: 0.2467\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.3343 - acc: 0.4700 - val_loss: 2.3575 - val_acc: 0.2500\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 256us/step - loss: 1.3350 - acc: 0.4757 - val_loss: 2.3373 - val_acc: 0.2467\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3328 - acc: 0.4757 - val_loss: 2.3318 - val_acc: 0.2400\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 263us/step - loss: 1.3350 - acc: 0.4757 - val_loss: 2.3286 - val_acc: 0.2467\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3334 - acc: 0.4771 - val_loss: 2.3296 - val_acc: 0.2367\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3343 - acc: 0.4757 - val_loss: 2.3365 - val_acc: 0.2400\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3337 - acc: 0.4729 - val_loss: 2.3314 - val_acc: 0.2433\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3342 - acc: 0.4786 - val_loss: 2.3571 - val_acc: 0.2467\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 253us/step - loss: 1.3330 - acc: 0.4814 - val_loss: 2.3604 - val_acc: 0.2433\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3347 - acc: 0.4714 - val_loss: 2.3482 - val_acc: 0.2433\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3339 - acc: 0.4771 - val_loss: 2.3371 - val_acc: 0.2367\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3335 - acc: 0.4757 - val_loss: 2.3630 - val_acc: 0.2433\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3339 - acc: 0.4671 - val_loss: 2.3410 - val_acc: 0.2433\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3327 - acc: 0.4757 - val_loss: 2.3258 - val_acc: 0.2467\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.3330 - acc: 0.4771 - val_loss: 2.3519 - val_acc: 0.2467\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 280us/step - loss: 1.3337 - acc: 0.4700 - val_loss: 2.3314 - val_acc: 0.2400\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3320 - acc: 0.4771 - val_loss: 2.3402 - val_acc: 0.2433\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3331 - acc: 0.4714 - val_loss: 2.3402 - val_acc: 0.2467\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3321 - acc: 0.4800 - val_loss: 2.3477 - val_acc: 0.2467\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3335 - acc: 0.4671 - val_loss: 2.3494 - val_acc: 0.2400\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3330 - acc: 0.4771 - val_loss: 2.3309 - val_acc: 0.2433\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3323 - acc: 0.4743 - val_loss: 2.3418 - val_acc: 0.2433\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3336 - acc: 0.4757 - val_loss: 2.3502 - val_acc: 0.2433\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3327 - acc: 0.4700 - val_loss: 2.3427 - val_acc: 0.2500\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3318 - acc: 0.4729 - val_loss: 2.3540 - val_acc: 0.2333\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3321 - acc: 0.4714 - val_loss: 2.3566 - val_acc: 0.2400\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3320 - acc: 0.4800 - val_loss: 2.3328 - val_acc: 0.2467\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3324 - acc: 0.4786 - val_loss: 2.3551 - val_acc: 0.2400\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3316 - acc: 0.4714 - val_loss: 2.3457 - val_acc: 0.2500\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3324 - acc: 0.4800 - val_loss: 2.3366 - val_acc: 0.2433\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3319 - acc: 0.4686 - val_loss: 2.3483 - val_acc: 0.2467\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3310 - acc: 0.4700 - val_loss: 2.3563 - val_acc: 0.2400\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3321 - acc: 0.4771 - val_loss: 2.3486 - val_acc: 0.2433\n",
      "Epoch 1595/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 247us/step - loss: 1.3310 - acc: 0.4771 - val_loss: 2.3433 - val_acc: 0.2433\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3315 - acc: 0.4729 - val_loss: 2.3237 - val_acc: 0.2467\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3311 - acc: 0.4757 - val_loss: 2.3335 - val_acc: 0.2433\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 271us/step - loss: 1.3323 - acc: 0.4829 - val_loss: 2.3487 - val_acc: 0.2400\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3313 - acc: 0.4686 - val_loss: 2.3439 - val_acc: 0.2333\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3315 - acc: 0.4771 - val_loss: 2.3504 - val_acc: 0.2333\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3320 - acc: 0.4771 - val_loss: 2.3337 - val_acc: 0.2467\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3307 - acc: 0.4729 - val_loss: 2.3595 - val_acc: 0.2467\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3313 - acc: 0.4714 - val_loss: 2.3600 - val_acc: 0.2500\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3311 - acc: 0.4757 - val_loss: 2.3520 - val_acc: 0.2433\n",
      "Epoch 1605/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3313 - acc: 0.4800 - val_loss: 2.3642 - val_acc: 0.2500\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3307 - acc: 0.4786 - val_loss: 2.3312 - val_acc: 0.2400\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3324 - acc: 0.4800 - val_loss: 2.3439 - val_acc: 0.2467\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3294 - acc: 0.4786 - val_loss: 2.3488 - val_acc: 0.2467\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3308 - acc: 0.4786 - val_loss: 2.3704 - val_acc: 0.2500\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3312 - acc: 0.4729 - val_loss: 2.3540 - val_acc: 0.2433\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3299 - acc: 0.4743 - val_loss: 2.3631 - val_acc: 0.2433\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3306 - acc: 0.4729 - val_loss: 2.3532 - val_acc: 0.2433\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3300 - acc: 0.4743 - val_loss: 2.3550 - val_acc: 0.2333\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3304 - acc: 0.4700 - val_loss: 2.3550 - val_acc: 0.2467\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3310 - acc: 0.4800 - val_loss: 2.3675 - val_acc: 0.2467\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3307 - acc: 0.4786 - val_loss: 2.3528 - val_acc: 0.2433\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3293 - acc: 0.4757 - val_loss: 2.3355 - val_acc: 0.2433\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3312 - acc: 0.4729 - val_loss: 2.3500 - val_acc: 0.2400\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3300 - acc: 0.4743 - val_loss: 2.3554 - val_acc: 0.2467\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3300 - acc: 0.4757 - val_loss: 2.3562 - val_acc: 0.2400\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3298 - acc: 0.4800 - val_loss: 2.3774 - val_acc: 0.2467\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3293 - acc: 0.4743 - val_loss: 2.3412 - val_acc: 0.2467\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3291 - acc: 0.4729 - val_loss: 2.3515 - val_acc: 0.2400\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3281 - acc: 0.4757 - val_loss: 2.3617 - val_acc: 0.2400\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3297 - acc: 0.4743 - val_loss: 2.3595 - val_acc: 0.2367\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3291 - acc: 0.4771 - val_loss: 2.3501 - val_acc: 0.2400\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3291 - acc: 0.4771 - val_loss: 2.3883 - val_acc: 0.2433\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3292 - acc: 0.4800 - val_loss: 2.3640 - val_acc: 0.2400\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3294 - acc: 0.4814 - val_loss: 2.3461 - val_acc: 0.2433\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3292 - acc: 0.4743 - val_loss: 2.3637 - val_acc: 0.2400\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3295 - acc: 0.4800 - val_loss: 2.3598 - val_acc: 0.2433\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3282 - acc: 0.4771 - val_loss: 2.3816 - val_acc: 0.2433\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3291 - acc: 0.4729 - val_loss: 2.3585 - val_acc: 0.2400\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3282 - acc: 0.4771 - val_loss: 2.3733 - val_acc: 0.2500\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3278 - acc: 0.4714 - val_loss: 2.3578 - val_acc: 0.2400\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3288 - acc: 0.4743 - val_loss: 2.3759 - val_acc: 0.2500\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3265 - acc: 0.4714 - val_loss: 2.3722 - val_acc: 0.2433\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3279 - acc: 0.4786 - val_loss: 2.3781 - val_acc: 0.2467\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3275 - acc: 0.4686 - val_loss: 2.3746 - val_acc: 0.2400\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3276 - acc: 0.4757 - val_loss: 2.3821 - val_acc: 0.2467\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3284 - acc: 0.4814 - val_loss: 2.3554 - val_acc: 0.2400\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3278 - acc: 0.4786 - val_loss: 2.3642 - val_acc: 0.2433\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3274 - acc: 0.4814 - val_loss: 2.3750 - val_acc: 0.2467\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3273 - acc: 0.4757 - val_loss: 2.3608 - val_acc: 0.2400\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3257 - acc: 0.4829 - val_loss: 2.3683 - val_acc: 0.2433\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3263 - acc: 0.4686 - val_loss: 2.3508 - val_acc: 0.2367\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3266 - acc: 0.4843 - val_loss: 2.3883 - val_acc: 0.2433\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3275 - acc: 0.4771 - val_loss: 2.3759 - val_acc: 0.2400\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3265 - acc: 0.4743 - val_loss: 2.3740 - val_acc: 0.2400\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3260 - acc: 0.4857 - val_loss: 2.3621 - val_acc: 0.2433\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3276 - acc: 0.4729 - val_loss: 2.3594 - val_acc: 0.2467\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3268 - acc: 0.4743 - val_loss: 2.3661 - val_acc: 0.2400\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3259 - acc: 0.4743 - val_loss: 2.3800 - val_acc: 0.2500\n",
      "Epoch 1654/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 233us/step - loss: 1.3285 - acc: 0.4786 - val_loss: 2.3636 - val_acc: 0.2467\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3257 - acc: 0.4771 - val_loss: 2.3661 - val_acc: 0.2400\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3273 - acc: 0.4786 - val_loss: 2.3653 - val_acc: 0.2400\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3268 - acc: 0.4829 - val_loss: 2.3644 - val_acc: 0.2467\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3263 - acc: 0.4786 - val_loss: 2.3749 - val_acc: 0.2400\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3266 - acc: 0.4857 - val_loss: 2.3595 - val_acc: 0.2400\n",
      "Epoch 1660/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3262 - acc: 0.4757 - val_loss: 2.3729 - val_acc: 0.2400\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3259 - acc: 0.4786 - val_loss: 2.3610 - val_acc: 0.2433\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3261 - acc: 0.4757 - val_loss: 2.3687 - val_acc: 0.2433\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3263 - acc: 0.4800 - val_loss: 2.3753 - val_acc: 0.2433\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3267 - acc: 0.4757 - val_loss: 2.3810 - val_acc: 0.2467\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3258 - acc: 0.4657 - val_loss: 2.3640 - val_acc: 0.2467\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3258 - acc: 0.4814 - val_loss: 2.3677 - val_acc: 0.2467\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3253 - acc: 0.4786 - val_loss: 2.3598 - val_acc: 0.2400\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3255 - acc: 0.4729 - val_loss: 2.3595 - val_acc: 0.2400\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3258 - acc: 0.4829 - val_loss: 2.3708 - val_acc: 0.2400\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3249 - acc: 0.4814 - val_loss: 2.3849 - val_acc: 0.2433\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3256 - acc: 0.4757 - val_loss: 2.3813 - val_acc: 0.2433\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3252 - acc: 0.4814 - val_loss: 2.3770 - val_acc: 0.2433\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3248 - acc: 0.4771 - val_loss: 2.3993 - val_acc: 0.2533\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3242 - acc: 0.4871 - val_loss: 2.3882 - val_acc: 0.2433\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3251 - acc: 0.4786 - val_loss: 2.3645 - val_acc: 0.2400\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3255 - acc: 0.4771 - val_loss: 2.3777 - val_acc: 0.2400\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3237 - acc: 0.4771 - val_loss: 2.3627 - val_acc: 0.2467\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3250 - acc: 0.4771 - val_loss: 2.3728 - val_acc: 0.2433\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3245 - acc: 0.4757 - val_loss: 2.3792 - val_acc: 0.2400\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3245 - acc: 0.4814 - val_loss: 2.3703 - val_acc: 0.2433\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3249 - acc: 0.4800 - val_loss: 2.3729 - val_acc: 0.2400\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3248 - acc: 0.4800 - val_loss: 2.3718 - val_acc: 0.2433\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3248 - acc: 0.4829 - val_loss: 2.3723 - val_acc: 0.2400\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3234 - acc: 0.4843 - val_loss: 2.3960 - val_acc: 0.2467\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3248 - acc: 0.4786 - val_loss: 2.3759 - val_acc: 0.2433\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3238 - acc: 0.4729 - val_loss: 2.3984 - val_acc: 0.2500\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3245 - acc: 0.4871 - val_loss: 2.3776 - val_acc: 0.2400\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3245 - acc: 0.4886 - val_loss: 2.3710 - val_acc: 0.2400\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3250 - acc: 0.4757 - val_loss: 2.3796 - val_acc: 0.2433\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3244 - acc: 0.4814 - val_loss: 2.3713 - val_acc: 0.2367\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3233 - acc: 0.4829 - val_loss: 2.3712 - val_acc: 0.2433\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3240 - acc: 0.4786 - val_loss: 2.3804 - val_acc: 0.2433\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3237 - acc: 0.4757 - val_loss: 2.3931 - val_acc: 0.2400\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3243 - acc: 0.4829 - val_loss: 2.3911 - val_acc: 0.2467\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3240 - acc: 0.4786 - val_loss: 2.3773 - val_acc: 0.2433\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3234 - acc: 0.4786 - val_loss: 2.3534 - val_acc: 0.2467\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3235 - acc: 0.4871 - val_loss: 2.3754 - val_acc: 0.2433\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3234 - acc: 0.4829 - val_loss: 2.3857 - val_acc: 0.2400\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3238 - acc: 0.4786 - val_loss: 2.3915 - val_acc: 0.2467\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3229 - acc: 0.4771 - val_loss: 2.3907 - val_acc: 0.2500\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3228 - acc: 0.4814 - val_loss: 2.3836 - val_acc: 0.2433\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3235 - acc: 0.4743 - val_loss: 2.3689 - val_acc: 0.2433\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3229 - acc: 0.4714 - val_loss: 2.3745 - val_acc: 0.2400\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3225 - acc: 0.4786 - val_loss: 2.3802 - val_acc: 0.2400\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3232 - acc: 0.4829 - val_loss: 2.3937 - val_acc: 0.2467\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3226 - acc: 0.4800 - val_loss: 2.3719 - val_acc: 0.2433\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3232 - acc: 0.4814 - val_loss: 2.3861 - val_acc: 0.2467\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3217 - acc: 0.4786 - val_loss: 2.3759 - val_acc: 0.2433\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3221 - acc: 0.4771 - val_loss: 2.3781 - val_acc: 0.2433\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3226 - acc: 0.4771 - val_loss: 2.3662 - val_acc: 0.2433\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3225 - acc: 0.4800 - val_loss: 2.3776 - val_acc: 0.2433\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3231 - acc: 0.4786 - val_loss: 2.3817 - val_acc: 0.2433\n",
      "Epoch 1713/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 228us/step - loss: 1.3219 - acc: 0.4757 - val_loss: 2.4006 - val_acc: 0.2500\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3233 - acc: 0.4814 - val_loss: 2.3623 - val_acc: 0.2433\n",
      "Epoch 1715/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3225 - acc: 0.4857 - val_loss: 2.3976 - val_acc: 0.2533\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3221 - acc: 0.4800 - val_loss: 2.3990 - val_acc: 0.2533\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3220 - acc: 0.4800 - val_loss: 2.3707 - val_acc: 0.2433\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3229 - acc: 0.4886 - val_loss: 2.3886 - val_acc: 0.2467\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3224 - acc: 0.4857 - val_loss: 2.3517 - val_acc: 0.2433\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3212 - acc: 0.4814 - val_loss: 2.3802 - val_acc: 0.2433\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3220 - acc: 0.4800 - val_loss: 2.3753 - val_acc: 0.2433\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3227 - acc: 0.4757 - val_loss: 2.3647 - val_acc: 0.2400\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3219 - acc: 0.4800 - val_loss: 2.3677 - val_acc: 0.2400\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3210 - acc: 0.4857 - val_loss: 2.3792 - val_acc: 0.2367\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3217 - acc: 0.4857 - val_loss: 2.3867 - val_acc: 0.2433\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3212 - acc: 0.4814 - val_loss: 2.3901 - val_acc: 0.2467\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3221 - acc: 0.4829 - val_loss: 2.3892 - val_acc: 0.2500\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3212 - acc: 0.4743 - val_loss: 2.3881 - val_acc: 0.2433\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3219 - acc: 0.4757 - val_loss: 2.3827 - val_acc: 0.2400\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3210 - acc: 0.4843 - val_loss: 2.3712 - val_acc: 0.2400\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3213 - acc: 0.4814 - val_loss: 2.3955 - val_acc: 0.2500\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3210 - acc: 0.4829 - val_loss: 2.3899 - val_acc: 0.2467\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3201 - acc: 0.4800 - val_loss: 2.3987 - val_acc: 0.2467\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3212 - acc: 0.4757 - val_loss: 2.3894 - val_acc: 0.2433\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3217 - acc: 0.4814 - val_loss: 2.3763 - val_acc: 0.2433\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3209 - acc: 0.4829 - val_loss: 2.3890 - val_acc: 0.2433\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3194 - acc: 0.4843 - val_loss: 2.3931 - val_acc: 0.2433\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3210 - acc: 0.4814 - val_loss: 2.4025 - val_acc: 0.2533\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3208 - acc: 0.4800 - val_loss: 2.3809 - val_acc: 0.2400\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3207 - acc: 0.4829 - val_loss: 2.4026 - val_acc: 0.2500\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 1.3206 - acc: 0.4857 - val_loss: 2.3612 - val_acc: 0.2400\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3199 - acc: 0.4843 - val_loss: 2.3977 - val_acc: 0.2500\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3208 - acc: 0.4814 - val_loss: 2.3995 - val_acc: 0.2467\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3204 - acc: 0.4771 - val_loss: 2.3929 - val_acc: 0.2467\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3201 - acc: 0.4843 - val_loss: 2.3829 - val_acc: 0.2400\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3205 - acc: 0.4786 - val_loss: 2.4031 - val_acc: 0.2500\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3201 - acc: 0.4814 - val_loss: 2.3959 - val_acc: 0.2433\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3194 - acc: 0.4743 - val_loss: 2.3953 - val_acc: 0.2400\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3201 - acc: 0.4800 - val_loss: 2.3944 - val_acc: 0.2467\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3192 - acc: 0.4814 - val_loss: 2.3646 - val_acc: 0.2433\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3200 - acc: 0.4829 - val_loss: 2.3665 - val_acc: 0.2433\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3188 - acc: 0.4800 - val_loss: 2.3726 - val_acc: 0.2433\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3199 - acc: 0.4771 - val_loss: 2.4031 - val_acc: 0.2433\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3200 - acc: 0.4843 - val_loss: 2.4039 - val_acc: 0.2433\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3186 - acc: 0.4843 - val_loss: 2.3983 - val_acc: 0.2467\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3196 - acc: 0.4771 - val_loss: 2.3755 - val_acc: 0.2433\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.3193 - acc: 0.4871 - val_loss: 2.4069 - val_acc: 0.2467\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3192 - acc: 0.4857 - val_loss: 2.3809 - val_acc: 0.2433\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3191 - acc: 0.4814 - val_loss: 2.4281 - val_acc: 0.2500\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3197 - acc: 0.4843 - val_loss: 2.3698 - val_acc: 0.2467\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3201 - acc: 0.4900 - val_loss: 2.3829 - val_acc: 0.2433\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3190 - acc: 0.4814 - val_loss: 2.4074 - val_acc: 0.2433\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3190 - acc: 0.4771 - val_loss: 2.3895 - val_acc: 0.2400\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3179 - acc: 0.4857 - val_loss: 2.3914 - val_acc: 0.2433\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3197 - acc: 0.4800 - val_loss: 2.3876 - val_acc: 0.2467\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3186 - acc: 0.4800 - val_loss: 2.3791 - val_acc: 0.2433\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3192 - acc: 0.4829 - val_loss: 2.3811 - val_acc: 0.2433\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3189 - acc: 0.4843 - val_loss: 2.3882 - val_acc: 0.2433\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3183 - acc: 0.4829 - val_loss: 2.3887 - val_acc: 0.2467\n",
      "Epoch 1770/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3190 - acc: 0.4929 - val_loss: 2.4006 - val_acc: 0.2467\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3186 - acc: 0.4843 - val_loss: 2.3824 - val_acc: 0.2433\n",
      "Epoch 1772/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 228us/step - loss: 1.3185 - acc: 0.4814 - val_loss: 2.4018 - val_acc: 0.2467\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3183 - acc: 0.4843 - val_loss: 2.3943 - val_acc: 0.2400\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3187 - acc: 0.4900 - val_loss: 2.3898 - val_acc: 0.2467\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3187 - acc: 0.4829 - val_loss: 2.4097 - val_acc: 0.2533\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3193 - acc: 0.4800 - val_loss: 2.3585 - val_acc: 0.2433\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3178 - acc: 0.4871 - val_loss: 2.3912 - val_acc: 0.2400\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3177 - acc: 0.4829 - val_loss: 2.3780 - val_acc: 0.2400\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3184 - acc: 0.4886 - val_loss: 2.3969 - val_acc: 0.2400\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3184 - acc: 0.4814 - val_loss: 2.4081 - val_acc: 0.2467\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3174 - acc: 0.4871 - val_loss: 2.4124 - val_acc: 0.2467\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3183 - acc: 0.4814 - val_loss: 2.3702 - val_acc: 0.2400\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3176 - acc: 0.4914 - val_loss: 2.4033 - val_acc: 0.2467\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3175 - acc: 0.4829 - val_loss: 2.3848 - val_acc: 0.2367\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3179 - acc: 0.4857 - val_loss: 2.3855 - val_acc: 0.2467\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3182 - acc: 0.4843 - val_loss: 2.3928 - val_acc: 0.2433\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3176 - acc: 0.4914 - val_loss: 2.3875 - val_acc: 0.2433\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3180 - acc: 0.4829 - val_loss: 2.3929 - val_acc: 0.2400\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 1.3178 - acc: 0.4843 - val_loss: 2.3724 - val_acc: 0.2400\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3175 - acc: 0.4857 - val_loss: 2.3712 - val_acc: 0.2400\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3179 - acc: 0.4814 - val_loss: 2.3887 - val_acc: 0.2400\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3168 - acc: 0.4814 - val_loss: 2.4136 - val_acc: 0.2467\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3170 - acc: 0.4814 - val_loss: 2.4039 - val_acc: 0.2467\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3168 - acc: 0.4857 - val_loss: 2.3978 - val_acc: 0.2433\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3173 - acc: 0.4814 - val_loss: 2.4011 - val_acc: 0.2433\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3167 - acc: 0.4814 - val_loss: 2.4217 - val_acc: 0.2533\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3163 - acc: 0.4800 - val_loss: 2.4045 - val_acc: 0.2433\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3176 - acc: 0.4871 - val_loss: 2.3901 - val_acc: 0.2433\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3168 - acc: 0.4900 - val_loss: 2.4228 - val_acc: 0.2467\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3170 - acc: 0.4843 - val_loss: 2.4116 - val_acc: 0.2467\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3162 - acc: 0.4857 - val_loss: 2.3887 - val_acc: 0.2400\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3164 - acc: 0.4857 - val_loss: 2.4072 - val_acc: 0.2467\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3160 - acc: 0.4843 - val_loss: 2.3962 - val_acc: 0.2467\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3167 - acc: 0.4886 - val_loss: 2.3920 - val_acc: 0.2433\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3167 - acc: 0.4843 - val_loss: 2.4107 - val_acc: 0.2467\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3164 - acc: 0.4814 - val_loss: 2.3903 - val_acc: 0.2400\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3162 - acc: 0.4800 - val_loss: 2.4088 - val_acc: 0.2467\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3157 - acc: 0.4771 - val_loss: 2.4080 - val_acc: 0.2500\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3164 - acc: 0.4814 - val_loss: 2.3794 - val_acc: 0.2367\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3163 - acc: 0.4843 - val_loss: 2.3949 - val_acc: 0.2400\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3158 - acc: 0.4871 - val_loss: 2.3952 - val_acc: 0.2433\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3160 - acc: 0.4829 - val_loss: 2.3930 - val_acc: 0.2467\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3169 - acc: 0.4771 - val_loss: 2.3945 - val_acc: 0.2400\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3167 - acc: 0.4771 - val_loss: 2.4005 - val_acc: 0.2467\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3155 - acc: 0.4871 - val_loss: 2.4065 - val_acc: 0.2467\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3148 - acc: 0.4857 - val_loss: 2.3937 - val_acc: 0.2400\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3150 - acc: 0.4843 - val_loss: 2.4089 - val_acc: 0.2433\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3162 - acc: 0.4800 - val_loss: 2.3945 - val_acc: 0.2400\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3158 - acc: 0.4871 - val_loss: 2.4056 - val_acc: 0.2433\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3166 - acc: 0.4829 - val_loss: 2.3878 - val_acc: 0.2400\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3147 - acc: 0.4829 - val_loss: 2.4348 - val_acc: 0.2467\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3144 - acc: 0.4857 - val_loss: 2.3916 - val_acc: 0.2467\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3142 - acc: 0.4786 - val_loss: 2.4230 - val_acc: 0.2433\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3154 - acc: 0.4829 - val_loss: 2.4262 - val_acc: 0.2500\n",
      "Epoch 1825/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3146 - acc: 0.4814 - val_loss: 2.4161 - val_acc: 0.2500\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3144 - acc: 0.4829 - val_loss: 2.3919 - val_acc: 0.2400\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3151 - acc: 0.4857 - val_loss: 2.3981 - val_acc: 0.2433\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3131 - acc: 0.4843 - val_loss: 2.4013 - val_acc: 0.2433\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3153 - acc: 0.4800 - val_loss: 2.3956 - val_acc: 0.2433\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3139 - acc: 0.4843 - val_loss: 2.4088 - val_acc: 0.2433\n",
      "Epoch 1831/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 226us/step - loss: 1.3138 - acc: 0.4871 - val_loss: 2.3987 - val_acc: 0.2400\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3138 - acc: 0.4857 - val_loss: 2.4097 - val_acc: 0.2467\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3136 - acc: 0.4843 - val_loss: 2.4204 - val_acc: 0.2433\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3137 - acc: 0.4814 - val_loss: 2.4211 - val_acc: 0.2433\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3134 - acc: 0.4871 - val_loss: 2.4119 - val_acc: 0.2433\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3140 - acc: 0.4886 - val_loss: 2.3945 - val_acc: 0.2400\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3136 - acc: 0.4843 - val_loss: 2.4007 - val_acc: 0.2400\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3133 - acc: 0.4800 - val_loss: 2.3967 - val_acc: 0.2400\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3124 - acc: 0.4900 - val_loss: 2.4295 - val_acc: 0.2467\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.3137 - acc: 0.4900 - val_loss: 2.4035 - val_acc: 0.2367\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3119 - acc: 0.4843 - val_loss: 2.3831 - val_acc: 0.2433\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3132 - acc: 0.4800 - val_loss: 2.4185 - val_acc: 0.2433\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3129 - acc: 0.4857 - val_loss: 2.4079 - val_acc: 0.2367\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3129 - acc: 0.4814 - val_loss: 2.4156 - val_acc: 0.2500\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3125 - acc: 0.4829 - val_loss: 2.3891 - val_acc: 0.2400\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3129 - acc: 0.4886 - val_loss: 2.4103 - val_acc: 0.2433\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3133 - acc: 0.4943 - val_loss: 2.3731 - val_acc: 0.2467\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3131 - acc: 0.4857 - val_loss: 2.4138 - val_acc: 0.2433\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3129 - acc: 0.4886 - val_loss: 2.4008 - val_acc: 0.2400\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3125 - acc: 0.4843 - val_loss: 2.4150 - val_acc: 0.2400\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3125 - acc: 0.4871 - val_loss: 2.4128 - val_acc: 0.2433\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3127 - acc: 0.4886 - val_loss: 2.4210 - val_acc: 0.2433\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3130 - acc: 0.4857 - val_loss: 2.3995 - val_acc: 0.2400\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3123 - acc: 0.4886 - val_loss: 2.4048 - val_acc: 0.2500\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 250us/step - loss: 1.3122 - acc: 0.4857 - val_loss: 2.4091 - val_acc: 0.2467\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3108 - acc: 0.4871 - val_loss: 2.4046 - val_acc: 0.2467\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3127 - acc: 0.4857 - val_loss: 2.4006 - val_acc: 0.2400\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3124 - acc: 0.4857 - val_loss: 2.4195 - val_acc: 0.2433\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3116 - acc: 0.4857 - val_loss: 2.4092 - val_acc: 0.2367\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3115 - acc: 0.4829 - val_loss: 2.4155 - val_acc: 0.2500\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3121 - acc: 0.4957 - val_loss: 2.4182 - val_acc: 0.2433\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3122 - acc: 0.4900 - val_loss: 2.4057 - val_acc: 0.2400\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 254us/step - loss: 1.3121 - acc: 0.4886 - val_loss: 2.4051 - val_acc: 0.2400\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3112 - acc: 0.4886 - val_loss: 2.4094 - val_acc: 0.2400\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3112 - acc: 0.4886 - val_loss: 2.4289 - val_acc: 0.2467\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3115 - acc: 0.4857 - val_loss: 2.4183 - val_acc: 0.2467\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3118 - acc: 0.4886 - val_loss: 2.4210 - val_acc: 0.2433\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 1.3116 - acc: 0.4871 - val_loss: 2.4131 - val_acc: 0.2333\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3108 - acc: 0.4929 - val_loss: 2.4329 - val_acc: 0.2500\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3118 - acc: 0.4829 - val_loss: 2.3952 - val_acc: 0.2400\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3113 - acc: 0.4829 - val_loss: 2.4022 - val_acc: 0.2400\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3114 - acc: 0.4843 - val_loss: 2.4021 - val_acc: 0.2400\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3111 - acc: 0.4871 - val_loss: 2.4368 - val_acc: 0.2467\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3110 - acc: 0.4943 - val_loss: 2.4155 - val_acc: 0.2467\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3110 - acc: 0.4971 - val_loss: 2.4288 - val_acc: 0.2467\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3108 - acc: 0.4771 - val_loss: 2.4091 - val_acc: 0.2367\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3113 - acc: 0.4843 - val_loss: 2.4035 - val_acc: 0.2467\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3110 - acc: 0.4886 - val_loss: 2.4235 - val_acc: 0.2500\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3105 - acc: 0.4886 - val_loss: 2.4226 - val_acc: 0.2400\n",
      "Epoch 1880/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.3104 - acc: 0.4957 - val_loss: 2.4233 - val_acc: 0.2467\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3104 - acc: 0.4900 - val_loss: 2.4356 - val_acc: 0.2467\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3106 - acc: 0.4786 - val_loss: 2.4005 - val_acc: 0.2400\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3107 - acc: 0.4843 - val_loss: 2.4133 - val_acc: 0.2433\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.3104 - acc: 0.4914 - val_loss: 2.4044 - val_acc: 0.2400\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3099 - acc: 0.4857 - val_loss: 2.3949 - val_acc: 0.2433\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3106 - acc: 0.4857 - val_loss: 2.4084 - val_acc: 0.2433\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3101 - acc: 0.4886 - val_loss: 2.4150 - val_acc: 0.2400\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3091 - acc: 0.4900 - val_loss: 2.4295 - val_acc: 0.2433\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.3106 - acc: 0.4886 - val_loss: 2.3988 - val_acc: 0.2467\n",
      "Epoch 1890/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 246us/step - loss: 1.3101 - acc: 0.4929 - val_loss: 2.4139 - val_acc: 0.2433\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3102 - acc: 0.4900 - val_loss: 2.4140 - val_acc: 0.2433\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3098 - acc: 0.4886 - val_loss: 2.4108 - val_acc: 0.2433\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3093 - acc: 0.4843 - val_loss: 2.4315 - val_acc: 0.2500\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3097 - acc: 0.4871 - val_loss: 2.4058 - val_acc: 0.2400\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.3099 - acc: 0.4914 - val_loss: 2.4035 - val_acc: 0.2433\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3097 - acc: 0.4871 - val_loss: 2.4351 - val_acc: 0.2467\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3096 - acc: 0.4914 - val_loss: 2.4058 - val_acc: 0.2467\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 264us/step - loss: 1.3097 - acc: 0.4829 - val_loss: 2.3977 - val_acc: 0.2433\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3095 - acc: 0.4871 - val_loss: 2.4071 - val_acc: 0.2500\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3092 - acc: 0.4914 - val_loss: 2.4334 - val_acc: 0.2467\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.3096 - acc: 0.4843 - val_loss: 2.4047 - val_acc: 0.2433\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3094 - acc: 0.4843 - val_loss: 2.4373 - val_acc: 0.2433\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3084 - acc: 0.4886 - val_loss: 2.4099 - val_acc: 0.2433\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.3091 - acc: 0.4929 - val_loss: 2.4354 - val_acc: 0.2500\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3096 - acc: 0.4871 - val_loss: 2.4338 - val_acc: 0.2467\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3101 - acc: 0.4914 - val_loss: 2.4237 - val_acc: 0.2467\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.3085 - acc: 0.4886 - val_loss: 2.4239 - val_acc: 0.2500\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3100 - acc: 0.4843 - val_loss: 2.4324 - val_acc: 0.2467\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3083 - acc: 0.4829 - val_loss: 2.4212 - val_acc: 0.2400\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 247us/step - loss: 1.3090 - acc: 0.4900 - val_loss: 2.4189 - val_acc: 0.2400\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3083 - acc: 0.4986 - val_loss: 2.4106 - val_acc: 0.2367\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3087 - acc: 0.4886 - val_loss: 2.4247 - val_acc: 0.2500\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3084 - acc: 0.4900 - val_loss: 2.4256 - val_acc: 0.2400\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3074 - acc: 0.4871 - val_loss: 2.4325 - val_acc: 0.2500\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3086 - acc: 0.4857 - val_loss: 2.4139 - val_acc: 0.2433\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3084 - acc: 0.4886 - val_loss: 2.4037 - val_acc: 0.2400\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3087 - acc: 0.4871 - val_loss: 2.4191 - val_acc: 0.2500\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3084 - acc: 0.4929 - val_loss: 2.4273 - val_acc: 0.2400\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3081 - acc: 0.4886 - val_loss: 2.4283 - val_acc: 0.2400\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3092 - acc: 0.4900 - val_loss: 2.4255 - val_acc: 0.2433\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3079 - acc: 0.4929 - val_loss: 2.4212 - val_acc: 0.2433\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3073 - acc: 0.4886 - val_loss: 2.4125 - val_acc: 0.2467\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3081 - acc: 0.4957 - val_loss: 2.4275 - val_acc: 0.2433\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3076 - acc: 0.4843 - val_loss: 2.4014 - val_acc: 0.2433\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3076 - acc: 0.4929 - val_loss: 2.4370 - val_acc: 0.2400\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3071 - acc: 0.4871 - val_loss: 2.4143 - val_acc: 0.2433\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3075 - acc: 0.4914 - val_loss: 2.4153 - val_acc: 0.2467\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3070 - acc: 0.4900 - val_loss: 2.4372 - val_acc: 0.2467\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3079 - acc: 0.4929 - val_loss: 2.4287 - val_acc: 0.2433\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3082 - acc: 0.4829 - val_loss: 2.4237 - val_acc: 0.2433\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3078 - acc: 0.4929 - val_loss: 2.4180 - val_acc: 0.2400\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3072 - acc: 0.4886 - val_loss: 2.4321 - val_acc: 0.2467\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3068 - acc: 0.4929 - val_loss: 2.4221 - val_acc: 0.2467\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3075 - acc: 0.4814 - val_loss: 2.4225 - val_acc: 0.2500\n",
      "Epoch 1935/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3069 - acc: 0.4914 - val_loss: 2.4222 - val_acc: 0.2467\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3071 - acc: 0.4886 - val_loss: 2.4454 - val_acc: 0.2467\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3067 - acc: 0.4957 - val_loss: 2.4277 - val_acc: 0.2467\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3071 - acc: 0.4886 - val_loss: 2.4416 - val_acc: 0.2467\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3071 - acc: 0.4929 - val_loss: 2.4221 - val_acc: 0.2467\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3071 - acc: 0.4914 - val_loss: 2.4303 - val_acc: 0.2467\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3066 - acc: 0.4857 - val_loss: 2.4175 - val_acc: 0.2467\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3066 - acc: 0.4914 - val_loss: 2.4359 - val_acc: 0.2467\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3066 - acc: 0.4900 - val_loss: 2.4379 - val_acc: 0.2467\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3065 - acc: 0.4929 - val_loss: 2.4420 - val_acc: 0.2467\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3064 - acc: 0.4929 - val_loss: 2.4206 - val_acc: 0.2400\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3068 - acc: 0.4871 - val_loss: 2.4340 - val_acc: 0.2500\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3073 - acc: 0.4857 - val_loss: 2.4160 - val_acc: 0.2467\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3059 - acc: 0.4914 - val_loss: 2.4331 - val_acc: 0.2467\n",
      "Epoch 1949/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.3074 - acc: 0.4900 - val_loss: 2.4342 - val_acc: 0.2433\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3072 - acc: 0.4914 - val_loss: 2.4247 - val_acc: 0.2400\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3056 - acc: 0.4857 - val_loss: 2.4464 - val_acc: 0.2500\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3065 - acc: 0.4857 - val_loss: 2.4532 - val_acc: 0.2467\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3060 - acc: 0.4871 - val_loss: 2.4223 - val_acc: 0.2467\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3061 - acc: 0.4929 - val_loss: 2.4234 - val_acc: 0.2500\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3063 - acc: 0.4886 - val_loss: 2.4329 - val_acc: 0.2433\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3058 - acc: 0.4914 - val_loss: 2.4355 - val_acc: 0.2467\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3057 - acc: 0.4886 - val_loss: 2.4062 - val_acc: 0.2433\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3062 - acc: 0.4914 - val_loss: 2.4137 - val_acc: 0.2433\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3057 - acc: 0.4943 - val_loss: 2.4154 - val_acc: 0.2433\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3060 - acc: 0.4971 - val_loss: 2.4310 - val_acc: 0.2400\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3058 - acc: 0.4843 - val_loss: 2.4493 - val_acc: 0.2467\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3055 - acc: 0.4943 - val_loss: 2.4254 - val_acc: 0.2467\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3049 - acc: 0.4900 - val_loss: 2.4349 - val_acc: 0.2467\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3056 - acc: 0.4886 - val_loss: 2.4318 - val_acc: 0.2400\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3054 - acc: 0.4829 - val_loss: 2.4397 - val_acc: 0.2467\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3055 - acc: 0.4900 - val_loss: 2.4368 - val_acc: 0.2433\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3053 - acc: 0.4929 - val_loss: 2.4321 - val_acc: 0.2433\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3047 - acc: 0.4886 - val_loss: 2.4472 - val_acc: 0.2500\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3059 - acc: 0.4943 - val_loss: 2.4473 - val_acc: 0.2467\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3051 - acc: 0.4857 - val_loss: 2.4414 - val_acc: 0.2467\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3051 - acc: 0.4914 - val_loss: 2.4414 - val_acc: 0.2467\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3040 - acc: 0.4900 - val_loss: 2.4355 - val_acc: 0.2433\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3055 - acc: 0.4971 - val_loss: 2.4412 - val_acc: 0.2467\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3048 - acc: 0.4929 - val_loss: 2.4142 - val_acc: 0.2433\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3050 - acc: 0.4929 - val_loss: 2.4300 - val_acc: 0.2500\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3051 - acc: 0.4857 - val_loss: 2.4399 - val_acc: 0.2467\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3049 - acc: 0.4914 - val_loss: 2.4382 - val_acc: 0.2433\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3052 - acc: 0.4943 - val_loss: 2.4334 - val_acc: 0.2433\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3040 - acc: 0.4943 - val_loss: 2.4545 - val_acc: 0.2467\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3033 - acc: 0.4900 - val_loss: 2.4265 - val_acc: 0.2467\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3044 - acc: 0.4900 - val_loss: 2.4315 - val_acc: 0.2433\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3043 - acc: 0.4900 - val_loss: 2.4241 - val_acc: 0.2500\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3045 - acc: 0.4886 - val_loss: 2.4310 - val_acc: 0.2467\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3045 - acc: 0.4943 - val_loss: 2.4339 - val_acc: 0.2433\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3039 - acc: 0.4957 - val_loss: 2.4507 - val_acc: 0.2467\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3048 - acc: 0.4886 - val_loss: 2.4420 - val_acc: 0.2433\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3042 - acc: 0.4957 - val_loss: 2.4257 - val_acc: 0.2500\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3054 - acc: 0.4886 - val_loss: 2.4584 - val_acc: 0.2467\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3043 - acc: 0.4986 - val_loss: 2.4388 - val_acc: 0.2433\n",
      "Epoch 1990/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3037 - acc: 0.4857 - val_loss: 2.4334 - val_acc: 0.2433\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3039 - acc: 0.4957 - val_loss: 2.4355 - val_acc: 0.2433\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3033 - acc: 0.4871 - val_loss: 2.4590 - val_acc: 0.2533\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3037 - acc: 0.4914 - val_loss: 2.4107 - val_acc: 0.2500\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3043 - acc: 0.4929 - val_loss: 2.4375 - val_acc: 0.2467\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3036 - acc: 0.4886 - val_loss: 2.4488 - val_acc: 0.2467\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3034 - acc: 0.4914 - val_loss: 2.4536 - val_acc: 0.2467\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3035 - acc: 0.4914 - val_loss: 2.4213 - val_acc: 0.2433\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3031 - acc: 0.4914 - val_loss: 2.4706 - val_acc: 0.2433\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3040 - acc: 0.4900 - val_loss: 2.4595 - val_acc: 0.2467\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3034 - acc: 0.4914 - val_loss: 2.4448 - val_acc: 0.2467\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3033 - acc: 0.4900 - val_loss: 2.4129 - val_acc: 0.2433\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3039 - acc: 0.4914 - val_loss: 2.4414 - val_acc: 0.2433\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3038 - acc: 0.4886 - val_loss: 2.4631 - val_acc: 0.2433\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3034 - acc: 0.4857 - val_loss: 2.4355 - val_acc: 0.2433\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3029 - acc: 0.4900 - val_loss: 2.4522 - val_acc: 0.2467\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3026 - acc: 0.4871 - val_loss: 2.4582 - val_acc: 0.2467\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3022 - acc: 0.4943 - val_loss: 2.4361 - val_acc: 0.2400\n",
      "Epoch 2008/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 230us/step - loss: 1.3024 - acc: 0.4914 - val_loss: 2.4697 - val_acc: 0.2500\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3035 - acc: 0.4929 - val_loss: 2.4399 - val_acc: 0.2400\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3025 - acc: 0.4900 - val_loss: 2.4412 - val_acc: 0.2467\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3033 - acc: 0.4943 - val_loss: 2.4548 - val_acc: 0.2500\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.3027 - acc: 0.4886 - val_loss: 2.4270 - val_acc: 0.2467\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3023 - acc: 0.4929 - val_loss: 2.4457 - val_acc: 0.2433\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3021 - acc: 0.4971 - val_loss: 2.4880 - val_acc: 0.2433\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3021 - acc: 0.4929 - val_loss: 2.4356 - val_acc: 0.2467\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3024 - acc: 0.4900 - val_loss: 2.4682 - val_acc: 0.2467\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3022 - acc: 0.4957 - val_loss: 2.4237 - val_acc: 0.2367\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3023 - acc: 0.4900 - val_loss: 2.4516 - val_acc: 0.2467\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3026 - acc: 0.4871 - val_loss: 2.4235 - val_acc: 0.2433\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3025 - acc: 0.4943 - val_loss: 2.4574 - val_acc: 0.2467\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3021 - acc: 0.4986 - val_loss: 2.4570 - val_acc: 0.2467\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3027 - acc: 0.4929 - val_loss: 2.4428 - val_acc: 0.2433\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3020 - acc: 0.4943 - val_loss: 2.4316 - val_acc: 0.2467\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3024 - acc: 0.4914 - val_loss: 2.4700 - val_acc: 0.2433\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3024 - acc: 0.4943 - val_loss: 2.4530 - val_acc: 0.2467\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3018 - acc: 0.4971 - val_loss: 2.4323 - val_acc: 0.2433\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3022 - acc: 0.4971 - val_loss: 2.4394 - val_acc: 0.2400\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3016 - acc: 0.4929 - val_loss: 2.4650 - val_acc: 0.2467\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3013 - acc: 0.4971 - val_loss: 2.4427 - val_acc: 0.2400\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3011 - acc: 0.4957 - val_loss: 2.4729 - val_acc: 0.2433\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3013 - acc: 0.4914 - val_loss: 2.4201 - val_acc: 0.2433\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3018 - acc: 0.4929 - val_loss: 2.4481 - val_acc: 0.2467\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3014 - acc: 0.4957 - val_loss: 2.4711 - val_acc: 0.2467\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3018 - acc: 0.4843 - val_loss: 2.4346 - val_acc: 0.2467\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3012 - acc: 0.4943 - val_loss: 2.4309 - val_acc: 0.2433\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3017 - acc: 0.4900 - val_loss: 2.4425 - val_acc: 0.2500\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3005 - acc: 0.4957 - val_loss: 2.4418 - val_acc: 0.2467\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3009 - acc: 0.4914 - val_loss: 2.4413 - val_acc: 0.2433\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3018 - acc: 0.4986 - val_loss: 2.4638 - val_acc: 0.2500\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3015 - acc: 0.4929 - val_loss: 2.4566 - val_acc: 0.2467\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3005 - acc: 0.4943 - val_loss: 2.4593 - val_acc: 0.2467\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3011 - acc: 0.4957 - val_loss: 2.4702 - val_acc: 0.2467\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.3007 - acc: 0.4914 - val_loss: 2.4669 - val_acc: 0.2467\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3010 - acc: 0.4914 - val_loss: 2.4546 - val_acc: 0.2500\n",
      "Epoch 2045/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3015 - acc: 0.4957 - val_loss: 2.4763 - val_acc: 0.2433\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.3007 - acc: 0.4971 - val_loss: 2.4368 - val_acc: 0.2467\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.3000 - acc: 0.4929 - val_loss: 2.4513 - val_acc: 0.2500\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.3000 - acc: 0.4943 - val_loss: 2.4341 - val_acc: 0.2433\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.3026 - acc: 0.4929 - val_loss: 2.4677 - val_acc: 0.2467\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.3009 - acc: 0.4900 - val_loss: 2.4662 - val_acc: 0.2433\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.3010 - acc: 0.4929 - val_loss: 2.4504 - val_acc: 0.2400\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.3012 - acc: 0.4943 - val_loss: 2.4460 - val_acc: 0.2433\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3008 - acc: 0.4900 - val_loss: 2.4432 - val_acc: 0.2400\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.3000 - acc: 0.4971 - val_loss: 2.4532 - val_acc: 0.2433\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.3011 - acc: 0.4943 - val_loss: 2.4464 - val_acc: 0.2400\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2995 - acc: 0.4986 - val_loss: 2.4664 - val_acc: 0.2433\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3007 - acc: 0.4900 - val_loss: 2.4588 - val_acc: 0.2467\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2994 - acc: 0.4971 - val_loss: 2.4696 - val_acc: 0.2467\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.3001 - acc: 0.4929 - val_loss: 2.4557 - val_acc: 0.2467\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2999 - acc: 0.4929 - val_loss: 2.4574 - val_acc: 0.2467\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2998 - acc: 0.4900 - val_loss: 2.4541 - val_acc: 0.2467\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.3000 - acc: 0.4914 - val_loss: 2.4588 - val_acc: 0.2467\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2993 - acc: 0.4943 - val_loss: 2.4571 - val_acc: 0.2467\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2996 - acc: 0.4886 - val_loss: 2.4583 - val_acc: 0.2467\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2999 - acc: 0.4943 - val_loss: 2.4537 - val_acc: 0.2467\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2999 - acc: 0.4971 - val_loss: 2.4695 - val_acc: 0.2433\n",
      "Epoch 2067/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 224us/step - loss: 1.2997 - acc: 0.4943 - val_loss: 2.4598 - val_acc: 0.2500\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2996 - acc: 0.4929 - val_loss: 2.4586 - val_acc: 0.2433\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2989 - acc: 0.4986 - val_loss: 2.5020 - val_acc: 0.2467\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2995 - acc: 0.4929 - val_loss: 2.4645 - val_acc: 0.2467\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2994 - acc: 0.4929 - val_loss: 2.4728 - val_acc: 0.2433\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2995 - acc: 0.4914 - val_loss: 2.4778 - val_acc: 0.2433\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2994 - acc: 0.4857 - val_loss: 2.4627 - val_acc: 0.2500\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2990 - acc: 0.4971 - val_loss: 2.4575 - val_acc: 0.2467\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2994 - acc: 0.4943 - val_loss: 2.4467 - val_acc: 0.2467\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2993 - acc: 0.4900 - val_loss: 2.4536 - val_acc: 0.2433\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2988 - acc: 0.4929 - val_loss: 2.4697 - val_acc: 0.2467\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2990 - acc: 0.4914 - val_loss: 2.4591 - val_acc: 0.2400\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2988 - acc: 0.4929 - val_loss: 2.4775 - val_acc: 0.2400\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2992 - acc: 0.4943 - val_loss: 2.4716 - val_acc: 0.2433\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2999 - acc: 0.4957 - val_loss: 2.4821 - val_acc: 0.2467\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2988 - acc: 0.4857 - val_loss: 2.4373 - val_acc: 0.2367\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2994 - acc: 0.4943 - val_loss: 2.4561 - val_acc: 0.2467\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2980 - acc: 0.4943 - val_loss: 2.4495 - val_acc: 0.2533\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2987 - acc: 0.4929 - val_loss: 2.4362 - val_acc: 0.2400\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2982 - acc: 0.4914 - val_loss: 2.4558 - val_acc: 0.2467\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2988 - acc: 0.4971 - val_loss: 2.4858 - val_acc: 0.2500\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2989 - acc: 0.4943 - val_loss: 2.4638 - val_acc: 0.2433\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2991 - acc: 0.4914 - val_loss: 2.4684 - val_acc: 0.2467\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2979 - acc: 0.4943 - val_loss: 2.4967 - val_acc: 0.2433\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2980 - acc: 0.4929 - val_loss: 2.4618 - val_acc: 0.2467\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2981 - acc: 0.4943 - val_loss: 2.4775 - val_acc: 0.2467\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2984 - acc: 0.4886 - val_loss: 2.4711 - val_acc: 0.2467\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2987 - acc: 0.4943 - val_loss: 2.4638 - val_acc: 0.2433\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2974 - acc: 0.4971 - val_loss: 2.4844 - val_acc: 0.2467\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2979 - acc: 0.4914 - val_loss: 2.4701 - val_acc: 0.2467\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2974 - acc: 0.4929 - val_loss: 2.4601 - val_acc: 0.2467\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2968 - acc: 0.4943 - val_loss: 2.4521 - val_acc: 0.2433\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2982 - acc: 0.4929 - val_loss: 2.4659 - val_acc: 0.2467\n",
      "Epoch 2100/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2977 - acc: 0.4943 - val_loss: 2.4591 - val_acc: 0.2433\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2982 - acc: 0.5000 - val_loss: 2.4683 - val_acc: 0.2467\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2982 - acc: 0.4957 - val_loss: 2.4702 - val_acc: 0.2433\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2974 - acc: 0.4957 - val_loss: 2.4748 - val_acc: 0.2467\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2977 - acc: 0.4971 - val_loss: 2.4488 - val_acc: 0.2467\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2971 - acc: 0.4900 - val_loss: 2.4644 - val_acc: 0.2500\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2978 - acc: 0.4957 - val_loss: 2.4472 - val_acc: 0.2467\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2973 - acc: 0.4900 - val_loss: 2.4586 - val_acc: 0.2433\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2976 - acc: 0.4943 - val_loss: 2.4720 - val_acc: 0.2467\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2976 - acc: 0.4914 - val_loss: 2.4693 - val_acc: 0.2500\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2986 - acc: 0.4971 - val_loss: 2.4633 - val_acc: 0.2433\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2983 - acc: 0.4900 - val_loss: 2.4566 - val_acc: 0.2433\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2969 - acc: 0.4914 - val_loss: 2.4908 - val_acc: 0.2433\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2976 - acc: 0.4943 - val_loss: 2.4663 - val_acc: 0.2467\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2966 - acc: 0.4957 - val_loss: 2.4591 - val_acc: 0.2433\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2973 - acc: 0.4957 - val_loss: 2.4842 - val_acc: 0.2400\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2970 - acc: 0.4986 - val_loss: 2.4754 - val_acc: 0.2467\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2973 - acc: 0.4957 - val_loss: 2.4893 - val_acc: 0.2467\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2965 - acc: 0.4943 - val_loss: 2.4688 - val_acc: 0.2467\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2968 - acc: 0.4929 - val_loss: 2.4716 - val_acc: 0.2467\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2965 - acc: 0.4957 - val_loss: 2.4738 - val_acc: 0.2467\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2965 - acc: 0.4986 - val_loss: 2.4942 - val_acc: 0.2400\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2968 - acc: 0.4971 - val_loss: 2.4842 - val_acc: 0.2433\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2964 - acc: 0.4971 - val_loss: 2.4618 - val_acc: 0.2433\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2967 - acc: 0.4957 - val_loss: 2.4731 - val_acc: 0.2467\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2961 - acc: 0.4986 - val_loss: 2.4702 - val_acc: 0.2433\n",
      "Epoch 2126/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 238us/step - loss: 1.2971 - acc: 0.4943 - val_loss: 2.4728 - val_acc: 0.2433\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2966 - acc: 0.4914 - val_loss: 2.4646 - val_acc: 0.2400\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2964 - acc: 0.4971 - val_loss: 2.4859 - val_acc: 0.2433\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2964 - acc: 0.4871 - val_loss: 2.4504 - val_acc: 0.2433\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2965 - acc: 0.5000 - val_loss: 2.4730 - val_acc: 0.2400\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2964 - acc: 0.4914 - val_loss: 2.4685 - val_acc: 0.2467\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2969 - acc: 0.4943 - val_loss: 2.4687 - val_acc: 0.2400\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2960 - acc: 0.4943 - val_loss: 2.4750 - val_acc: 0.2500\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2963 - acc: 0.5000 - val_loss: 2.4698 - val_acc: 0.2433\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2956 - acc: 0.4943 - val_loss: 2.4724 - val_acc: 0.2467\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2964 - acc: 0.4914 - val_loss: 2.4553 - val_acc: 0.2433\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.2958 - acc: 0.4986 - val_loss: 2.4787 - val_acc: 0.2433\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2973 - acc: 0.4914 - val_loss: 2.4830 - val_acc: 0.2467\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2959 - acc: 0.5014 - val_loss: 2.4669 - val_acc: 0.2467\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2955 - acc: 0.4914 - val_loss: 2.4806 - val_acc: 0.2433\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2966 - acc: 0.4943 - val_loss: 2.4784 - val_acc: 0.2467\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2956 - acc: 0.4943 - val_loss: 2.4730 - val_acc: 0.2467\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2959 - acc: 0.4957 - val_loss: 2.4895 - val_acc: 0.2433\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2957 - acc: 0.4957 - val_loss: 2.4760 - val_acc: 0.2467\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2950 - acc: 0.4914 - val_loss: 2.4622 - val_acc: 0.2500\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2946 - acc: 0.4914 - val_loss: 2.4442 - val_acc: 0.2467\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2953 - acc: 0.5014 - val_loss: 2.4806 - val_acc: 0.2433\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2964 - acc: 0.4857 - val_loss: 2.4724 - val_acc: 0.2467\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2947 - acc: 0.5000 - val_loss: 2.4439 - val_acc: 0.2467\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2951 - acc: 0.4929 - val_loss: 2.4613 - val_acc: 0.2533\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2954 - acc: 0.4929 - val_loss: 2.4940 - val_acc: 0.2367\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2947 - acc: 0.4914 - val_loss: 2.4929 - val_acc: 0.2467\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2953 - acc: 0.4943 - val_loss: 2.4740 - val_acc: 0.2467\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2949 - acc: 0.4957 - val_loss: 2.5027 - val_acc: 0.2367\n",
      "Epoch 2155/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2951 - acc: 0.4971 - val_loss: 2.4955 - val_acc: 0.2433\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2943 - acc: 0.4986 - val_loss: 2.5013 - val_acc: 0.2433\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2946 - acc: 0.4871 - val_loss: 2.4579 - val_acc: 0.2467\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2944 - acc: 0.4971 - val_loss: 2.5052 - val_acc: 0.2433\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2942 - acc: 0.4971 - val_loss: 2.4643 - val_acc: 0.2467\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2951 - acc: 0.4943 - val_loss: 2.4950 - val_acc: 0.2467\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2946 - acc: 0.5014 - val_loss: 2.4819 - val_acc: 0.2467\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2941 - acc: 0.4929 - val_loss: 2.4731 - val_acc: 0.2400\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2946 - acc: 0.4914 - val_loss: 2.4624 - val_acc: 0.2433\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2953 - acc: 0.4986 - val_loss: 2.4820 - val_acc: 0.2467\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2945 - acc: 0.4914 - val_loss: 2.4734 - val_acc: 0.2500\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2949 - acc: 0.4957 - val_loss: 2.4795 - val_acc: 0.2467\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2942 - acc: 0.4943 - val_loss: 2.4757 - val_acc: 0.2467\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2945 - acc: 0.5014 - val_loss: 2.4873 - val_acc: 0.2433\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2940 - acc: 0.4957 - val_loss: 2.4898 - val_acc: 0.2500\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2939 - acc: 0.5000 - val_loss: 2.4902 - val_acc: 0.2433\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2935 - acc: 0.5000 - val_loss: 2.4644 - val_acc: 0.2533\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2937 - acc: 0.4971 - val_loss: 2.5011 - val_acc: 0.2467\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2931 - acc: 0.4971 - val_loss: 2.4907 - val_acc: 0.2467\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2940 - acc: 0.5014 - val_loss: 2.4799 - val_acc: 0.2400\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2931 - acc: 0.4914 - val_loss: 2.4586 - val_acc: 0.2500\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2936 - acc: 0.4957 - val_loss: 2.4551 - val_acc: 0.2467\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2940 - acc: 0.4957 - val_loss: 2.4856 - val_acc: 0.2533\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2939 - acc: 0.4957 - val_loss: 2.4820 - val_acc: 0.2467\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2930 - acc: 0.4986 - val_loss: 2.4764 - val_acc: 0.2467\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2944 - acc: 0.4886 - val_loss: 2.4770 - val_acc: 0.2467\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2932 - acc: 0.5000 - val_loss: 2.4825 - val_acc: 0.2367\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2933 - acc: 0.4971 - val_loss: 2.4893 - val_acc: 0.2433\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2931 - acc: 0.4971 - val_loss: 2.5076 - val_acc: 0.2433\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2940 - acc: 0.4971 - val_loss: 2.4834 - val_acc: 0.2467\n",
      "Epoch 2185/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 231us/step - loss: 1.2925 - acc: 0.4943 - val_loss: 2.4792 - val_acc: 0.2433\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2939 - acc: 0.4971 - val_loss: 2.4842 - val_acc: 0.2533\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2928 - acc: 0.5029 - val_loss: 2.4801 - val_acc: 0.2467\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2930 - acc: 0.5029 - val_loss: 2.4979 - val_acc: 0.2467\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2932 - acc: 0.4929 - val_loss: 2.5187 - val_acc: 0.2433\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2931 - acc: 0.4943 - val_loss: 2.4896 - val_acc: 0.2433\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2926 - acc: 0.4914 - val_loss: 2.4865 - val_acc: 0.2433\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2927 - acc: 0.4957 - val_loss: 2.4688 - val_acc: 0.2400\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2924 - acc: 0.4957 - val_loss: 2.4840 - val_acc: 0.2400\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2932 - acc: 0.4957 - val_loss: 2.4982 - val_acc: 0.2433\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2919 - acc: 0.4929 - val_loss: 2.4933 - val_acc: 0.2400\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2930 - acc: 0.4971 - val_loss: 2.4987 - val_acc: 0.2467\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2926 - acc: 0.4971 - val_loss: 2.4936 - val_acc: 0.2500\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2925 - acc: 0.4943 - val_loss: 2.4830 - val_acc: 0.2433\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2933 - acc: 0.5000 - val_loss: 2.4951 - val_acc: 0.2433\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2927 - acc: 0.4943 - val_loss: 2.4849 - val_acc: 0.2433\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.2920 - acc: 0.5000 - val_loss: 2.5102 - val_acc: 0.2467\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2906 - acc: 0.4957 - val_loss: 2.4914 - val_acc: 0.2467\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2926 - acc: 0.4914 - val_loss: 2.4948 - val_acc: 0.2433\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2917 - acc: 0.4986 - val_loss: 2.4659 - val_acc: 0.2367\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2916 - acc: 0.4971 - val_loss: 2.5016 - val_acc: 0.2433\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 1.2922 - acc: 0.4957 - val_loss: 2.4814 - val_acc: 0.2467\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2919 - acc: 0.4957 - val_loss: 2.4978 - val_acc: 0.2433\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2918 - acc: 0.4971 - val_loss: 2.4646 - val_acc: 0.2433\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2918 - acc: 0.4957 - val_loss: 2.4498 - val_acc: 0.2567\n",
      "Epoch 2210/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2918 - acc: 0.4929 - val_loss: 2.4894 - val_acc: 0.2467\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2919 - acc: 0.4914 - val_loss: 2.4954 - val_acc: 0.2433\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2914 - acc: 0.5000 - val_loss: 2.4992 - val_acc: 0.2533\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2914 - acc: 0.4957 - val_loss: 2.4828 - val_acc: 0.2367\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2906 - acc: 0.4957 - val_loss: 2.4974 - val_acc: 0.2433\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2916 - acc: 0.4971 - val_loss: 2.4855 - val_acc: 0.2433\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2918 - acc: 0.4943 - val_loss: 2.4810 - val_acc: 0.2433\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2913 - acc: 0.4957 - val_loss: 2.4988 - val_acc: 0.2467\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2907 - acc: 0.5043 - val_loss: 2.5018 - val_acc: 0.2367\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2913 - acc: 0.4986 - val_loss: 2.4874 - val_acc: 0.2433\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2899 - acc: 0.4971 - val_loss: 2.4845 - val_acc: 0.2467\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2905 - acc: 0.4971 - val_loss: 2.4860 - val_acc: 0.2500\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2925 - acc: 0.4957 - val_loss: 2.4694 - val_acc: 0.2467\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2914 - acc: 0.4957 - val_loss: 2.4952 - val_acc: 0.2500\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2906 - acc: 0.4971 - val_loss: 2.5076 - val_acc: 0.2533\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.2901 - acc: 0.4971 - val_loss: 2.4805 - val_acc: 0.2467\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2907 - acc: 0.5029 - val_loss: 2.5101 - val_acc: 0.2433\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2906 - acc: 0.4971 - val_loss: 2.4846 - val_acc: 0.2433\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2907 - acc: 0.4971 - val_loss: 2.4965 - val_acc: 0.2500\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2905 - acc: 0.5029 - val_loss: 2.4727 - val_acc: 0.2400\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2907 - acc: 0.5029 - val_loss: 2.4847 - val_acc: 0.2433\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2901 - acc: 0.4986 - val_loss: 2.4811 - val_acc: 0.2500\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2904 - acc: 0.4929 - val_loss: 2.4944 - val_acc: 0.2433\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2904 - acc: 0.4929 - val_loss: 2.4967 - val_acc: 0.2467\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2905 - acc: 0.5029 - val_loss: 2.4753 - val_acc: 0.2400\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2899 - acc: 0.5000 - val_loss: 2.5041 - val_acc: 0.2467\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2897 - acc: 0.4957 - val_loss: 2.4764 - val_acc: 0.2400\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2900 - acc: 0.5000 - val_loss: 2.5207 - val_acc: 0.2367\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2901 - acc: 0.4971 - val_loss: 2.5284 - val_acc: 0.2400\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2896 - acc: 0.4957 - val_loss: 2.4835 - val_acc: 0.2567\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.2901 - acc: 0.5014 - val_loss: 2.5107 - val_acc: 0.2433\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2902 - acc: 0.4943 - val_loss: 2.4874 - val_acc: 0.2433\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2898 - acc: 0.4943 - val_loss: 2.4960 - val_acc: 0.2467\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2899 - acc: 0.4957 - val_loss: 2.4956 - val_acc: 0.2467\n",
      "Epoch 2244/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 233us/step - loss: 1.2898 - acc: 0.4929 - val_loss: 2.4856 - val_acc: 0.2433\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2889 - acc: 0.4957 - val_loss: 2.5285 - val_acc: 0.2367\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2892 - acc: 0.5014 - val_loss: 2.5006 - val_acc: 0.2433\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2894 - acc: 0.4943 - val_loss: 2.4918 - val_acc: 0.2467\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2895 - acc: 0.4943 - val_loss: 2.5454 - val_acc: 0.2367\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2902 - acc: 0.4986 - val_loss: 2.4929 - val_acc: 0.2533\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2889 - acc: 0.4986 - val_loss: 2.4915 - val_acc: 0.2433\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2901 - acc: 0.4929 - val_loss: 2.4938 - val_acc: 0.2467\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2891 - acc: 0.4943 - val_loss: 2.4805 - val_acc: 0.2400\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2884 - acc: 0.5000 - val_loss: 2.5163 - val_acc: 0.2467\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2896 - acc: 0.4986 - val_loss: 2.5045 - val_acc: 0.2500\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2886 - acc: 0.4986 - val_loss: 2.5106 - val_acc: 0.2400\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2892 - acc: 0.5000 - val_loss: 2.4942 - val_acc: 0.2400\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2891 - acc: 0.5014 - val_loss: 2.5228 - val_acc: 0.2367\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2887 - acc: 0.5029 - val_loss: 2.4640 - val_acc: 0.2367\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2878 - acc: 0.5000 - val_loss: 2.5233 - val_acc: 0.2433\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2888 - acc: 0.4971 - val_loss: 2.5093 - val_acc: 0.2500\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2881 - acc: 0.4986 - val_loss: 2.4975 - val_acc: 0.2433\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2886 - acc: 0.5014 - val_loss: 2.4975 - val_acc: 0.2433\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2884 - acc: 0.4971 - val_loss: 2.5174 - val_acc: 0.2367\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2883 - acc: 0.5000 - val_loss: 2.5354 - val_acc: 0.2367\n",
      "Epoch 2265/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2889 - acc: 0.4971 - val_loss: 2.4975 - val_acc: 0.2467\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2881 - acc: 0.5029 - val_loss: 2.5311 - val_acc: 0.2367\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2889 - acc: 0.4914 - val_loss: 2.4827 - val_acc: 0.2433\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2882 - acc: 0.4971 - val_loss: 2.4839 - val_acc: 0.2433\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2870 - acc: 0.5000 - val_loss: 2.4903 - val_acc: 0.2500\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2887 - acc: 0.5029 - val_loss: 2.5025 - val_acc: 0.2500\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2881 - acc: 0.4929 - val_loss: 2.5208 - val_acc: 0.2433\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2874 - acc: 0.4943 - val_loss: 2.5302 - val_acc: 0.2433\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2877 - acc: 0.4957 - val_loss: 2.4916 - val_acc: 0.2433\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2883 - acc: 0.4957 - val_loss: 2.5094 - val_acc: 0.2533\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2876 - acc: 0.5043 - val_loss: 2.5081 - val_acc: 0.2433\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.2881 - acc: 0.4986 - val_loss: 2.5084 - val_acc: 0.2467\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2878 - acc: 0.4986 - val_loss: 2.5141 - val_acc: 0.2400\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2876 - acc: 0.4900 - val_loss: 2.5023 - val_acc: 0.2467\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2875 - acc: 0.4957 - val_loss: 2.5110 - val_acc: 0.2433\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2873 - acc: 0.4986 - val_loss: 2.5239 - val_acc: 0.2367\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2859 - acc: 0.5014 - val_loss: 2.5024 - val_acc: 0.2500\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2874 - acc: 0.4957 - val_loss: 2.5052 - val_acc: 0.2467\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2865 - acc: 0.5000 - val_loss: 2.4763 - val_acc: 0.2500\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2883 - acc: 0.5014 - val_loss: 2.5034 - val_acc: 0.2533\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2885 - acc: 0.4929 - val_loss: 2.5211 - val_acc: 0.2400\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2873 - acc: 0.4957 - val_loss: 2.5091 - val_acc: 0.2433\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2874 - acc: 0.4971 - val_loss: 2.4948 - val_acc: 0.2400\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2872 - acc: 0.5014 - val_loss: 2.4996 - val_acc: 0.2467\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2879 - acc: 0.4986 - val_loss: 2.5237 - val_acc: 0.2400\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2873 - acc: 0.4929 - val_loss: 2.5111 - val_acc: 0.2367\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2872 - acc: 0.4986 - val_loss: 2.5120 - val_acc: 0.2467\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2862 - acc: 0.4986 - val_loss: 2.5151 - val_acc: 0.2367\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2867 - acc: 0.5014 - val_loss: 2.5169 - val_acc: 0.2433\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2868 - acc: 0.5014 - val_loss: 2.5170 - val_acc: 0.2500\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2870 - acc: 0.4929 - val_loss: 2.5139 - val_acc: 0.2400\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2868 - acc: 0.4957 - val_loss: 2.4899 - val_acc: 0.2467\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2859 - acc: 0.4971 - val_loss: 2.5119 - val_acc: 0.2433\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2863 - acc: 0.5000 - val_loss: 2.5286 - val_acc: 0.2467\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2869 - acc: 0.5057 - val_loss: 2.5197 - val_acc: 0.2500\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2857 - acc: 0.5000 - val_loss: 2.5016 - val_acc: 0.2367\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2869 - acc: 0.4929 - val_loss: 2.5048 - val_acc: 0.2433\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2861 - acc: 0.4971 - val_loss: 2.5325 - val_acc: 0.2433\n",
      "Epoch 2303/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.2860 - acc: 0.4986 - val_loss: 2.4974 - val_acc: 0.2367\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2866 - acc: 0.5000 - val_loss: 2.5155 - val_acc: 0.2533\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2859 - acc: 0.4943 - val_loss: 2.5470 - val_acc: 0.2433\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2861 - acc: 0.5000 - val_loss: 2.5033 - val_acc: 0.2500\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2865 - acc: 0.4986 - val_loss: 2.4956 - val_acc: 0.2433\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.2861 - acc: 0.5014 - val_loss: 2.4983 - val_acc: 0.2500\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.2861 - acc: 0.4986 - val_loss: 2.5253 - val_acc: 0.2467\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.2855 - acc: 0.4986 - val_loss: 2.5230 - val_acc: 0.2400\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2857 - acc: 0.4914 - val_loss: 2.5156 - val_acc: 0.2400\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.2859 - acc: 0.4971 - val_loss: 2.5293 - val_acc: 0.2367\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.2853 - acc: 0.4971 - val_loss: 2.5015 - val_acc: 0.2500\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2860 - acc: 0.5014 - val_loss: 2.5178 - val_acc: 0.2400\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2856 - acc: 0.5029 - val_loss: 2.5044 - val_acc: 0.2433\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2854 - acc: 0.4957 - val_loss: 2.5340 - val_acc: 0.2367\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2839 - acc: 0.5029 - val_loss: 2.5207 - val_acc: 0.2500\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2856 - acc: 0.5014 - val_loss: 2.5164 - val_acc: 0.2433\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2856 - acc: 0.4971 - val_loss: 2.4992 - val_acc: 0.2400\n",
      "Epoch 2320/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2855 - acc: 0.4943 - val_loss: 2.5122 - val_acc: 0.2533\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2851 - acc: 0.5000 - val_loss: 2.5233 - val_acc: 0.2400\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2853 - acc: 0.5000 - val_loss: 2.5223 - val_acc: 0.2400\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2848 - acc: 0.5000 - val_loss: 2.4925 - val_acc: 0.2533\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2852 - acc: 0.5057 - val_loss: 2.5366 - val_acc: 0.2400\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2857 - acc: 0.4943 - val_loss: 2.5151 - val_acc: 0.2400\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2853 - acc: 0.5000 - val_loss: 2.5194 - val_acc: 0.2400\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2851 - acc: 0.5029 - val_loss: 2.5144 - val_acc: 0.2367\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2852 - acc: 0.4957 - val_loss: 2.5344 - val_acc: 0.2300\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2851 - acc: 0.4986 - val_loss: 2.5394 - val_acc: 0.2367\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2848 - acc: 0.5043 - val_loss: 2.5082 - val_acc: 0.2500\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2839 - acc: 0.5014 - val_loss: 2.5174 - val_acc: 0.2467\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2855 - acc: 0.4957 - val_loss: 2.5170 - val_acc: 0.2533\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2847 - acc: 0.5029 - val_loss: 2.5261 - val_acc: 0.2400\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2845 - acc: 0.4971 - val_loss: 2.5216 - val_acc: 0.2433\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2836 - acc: 0.5014 - val_loss: 2.5232 - val_acc: 0.2400\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2843 - acc: 0.4971 - val_loss: 2.5308 - val_acc: 0.2500\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2851 - acc: 0.5000 - val_loss: 2.5247 - val_acc: 0.2433\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2848 - acc: 0.4986 - val_loss: 2.5266 - val_acc: 0.2433\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.2840 - acc: 0.4986 - val_loss: 2.5037 - val_acc: 0.2467\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.2839 - acc: 0.4986 - val_loss: 2.5496 - val_acc: 0.2433\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2843 - acc: 0.4957 - val_loss: 2.5270 - val_acc: 0.2500\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2840 - acc: 0.5000 - val_loss: 2.5122 - val_acc: 0.2533\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2837 - acc: 0.5029 - val_loss: 2.5317 - val_acc: 0.2500\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2835 - acc: 0.4971 - val_loss: 2.5178 - val_acc: 0.2500\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2838 - acc: 0.5014 - val_loss: 2.5237 - val_acc: 0.2500\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2838 - acc: 0.5014 - val_loss: 2.5401 - val_acc: 0.2467\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2843 - acc: 0.5000 - val_loss: 2.5207 - val_acc: 0.2467\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2832 - acc: 0.5000 - val_loss: 2.5103 - val_acc: 0.2433\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2831 - acc: 0.4957 - val_loss: 2.5211 - val_acc: 0.2500\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2829 - acc: 0.4943 - val_loss: 2.5334 - val_acc: 0.2567\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2838 - acc: 0.5000 - val_loss: 2.5301 - val_acc: 0.2433\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2846 - acc: 0.4971 - val_loss: 2.5331 - val_acc: 0.2467\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2831 - acc: 0.5029 - val_loss: 2.5142 - val_acc: 0.2467\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2830 - acc: 0.5000 - val_loss: 2.5438 - val_acc: 0.2300\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2830 - acc: 0.5014 - val_loss: 2.5356 - val_acc: 0.2367\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2827 - acc: 0.4957 - val_loss: 2.5203 - val_acc: 0.2400\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2832 - acc: 0.4957 - val_loss: 2.5080 - val_acc: 0.2433\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2840 - acc: 0.4971 - val_loss: 2.5447 - val_acc: 0.2400\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2829 - acc: 0.4971 - val_loss: 2.5198 - val_acc: 0.2500\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2830 - acc: 0.4957 - val_loss: 2.5390 - val_acc: 0.2400\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2833 - acc: 0.5014 - val_loss: 2.5303 - val_acc: 0.2367\n",
      "Epoch 2362/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 224us/step - loss: 1.2829 - acc: 0.4957 - val_loss: 2.5158 - val_acc: 0.2467\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2824 - acc: 0.4986 - val_loss: 2.5172 - val_acc: 0.2433\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2826 - acc: 0.5000 - val_loss: 2.5263 - val_acc: 0.2367\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2823 - acc: 0.5014 - val_loss: 2.5481 - val_acc: 0.2467\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2825 - acc: 0.5071 - val_loss: 2.5365 - val_acc: 0.2300\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2825 - acc: 0.5029 - val_loss: 2.5256 - val_acc: 0.2333\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2827 - acc: 0.5029 - val_loss: 2.5296 - val_acc: 0.2333\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2822 - acc: 0.5043 - val_loss: 2.5267 - val_acc: 0.2400\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2815 - acc: 0.5029 - val_loss: 2.5243 - val_acc: 0.2467\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2826 - acc: 0.5014 - val_loss: 2.5426 - val_acc: 0.2467\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2819 - acc: 0.5000 - val_loss: 2.5072 - val_acc: 0.2500\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2831 - acc: 0.4971 - val_loss: 2.5505 - val_acc: 0.2433\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2817 - acc: 0.4986 - val_loss: 2.5424 - val_acc: 0.2367\n",
      "Epoch 2375/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2824 - acc: 0.5000 - val_loss: 2.5279 - val_acc: 0.2467\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2822 - acc: 0.4986 - val_loss: 2.5379 - val_acc: 0.2433\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2828 - acc: 0.4943 - val_loss: 2.5229 - val_acc: 0.2400\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2817 - acc: 0.5014 - val_loss: 2.5222 - val_acc: 0.2500\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2820 - acc: 0.5014 - val_loss: 2.5230 - val_acc: 0.2500\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2816 - acc: 0.4986 - val_loss: 2.5038 - val_acc: 0.2467\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2819 - acc: 0.5071 - val_loss: 2.5367 - val_acc: 0.2500\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2815 - acc: 0.4986 - val_loss: 2.5361 - val_acc: 0.2467\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2815 - acc: 0.5000 - val_loss: 2.5489 - val_acc: 0.2467\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2818 - acc: 0.4957 - val_loss: 2.5322 - val_acc: 0.2433\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2819 - acc: 0.5000 - val_loss: 2.5455 - val_acc: 0.2467\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2810 - acc: 0.4971 - val_loss: 2.5308 - val_acc: 0.2400\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2813 - acc: 0.5029 - val_loss: 2.5460 - val_acc: 0.2367\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2812 - acc: 0.5014 - val_loss: 2.5432 - val_acc: 0.2400\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2816 - acc: 0.5000 - val_loss: 2.5246 - val_acc: 0.2367\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2809 - acc: 0.4943 - val_loss: 2.5529 - val_acc: 0.2433\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2810 - acc: 0.4986 - val_loss: 2.5470 - val_acc: 0.2467\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2818 - acc: 0.4986 - val_loss: 2.5452 - val_acc: 0.2433\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2812 - acc: 0.4971 - val_loss: 2.5356 - val_acc: 0.2467\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2814 - acc: 0.5057 - val_loss: 2.5378 - val_acc: 0.2467\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2810 - acc: 0.4971 - val_loss: 2.5514 - val_acc: 0.2433\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2812 - acc: 0.5043 - val_loss: 2.5615 - val_acc: 0.2433\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2806 - acc: 0.5014 - val_loss: 2.5475 - val_acc: 0.2400\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2807 - acc: 0.5057 - val_loss: 2.5157 - val_acc: 0.2500\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2811 - acc: 0.5071 - val_loss: 2.5649 - val_acc: 0.2433\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2802 - acc: 0.5014 - val_loss: 2.5404 - val_acc: 0.2433\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2801 - acc: 0.4943 - val_loss: 2.5622 - val_acc: 0.2400\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2818 - acc: 0.4943 - val_loss: 2.5007 - val_acc: 0.2400\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2811 - acc: 0.5014 - val_loss: 2.5313 - val_acc: 0.2467\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2798 - acc: 0.5029 - val_loss: 2.5356 - val_acc: 0.2467\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.2809 - acc: 0.5043 - val_loss: 2.5210 - val_acc: 0.2467\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2812 - acc: 0.5043 - val_loss: 2.5397 - val_acc: 0.2467\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2798 - acc: 0.5043 - val_loss: 2.5325 - val_acc: 0.2367\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2800 - acc: 0.5000 - val_loss: 2.5373 - val_acc: 0.2467\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2804 - acc: 0.4986 - val_loss: 2.5345 - val_acc: 0.2433\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2800 - acc: 0.5000 - val_loss: 2.5526 - val_acc: 0.2367\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2800 - acc: 0.5043 - val_loss: 2.5297 - val_acc: 0.2467\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2801 - acc: 0.5043 - val_loss: 2.5818 - val_acc: 0.2467\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2805 - acc: 0.4986 - val_loss: 2.5485 - val_acc: 0.2367\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2801 - acc: 0.4986 - val_loss: 2.5519 - val_acc: 0.2433\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2807 - acc: 0.5057 - val_loss: 2.5474 - val_acc: 0.2433\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2797 - acc: 0.5000 - val_loss: 2.5326 - val_acc: 0.2400\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2806 - acc: 0.5014 - val_loss: 2.5468 - val_acc: 0.2400\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2807 - acc: 0.5014 - val_loss: 2.5608 - val_acc: 0.2267\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2797 - acc: 0.4986 - val_loss: 2.5371 - val_acc: 0.2467\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2794 - acc: 0.4971 - val_loss: 2.5174 - val_acc: 0.2367\n",
      "Epoch 2421/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 233us/step - loss: 1.2798 - acc: 0.4986 - val_loss: 2.5230 - val_acc: 0.2367\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2794 - acc: 0.5071 - val_loss: 2.5435 - val_acc: 0.2333\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2800 - acc: 0.5029 - val_loss: 2.5583 - val_acc: 0.2400\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2795 - acc: 0.5000 - val_loss: 2.5308 - val_acc: 0.2467\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2795 - acc: 0.5000 - val_loss: 2.5461 - val_acc: 0.2400\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2784 - acc: 0.5029 - val_loss: 2.5415 - val_acc: 0.2367\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2796 - acc: 0.5014 - val_loss: 2.5432 - val_acc: 0.2367\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2789 - acc: 0.5029 - val_loss: 2.5296 - val_acc: 0.2433\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2786 - acc: 0.5029 - val_loss: 2.5489 - val_acc: 0.2433\n",
      "Epoch 2430/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2788 - acc: 0.4971 - val_loss: 2.5420 - val_acc: 0.2467\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2786 - acc: 0.5057 - val_loss: 2.5412 - val_acc: 0.2400\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2784 - acc: 0.5029 - val_loss: 2.5520 - val_acc: 0.2433\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2791 - acc: 0.4971 - val_loss: 2.5372 - val_acc: 0.2467\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2787 - acc: 0.4971 - val_loss: 2.5363 - val_acc: 0.2367\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2791 - acc: 0.5071 - val_loss: 2.5663 - val_acc: 0.2367\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2787 - acc: 0.5029 - val_loss: 2.5641 - val_acc: 0.2433\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2798 - acc: 0.4971 - val_loss: 2.5435 - val_acc: 0.2500\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2793 - acc: 0.5014 - val_loss: 2.5483 - val_acc: 0.2433\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2795 - acc: 0.5043 - val_loss: 2.5625 - val_acc: 0.2433\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2791 - acc: 0.5071 - val_loss: 2.5652 - val_acc: 0.2433\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2781 - acc: 0.4957 - val_loss: 2.5311 - val_acc: 0.2433\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2791 - acc: 0.5000 - val_loss: 2.5815 - val_acc: 0.2367\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2786 - acc: 0.5029 - val_loss: 2.5642 - val_acc: 0.2433\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2780 - acc: 0.5014 - val_loss: 2.5476 - val_acc: 0.2467\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2784 - acc: 0.5000 - val_loss: 2.5446 - val_acc: 0.2400\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2781 - acc: 0.5057 - val_loss: 2.5375 - val_acc: 0.2400\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2781 - acc: 0.5086 - val_loss: 2.5691 - val_acc: 0.2367\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2781 - acc: 0.5029 - val_loss: 2.5482 - val_acc: 0.2433\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2780 - acc: 0.5000 - val_loss: 2.5573 - val_acc: 0.2367\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2777 - acc: 0.5057 - val_loss: 2.5360 - val_acc: 0.2300\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2781 - acc: 0.5043 - val_loss: 2.5546 - val_acc: 0.2400\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2784 - acc: 0.5029 - val_loss: 2.5295 - val_acc: 0.2433\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2778 - acc: 0.5000 - val_loss: 2.5438 - val_acc: 0.2367\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2780 - acc: 0.5000 - val_loss: 2.5852 - val_acc: 0.2467\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2784 - acc: 0.5000 - val_loss: 2.5617 - val_acc: 0.2367\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2774 - acc: 0.5071 - val_loss: 2.5802 - val_acc: 0.2467\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2781 - acc: 0.5043 - val_loss: 2.5593 - val_acc: 0.2433\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2778 - acc: 0.5014 - val_loss: 2.5350 - val_acc: 0.2467\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2776 - acc: 0.5043 - val_loss: 2.5437 - val_acc: 0.2433\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2778 - acc: 0.5014 - val_loss: 2.5415 - val_acc: 0.2433\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.2773 - acc: 0.5029 - val_loss: 2.5417 - val_acc: 0.2467\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2768 - acc: 0.4986 - val_loss: 2.5609 - val_acc: 0.2400\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2774 - acc: 0.5014 - val_loss: 2.5427 - val_acc: 0.2433\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2771 - acc: 0.5014 - val_loss: 2.5445 - val_acc: 0.2433\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2771 - acc: 0.4986 - val_loss: 2.5651 - val_acc: 0.2433\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2765 - acc: 0.4957 - val_loss: 2.5515 - val_acc: 0.2433\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2773 - acc: 0.5043 - val_loss: 2.5442 - val_acc: 0.2333\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2767 - acc: 0.5000 - val_loss: 2.5406 - val_acc: 0.2467\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2767 - acc: 0.5000 - val_loss: 2.5389 - val_acc: 0.2400\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2769 - acc: 0.4971 - val_loss: 2.5614 - val_acc: 0.2433\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2772 - acc: 0.5000 - val_loss: 2.5388 - val_acc: 0.2467\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2765 - acc: 0.5000 - val_loss: 2.5673 - val_acc: 0.2400\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2769 - acc: 0.5057 - val_loss: 2.5826 - val_acc: 0.2333\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2775 - acc: 0.5000 - val_loss: 2.5567 - val_acc: 0.2300\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2764 - acc: 0.5014 - val_loss: 2.5782 - val_acc: 0.2433\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2762 - acc: 0.5029 - val_loss: 2.5678 - val_acc: 0.2433\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2768 - acc: 0.4957 - val_loss: 2.5495 - val_acc: 0.2400\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2765 - acc: 0.4957 - val_loss: 2.5607 - val_acc: 0.2367\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2751 - acc: 0.5071 - val_loss: 2.5481 - val_acc: 0.2467\n",
      "Epoch 2480/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.2753 - acc: 0.5086 - val_loss: 2.5597 - val_acc: 0.2333\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2757 - acc: 0.5014 - val_loss: 2.5729 - val_acc: 0.2433\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2763 - acc: 0.5000 - val_loss: 2.5716 - val_acc: 0.2367\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2765 - acc: 0.5043 - val_loss: 2.5522 - val_acc: 0.2333\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2769 - acc: 0.5014 - val_loss: 2.5553 - val_acc: 0.2367\n",
      "Epoch 2485/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2762 - acc: 0.5014 - val_loss: 2.5508 - val_acc: 0.2333\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2760 - acc: 0.5000 - val_loss: 2.5393 - val_acc: 0.2467\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2762 - acc: 0.5043 - val_loss: 2.5757 - val_acc: 0.2433\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2757 - acc: 0.5000 - val_loss: 2.5539 - val_acc: 0.2433\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2764 - acc: 0.5029 - val_loss: 2.5683 - val_acc: 0.2400\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2755 - acc: 0.5029 - val_loss: 2.5702 - val_acc: 0.2433\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2762 - acc: 0.4986 - val_loss: 2.5531 - val_acc: 0.2400\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2763 - acc: 0.5014 - val_loss: 2.5492 - val_acc: 0.2433\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2759 - acc: 0.5043 - val_loss: 2.5828 - val_acc: 0.2400\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2762 - acc: 0.4971 - val_loss: 2.5455 - val_acc: 0.2433\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2753 - acc: 0.5029 - val_loss: 2.5884 - val_acc: 0.2400\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2765 - acc: 0.4986 - val_loss: 2.5707 - val_acc: 0.2433\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2757 - acc: 0.5043 - val_loss: 2.5718 - val_acc: 0.2400\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2756 - acc: 0.5014 - val_loss: 2.5810 - val_acc: 0.2467\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2752 - acc: 0.5043 - val_loss: 2.5468 - val_acc: 0.2367\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2749 - acc: 0.5029 - val_loss: 2.5433 - val_acc: 0.2500\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2757 - acc: 0.5043 - val_loss: 2.5915 - val_acc: 0.2400\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2756 - acc: 0.5014 - val_loss: 2.5654 - val_acc: 0.2433\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2750 - acc: 0.5043 - val_loss: 2.5691 - val_acc: 0.2400\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2749 - acc: 0.5100 - val_loss: 2.5712 - val_acc: 0.2433\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2763 - acc: 0.4971 - val_loss: 2.5662 - val_acc: 0.2433\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2747 - acc: 0.5029 - val_loss: 2.5660 - val_acc: 0.2400\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2751 - acc: 0.5057 - val_loss: 2.5528 - val_acc: 0.2400\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2746 - acc: 0.5014 - val_loss: 2.5990 - val_acc: 0.2467\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2749 - acc: 0.5071 - val_loss: 2.5650 - val_acc: 0.2433\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2745 - acc: 0.5000 - val_loss: 2.5716 - val_acc: 0.2367\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2746 - acc: 0.5014 - val_loss: 2.5679 - val_acc: 0.2367\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2744 - acc: 0.5029 - val_loss: 2.5753 - val_acc: 0.2433\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2753 - acc: 0.5071 - val_loss: 2.5589 - val_acc: 0.2433\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2738 - acc: 0.4986 - val_loss: 2.5537 - val_acc: 0.2433\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2742 - acc: 0.5043 - val_loss: 2.5445 - val_acc: 0.2400\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2744 - acc: 0.5043 - val_loss: 2.5800 - val_acc: 0.2433\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2750 - acc: 0.5043 - val_loss: 2.5832 - val_acc: 0.2433\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2745 - acc: 0.5043 - val_loss: 2.5713 - val_acc: 0.2433\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2756 - acc: 0.5071 - val_loss: 2.5806 - val_acc: 0.2400\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2738 - acc: 0.5000 - val_loss: 2.5743 - val_acc: 0.2367\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2740 - acc: 0.5000 - val_loss: 2.5697 - val_acc: 0.2300\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2744 - acc: 0.4971 - val_loss: 2.5655 - val_acc: 0.2367\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2748 - acc: 0.5014 - val_loss: 2.5615 - val_acc: 0.2367\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2734 - acc: 0.4986 - val_loss: 2.5627 - val_acc: 0.2400\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2740 - acc: 0.5000 - val_loss: 2.5782 - val_acc: 0.2433\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2739 - acc: 0.5029 - val_loss: 2.5583 - val_acc: 0.2333\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2738 - acc: 0.5029 - val_loss: 2.5746 - val_acc: 0.2367\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2733 - acc: 0.5043 - val_loss: 2.5724 - val_acc: 0.2333\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2746 - acc: 0.5071 - val_loss: 2.5889 - val_acc: 0.2367\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2732 - acc: 0.5071 - val_loss: 2.5707 - val_acc: 0.2367\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2734 - acc: 0.5014 - val_loss: 2.5849 - val_acc: 0.2433\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2735 - acc: 0.5057 - val_loss: 2.5751 - val_acc: 0.2433\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2744 - acc: 0.5029 - val_loss: 2.5770 - val_acc: 0.2433\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2739 - acc: 0.5014 - val_loss: 2.5895 - val_acc: 0.2400\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2738 - acc: 0.5029 - val_loss: 2.5677 - val_acc: 0.2433\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2733 - acc: 0.5057 - val_loss: 2.5906 - val_acc: 0.2367\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2746 - acc: 0.5029 - val_loss: 2.5554 - val_acc: 0.2467\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2731 - acc: 0.5071 - val_loss: 2.5788 - val_acc: 0.2367\n",
      "Epoch 2539/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 228us/step - loss: 1.2742 - acc: 0.5029 - val_loss: 2.5880 - val_acc: 0.2433\n",
      "Epoch 2540/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2736 - acc: 0.5014 - val_loss: 2.5999 - val_acc: 0.2467\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2734 - acc: 0.5057 - val_loss: 2.5773 - val_acc: 0.2367\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2726 - acc: 0.5043 - val_loss: 2.5763 - val_acc: 0.2433\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2733 - acc: 0.5000 - val_loss: 2.5721 - val_acc: 0.2333\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2735 - acc: 0.4986 - val_loss: 2.5772 - val_acc: 0.2367\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2731 - acc: 0.5057 - val_loss: 2.5964 - val_acc: 0.2367\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2734 - acc: 0.5057 - val_loss: 2.5930 - val_acc: 0.2400\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2734 - acc: 0.5043 - val_loss: 2.5885 - val_acc: 0.2433\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2727 - acc: 0.5057 - val_loss: 2.5768 - val_acc: 0.2433\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2728 - acc: 0.5029 - val_loss: 2.6081 - val_acc: 0.2467\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2733 - acc: 0.5014 - val_loss: 2.5710 - val_acc: 0.2367\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2719 - acc: 0.5014 - val_loss: 2.5960 - val_acc: 0.2433\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2726 - acc: 0.5029 - val_loss: 2.5600 - val_acc: 0.2333\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2722 - acc: 0.5000 - val_loss: 2.5697 - val_acc: 0.2367\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2725 - acc: 0.5014 - val_loss: 2.5610 - val_acc: 0.2400\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.2727 - acc: 0.5029 - val_loss: 2.5938 - val_acc: 0.2433\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2729 - acc: 0.4986 - val_loss: 2.5657 - val_acc: 0.2400\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2722 - acc: 0.5029 - val_loss: 2.5968 - val_acc: 0.2433\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2721 - acc: 0.4971 - val_loss: 2.5853 - val_acc: 0.2433\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2720 - acc: 0.5014 - val_loss: 2.5844 - val_acc: 0.2367\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2724 - acc: 0.5043 - val_loss: 2.5701 - val_acc: 0.2367\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2722 - acc: 0.5057 - val_loss: 2.5728 - val_acc: 0.2400\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2718 - acc: 0.5043 - val_loss: 2.5690 - val_acc: 0.2433\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2721 - acc: 0.5029 - val_loss: 2.5839 - val_acc: 0.2467\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2723 - acc: 0.5029 - val_loss: 2.5778 - val_acc: 0.2400\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2719 - acc: 0.5057 - val_loss: 2.5771 - val_acc: 0.2400\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2728 - acc: 0.5000 - val_loss: 2.5886 - val_acc: 0.2400\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2726 - acc: 0.5029 - val_loss: 2.5861 - val_acc: 0.2433\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2721 - acc: 0.5029 - val_loss: 2.5744 - val_acc: 0.2367\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2707 - acc: 0.5029 - val_loss: 2.5695 - val_acc: 0.2433\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2723 - acc: 0.4957 - val_loss: 2.5915 - val_acc: 0.2433\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2714 - acc: 0.5071 - val_loss: 2.5862 - val_acc: 0.2400\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2718 - acc: 0.5057 - val_loss: 2.5999 - val_acc: 0.2433\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2708 - acc: 0.5029 - val_loss: 2.6144 - val_acc: 0.2367\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2721 - acc: 0.4986 - val_loss: 2.5532 - val_acc: 0.2400\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2715 - acc: 0.5057 - val_loss: 2.6011 - val_acc: 0.2367\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2714 - acc: 0.5057 - val_loss: 2.5895 - val_acc: 0.2433\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2711 - acc: 0.5014 - val_loss: 2.5918 - val_acc: 0.2433\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2711 - acc: 0.5043 - val_loss: 2.5854 - val_acc: 0.2433\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2715 - acc: 0.5014 - val_loss: 2.5803 - val_acc: 0.2367\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2712 - acc: 0.5057 - val_loss: 2.5853 - val_acc: 0.2433\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2706 - acc: 0.5029 - val_loss: 2.5627 - val_acc: 0.2333\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.2711 - acc: 0.5043 - val_loss: 2.6027 - val_acc: 0.2367\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2715 - acc: 0.5029 - val_loss: 2.5937 - val_acc: 0.2367\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2708 - acc: 0.5086 - val_loss: 2.5892 - val_acc: 0.2367\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2705 - acc: 0.4986 - val_loss: 2.5827 - val_acc: 0.2367\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2709 - acc: 0.5057 - val_loss: 2.5740 - val_acc: 0.2433\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2707 - acc: 0.5043 - val_loss: 2.5939 - val_acc: 0.2400\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.2714 - acc: 0.5014 - val_loss: 2.5861 - val_acc: 0.2367\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2708 - acc: 0.5000 - val_loss: 2.5825 - val_acc: 0.2367\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2699 - acc: 0.4986 - val_loss: 2.5915 - val_acc: 0.2367\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2705 - acc: 0.5086 - val_loss: 2.5684 - val_acc: 0.2433\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2706 - acc: 0.5071 - val_loss: 2.6091 - val_acc: 0.2367\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2701 - acc: 0.5029 - val_loss: 2.6138 - val_acc: 0.2433\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2709 - acc: 0.5029 - val_loss: 2.5760 - val_acc: 0.2367\n",
      "Epoch 2595/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2707 - acc: 0.4986 - val_loss: 2.5855 - val_acc: 0.2333\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2703 - acc: 0.5086 - val_loss: 2.5819 - val_acc: 0.2367\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2708 - acc: 0.5043 - val_loss: 2.5626 - val_acc: 0.2367\n",
      "Epoch 2598/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 233us/step - loss: 1.2698 - acc: 0.4986 - val_loss: 2.5865 - val_acc: 0.2433\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2705 - acc: 0.5043 - val_loss: 2.5721 - val_acc: 0.2367\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2696 - acc: 0.5057 - val_loss: 2.5842 - val_acc: 0.2433\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2696 - acc: 0.5029 - val_loss: 2.5886 - val_acc: 0.2433\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2711 - acc: 0.5086 - val_loss: 2.6017 - val_acc: 0.2433\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2705 - acc: 0.5014 - val_loss: 2.5717 - val_acc: 0.2433\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2696 - acc: 0.5100 - val_loss: 2.5943 - val_acc: 0.2367\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2701 - acc: 0.5029 - val_loss: 2.5913 - val_acc: 0.2400\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2701 - acc: 0.5029 - val_loss: 2.5854 - val_acc: 0.2367\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2698 - acc: 0.5014 - val_loss: 2.5742 - val_acc: 0.2367\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2703 - acc: 0.5000 - val_loss: 2.6048 - val_acc: 0.2367\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2695 - acc: 0.5043 - val_loss: 2.5830 - val_acc: 0.2400\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2698 - acc: 0.5029 - val_loss: 2.5746 - val_acc: 0.2433\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2696 - acc: 0.5057 - val_loss: 2.5729 - val_acc: 0.2367\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2699 - acc: 0.5029 - val_loss: 2.5916 - val_acc: 0.2367\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2694 - acc: 0.5071 - val_loss: 2.5928 - val_acc: 0.2433\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2692 - acc: 0.5057 - val_loss: 2.6042 - val_acc: 0.2433\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2692 - acc: 0.5029 - val_loss: 2.5881 - val_acc: 0.2433\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2693 - acc: 0.5057 - val_loss: 2.6102 - val_acc: 0.2400\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2698 - acc: 0.5043 - val_loss: 2.5955 - val_acc: 0.2367\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2700 - acc: 0.4971 - val_loss: 2.5815 - val_acc: 0.2367\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2695 - acc: 0.5043 - val_loss: 2.5982 - val_acc: 0.2367\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2691 - acc: 0.5043 - val_loss: 2.6046 - val_acc: 0.2367\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2693 - acc: 0.5071 - val_loss: 2.5947 - val_acc: 0.2367\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2697 - acc: 0.5000 - val_loss: 2.5742 - val_acc: 0.2400\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2692 - acc: 0.5014 - val_loss: 2.5993 - val_acc: 0.2367\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 243us/step - loss: 1.2684 - acc: 0.5029 - val_loss: 2.5785 - val_acc: 0.2333\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2686 - acc: 0.5057 - val_loss: 2.6121 - val_acc: 0.2433\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2691 - acc: 0.5043 - val_loss: 2.6043 - val_acc: 0.2433\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2692 - acc: 0.5057 - val_loss: 2.5913 - val_acc: 0.2367\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2681 - acc: 0.5014 - val_loss: 2.6077 - val_acc: 0.2367\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2687 - acc: 0.5014 - val_loss: 2.5998 - val_acc: 0.2400\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2681 - acc: 0.5029 - val_loss: 2.5652 - val_acc: 0.2433\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2690 - acc: 0.5071 - val_loss: 2.5789 - val_acc: 0.2333\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2696 - acc: 0.5043 - val_loss: 2.5954 - val_acc: 0.2433\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2681 - acc: 0.5071 - val_loss: 2.5969 - val_acc: 0.2367\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2681 - acc: 0.5057 - val_loss: 2.5749 - val_acc: 0.2400\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2691 - acc: 0.5014 - val_loss: 2.6129 - val_acc: 0.2367\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2684 - acc: 0.5071 - val_loss: 2.6002 - val_acc: 0.2367\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2686 - acc: 0.5043 - val_loss: 2.6036 - val_acc: 0.2367\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2684 - acc: 0.5029 - val_loss: 2.6064 - val_acc: 0.2433\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2683 - acc: 0.5029 - val_loss: 2.5696 - val_acc: 0.2433\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2683 - acc: 0.5086 - val_loss: 2.6141 - val_acc: 0.2467\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2675 - acc: 0.5043 - val_loss: 2.6402 - val_acc: 0.2467\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2677 - acc: 0.5000 - val_loss: 2.5729 - val_acc: 0.2433\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2679 - acc: 0.5143 - val_loss: 2.5999 - val_acc: 0.2433\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2679 - acc: 0.5014 - val_loss: 2.6143 - val_acc: 0.2433\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2680 - acc: 0.5014 - val_loss: 2.5934 - val_acc: 0.2433\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2683 - acc: 0.5086 - val_loss: 2.6074 - val_acc: 0.2433\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2679 - acc: 0.5043 - val_loss: 2.5990 - val_acc: 0.2467\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2679 - acc: 0.5043 - val_loss: 2.6112 - val_acc: 0.2433\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2680 - acc: 0.5071 - val_loss: 2.5838 - val_acc: 0.2367\n",
      "Epoch 2650/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2672 - acc: 0.5043 - val_loss: 2.5776 - val_acc: 0.2400\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2669 - acc: 0.5014 - val_loss: 2.5961 - val_acc: 0.2433\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2672 - acc: 0.5071 - val_loss: 2.5866 - val_acc: 0.2467\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2681 - acc: 0.5086 - val_loss: 2.6193 - val_acc: 0.2433\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2677 - acc: 0.4971 - val_loss: 2.5975 - val_acc: 0.2400\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2675 - acc: 0.5071 - val_loss: 2.6024 - val_acc: 0.2367\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2675 - acc: 0.5029 - val_loss: 2.6122 - val_acc: 0.2367\n",
      "Epoch 2657/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 226us/step - loss: 1.2668 - acc: 0.4986 - val_loss: 2.5686 - val_acc: 0.2367\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2672 - acc: 0.5043 - val_loss: 2.5835 - val_acc: 0.2367\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2669 - acc: 0.5000 - val_loss: 2.5819 - val_acc: 0.2367\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2671 - acc: 0.5029 - val_loss: 2.6205 - val_acc: 0.2400\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2680 - acc: 0.5029 - val_loss: 2.6008 - val_acc: 0.2367\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2678 - acc: 0.5029 - val_loss: 2.5906 - val_acc: 0.2400\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2665 - acc: 0.5057 - val_loss: 2.5938 - val_acc: 0.2367\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2668 - acc: 0.5043 - val_loss: 2.5961 - val_acc: 0.2367\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2671 - acc: 0.5086 - val_loss: 2.5835 - val_acc: 0.2367\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2672 - acc: 0.5043 - val_loss: 2.5946 - val_acc: 0.2367\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2661 - acc: 0.5100 - val_loss: 2.5975 - val_acc: 0.2433\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2669 - acc: 0.5086 - val_loss: 2.6302 - val_acc: 0.2500\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2666 - acc: 0.5086 - val_loss: 2.6137 - val_acc: 0.2400\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2670 - acc: 0.5043 - val_loss: 2.6210 - val_acc: 0.2433\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2667 - acc: 0.5043 - val_loss: 2.6211 - val_acc: 0.2400\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2663 - acc: 0.5100 - val_loss: 2.6241 - val_acc: 0.2433\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2670 - acc: 0.5086 - val_loss: 2.5873 - val_acc: 0.2367\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2664 - acc: 0.5014 - val_loss: 2.5802 - val_acc: 0.2367\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2662 - acc: 0.5043 - val_loss: 2.5827 - val_acc: 0.2367\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2666 - acc: 0.5100 - val_loss: 2.6101 - val_acc: 0.2400\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2664 - acc: 0.5057 - val_loss: 2.6169 - val_acc: 0.2467\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2669 - acc: 0.5057 - val_loss: 2.6018 - val_acc: 0.2333\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2666 - acc: 0.5043 - val_loss: 2.6094 - val_acc: 0.2467\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2686 - acc: 0.5057 - val_loss: 2.5939 - val_acc: 0.2367\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2666 - acc: 0.5029 - val_loss: 2.6229 - val_acc: 0.2367\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2662 - acc: 0.5057 - val_loss: 2.5937 - val_acc: 0.2333\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2666 - acc: 0.5029 - val_loss: 2.6093 - val_acc: 0.2433\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2656 - acc: 0.5029 - val_loss: 2.6006 - val_acc: 0.2400\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2660 - acc: 0.5071 - val_loss: 2.6018 - val_acc: 0.2400\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2662 - acc: 0.5057 - val_loss: 2.6043 - val_acc: 0.2367\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2660 - acc: 0.5043 - val_loss: 2.5991 - val_acc: 0.2333\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2659 - acc: 0.5057 - val_loss: 2.6281 - val_acc: 0.2433\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2655 - acc: 0.5057 - val_loss: 2.6103 - val_acc: 0.2433\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2663 - acc: 0.5086 - val_loss: 2.5660 - val_acc: 0.2400\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2659 - acc: 0.5014 - val_loss: 2.6194 - val_acc: 0.2467\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2657 - acc: 0.5029 - val_loss: 2.6328 - val_acc: 0.2433\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2654 - acc: 0.5071 - val_loss: 2.6180 - val_acc: 0.2433\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2655 - acc: 0.5043 - val_loss: 2.5950 - val_acc: 0.2433\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2647 - acc: 0.5086 - val_loss: 2.6125 - val_acc: 0.2467\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.2653 - acc: 0.5086 - val_loss: 2.6013 - val_acc: 0.2367\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2660 - acc: 0.5029 - val_loss: 2.5923 - val_acc: 0.2400\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2657 - acc: 0.5057 - val_loss: 2.6193 - val_acc: 0.2367\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2658 - acc: 0.5014 - val_loss: 2.6155 - val_acc: 0.2433\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2653 - acc: 0.5043 - val_loss: 2.5926 - val_acc: 0.2467\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2656 - acc: 0.5057 - val_loss: 2.6259 - val_acc: 0.2467\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2652 - acc: 0.5071 - val_loss: 2.6301 - val_acc: 0.2367\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2647 - acc: 0.5057 - val_loss: 2.6457 - val_acc: 0.2467\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2647 - acc: 0.5043 - val_loss: 2.6138 - val_acc: 0.2433\n",
      "Epoch 2705/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2649 - acc: 0.5071 - val_loss: 2.6058 - val_acc: 0.2400\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2655 - acc: 0.5057 - val_loss: 2.6117 - val_acc: 0.2433\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2661 - acc: 0.5043 - val_loss: 2.6207 - val_acc: 0.2400\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2649 - acc: 0.5014 - val_loss: 2.6245 - val_acc: 0.2367\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2646 - acc: 0.5057 - val_loss: 2.6069 - val_acc: 0.2367\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2647 - acc: 0.5057 - val_loss: 2.6084 - val_acc: 0.2367\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2650 - acc: 0.5057 - val_loss: 2.6022 - val_acc: 0.2433\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2643 - acc: 0.5043 - val_loss: 2.5822 - val_acc: 0.2367\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2648 - acc: 0.5071 - val_loss: 2.6392 - val_acc: 0.2467\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2648 - acc: 0.5029 - val_loss: 2.6369 - val_acc: 0.2467\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2651 - acc: 0.5057 - val_loss: 2.6487 - val_acc: 0.2400\n",
      "Epoch 2716/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.2645 - acc: 0.5086 - val_loss: 2.6350 - val_acc: 0.2467\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2648 - acc: 0.5029 - val_loss: 2.6152 - val_acc: 0.2433\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2649 - acc: 0.5057 - val_loss: 2.6251 - val_acc: 0.2467\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2643 - acc: 0.5071 - val_loss: 2.6061 - val_acc: 0.2433\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2646 - acc: 0.5057 - val_loss: 2.6191 - val_acc: 0.2367\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2649 - acc: 0.5000 - val_loss: 2.6070 - val_acc: 0.2367\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2642 - acc: 0.5086 - val_loss: 2.6228 - val_acc: 0.2467\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2646 - acc: 0.5071 - val_loss: 2.6305 - val_acc: 0.2467\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2647 - acc: 0.5057 - val_loss: 2.6261 - val_acc: 0.2467\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2642 - acc: 0.5057 - val_loss: 2.6149 - val_acc: 0.2433\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2638 - acc: 0.5043 - val_loss: 2.6388 - val_acc: 0.2467\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2638 - acc: 0.5086 - val_loss: 2.6236 - val_acc: 0.2400\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.2633 - acc: 0.5043 - val_loss: 2.5915 - val_acc: 0.2433\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2638 - acc: 0.5086 - val_loss: 2.6288 - val_acc: 0.2433\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2636 - acc: 0.5057 - val_loss: 2.5976 - val_acc: 0.2333\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2635 - acc: 0.5029 - val_loss: 2.6173 - val_acc: 0.2400\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2654 - acc: 0.5057 - val_loss: 2.6282 - val_acc: 0.2433\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2639 - acc: 0.5057 - val_loss: 2.5981 - val_acc: 0.2367\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2632 - acc: 0.5114 - val_loss: 2.6201 - val_acc: 0.2433\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2636 - acc: 0.5043 - val_loss: 2.6233 - val_acc: 0.2400\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2634 - acc: 0.5071 - val_loss: 2.6278 - val_acc: 0.2400\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2627 - acc: 0.5114 - val_loss: 2.6367 - val_acc: 0.2467\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2635 - acc: 0.5057 - val_loss: 2.6299 - val_acc: 0.2433\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2631 - acc: 0.5086 - val_loss: 2.6378 - val_acc: 0.2433\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2641 - acc: 0.5043 - val_loss: 2.6054 - val_acc: 0.2367\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2644 - acc: 0.5014 - val_loss: 2.6402 - val_acc: 0.2400\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2642 - acc: 0.5014 - val_loss: 2.6357 - val_acc: 0.2367\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2636 - acc: 0.5014 - val_loss: 2.6188 - val_acc: 0.2400\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2638 - acc: 0.5029 - val_loss: 2.6149 - val_acc: 0.2433\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2635 - acc: 0.5029 - val_loss: 2.6312 - val_acc: 0.2433\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2635 - acc: 0.5057 - val_loss: 2.6329 - val_acc: 0.2400\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2638 - acc: 0.5029 - val_loss: 2.6181 - val_acc: 0.2333\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2632 - acc: 0.5071 - val_loss: 2.6451 - val_acc: 0.2433\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2637 - acc: 0.5000 - val_loss: 2.6354 - val_acc: 0.2400\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2629 - acc: 0.5071 - val_loss: 2.6378 - val_acc: 0.2467\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2632 - acc: 0.5057 - val_loss: 2.6192 - val_acc: 0.2400\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2627 - acc: 0.5086 - val_loss: 2.6283 - val_acc: 0.2333\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2630 - acc: 0.5043 - val_loss: 2.6325 - val_acc: 0.2433\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2634 - acc: 0.5071 - val_loss: 2.6105 - val_acc: 0.2400\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2620 - acc: 0.5029 - val_loss: 2.5990 - val_acc: 0.2400\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2625 - acc: 0.5057 - val_loss: 2.6740 - val_acc: 0.2467\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2638 - acc: 0.5071 - val_loss: 2.6257 - val_acc: 0.2400\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2633 - acc: 0.5000 - val_loss: 2.5828 - val_acc: 0.2400\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2631 - acc: 0.5071 - val_loss: 2.6451 - val_acc: 0.2433\n",
      "Epoch 2760/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2626 - acc: 0.5086 - val_loss: 2.6360 - val_acc: 0.2400\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2624 - acc: 0.5057 - val_loss: 2.6195 - val_acc: 0.2433\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2626 - acc: 0.5129 - val_loss: 2.6128 - val_acc: 0.2367\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2630 - acc: 0.5057 - val_loss: 2.6422 - val_acc: 0.2400\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2613 - acc: 0.5000 - val_loss: 2.6474 - val_acc: 0.2433\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2626 - acc: 0.5029 - val_loss: 2.6234 - val_acc: 0.2400\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2617 - acc: 0.5100 - val_loss: 2.6385 - val_acc: 0.2433\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2624 - acc: 0.5143 - val_loss: 2.6382 - val_acc: 0.2367\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2620 - acc: 0.5086 - val_loss: 2.6450 - val_acc: 0.2467\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2613 - acc: 0.5071 - val_loss: 2.6361 - val_acc: 0.2433\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2618 - acc: 0.5043 - val_loss: 2.6166 - val_acc: 0.2367\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2615 - acc: 0.5086 - val_loss: 2.6156 - val_acc: 0.2367\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2635 - acc: 0.5086 - val_loss: 2.6173 - val_acc: 0.2400\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2619 - acc: 0.5057 - val_loss: 2.6444 - val_acc: 0.2400\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2616 - acc: 0.5043 - val_loss: 2.6336 - val_acc: 0.2433\n",
      "Epoch 2775/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 230us/step - loss: 1.2617 - acc: 0.5100 - val_loss: 2.6237 - val_acc: 0.2367\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2622 - acc: 0.5071 - val_loss: 2.6314 - val_acc: 0.2400\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2623 - acc: 0.5057 - val_loss: 2.6512 - val_acc: 0.2467\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2622 - acc: 0.5043 - val_loss: 2.6424 - val_acc: 0.2400\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2610 - acc: 0.5100 - val_loss: 2.6121 - val_acc: 0.2367\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2618 - acc: 0.5043 - val_loss: 2.6520 - val_acc: 0.2467\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2618 - acc: 0.5086 - val_loss: 2.6338 - val_acc: 0.2433\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2613 - acc: 0.5114 - val_loss: 2.6013 - val_acc: 0.2367\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2615 - acc: 0.5014 - val_loss: 2.6469 - val_acc: 0.2467\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2609 - acc: 0.5014 - val_loss: 2.6415 - val_acc: 0.2433\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2613 - acc: 0.5100 - val_loss: 2.6284 - val_acc: 0.2400\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2617 - acc: 0.5086 - val_loss: 2.6534 - val_acc: 0.2467\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2617 - acc: 0.5043 - val_loss: 2.6285 - val_acc: 0.2367\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2613 - acc: 0.5057 - val_loss: 2.6589 - val_acc: 0.2400\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2611 - acc: 0.5071 - val_loss: 2.6501 - val_acc: 0.2400\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2610 - acc: 0.5057 - val_loss: 2.6183 - val_acc: 0.2367\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2612 - acc: 0.5086 - val_loss: 2.6049 - val_acc: 0.2400\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2612 - acc: 0.5029 - val_loss: 2.6446 - val_acc: 0.2367\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2605 - acc: 0.5071 - val_loss: 2.6057 - val_acc: 0.2367\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2615 - acc: 0.5071 - val_loss: 2.6400 - val_acc: 0.2467\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2607 - acc: 0.5071 - val_loss: 2.6157 - val_acc: 0.2333\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2608 - acc: 0.5057 - val_loss: 2.6447 - val_acc: 0.2433\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2611 - acc: 0.5029 - val_loss: 2.6436 - val_acc: 0.2367\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2601 - acc: 0.5143 - val_loss: 2.6556 - val_acc: 0.2467\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2605 - acc: 0.5057 - val_loss: 2.6205 - val_acc: 0.2367\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2615 - acc: 0.5014 - val_loss: 2.6411 - val_acc: 0.2400\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2611 - acc: 0.5086 - val_loss: 2.6638 - val_acc: 0.2433\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2610 - acc: 0.5057 - val_loss: 2.6475 - val_acc: 0.2433\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2606 - acc: 0.5100 - val_loss: 2.6396 - val_acc: 0.2467\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2605 - acc: 0.5114 - val_loss: 2.6433 - val_acc: 0.2433\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2602 - acc: 0.5057 - val_loss: 2.6448 - val_acc: 0.2400\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2606 - acc: 0.5014 - val_loss: 2.6361 - val_acc: 0.2433\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2605 - acc: 0.5100 - val_loss: 2.6608 - val_acc: 0.2467\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2600 - acc: 0.5071 - val_loss: 2.6252 - val_acc: 0.2467\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2603 - acc: 0.5071 - val_loss: 2.6487 - val_acc: 0.2467\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2601 - acc: 0.5071 - val_loss: 2.6353 - val_acc: 0.2467\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2593 - acc: 0.5043 - val_loss: 2.6470 - val_acc: 0.2467\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2604 - acc: 0.5071 - val_loss: 2.6341 - val_acc: 0.2433\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2606 - acc: 0.5129 - val_loss: 2.6600 - val_acc: 0.2433\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2599 - acc: 0.5071 - val_loss: 2.6309 - val_acc: 0.2367\n",
      "Epoch 2815/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2599 - acc: 0.5086 - val_loss: 2.6630 - val_acc: 0.2433\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2607 - acc: 0.5100 - val_loss: 2.6359 - val_acc: 0.2400\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2596 - acc: 0.5086 - val_loss: 2.6495 - val_acc: 0.2367\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2599 - acc: 0.5043 - val_loss: 2.6435 - val_acc: 0.2433\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2603 - acc: 0.5086 - val_loss: 2.6418 - val_acc: 0.2433\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2602 - acc: 0.5057 - val_loss: 2.6264 - val_acc: 0.2333\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2606 - acc: 0.5029 - val_loss: 2.6602 - val_acc: 0.2467\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2596 - acc: 0.5086 - val_loss: 2.6495 - val_acc: 0.2400\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2595 - acc: 0.5043 - val_loss: 2.6543 - val_acc: 0.2333\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2591 - acc: 0.5114 - val_loss: 2.6536 - val_acc: 0.2367\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2601 - acc: 0.5057 - val_loss: 2.6562 - val_acc: 0.2433\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2587 - acc: 0.5086 - val_loss: 2.6584 - val_acc: 0.2400\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2605 - acc: 0.5029 - val_loss: 2.6317 - val_acc: 0.2367\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2599 - acc: 0.5057 - val_loss: 2.6682 - val_acc: 0.2400\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2600 - acc: 0.5057 - val_loss: 2.6306 - val_acc: 0.2367\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2586 - acc: 0.5043 - val_loss: 2.6317 - val_acc: 0.2400\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2598 - acc: 0.5114 - val_loss: 2.6248 - val_acc: 0.2400\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2591 - acc: 0.5114 - val_loss: 2.6732 - val_acc: 0.2467\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2591 - acc: 0.5086 - val_loss: 2.6453 - val_acc: 0.2400\n",
      "Epoch 2834/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 228us/step - loss: 1.2596 - acc: 0.5043 - val_loss: 2.6443 - val_acc: 0.2467\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2587 - acc: 0.5014 - val_loss: 2.6601 - val_acc: 0.2433\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2592 - acc: 0.5071 - val_loss: 2.6436 - val_acc: 0.2400\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2588 - acc: 0.5086 - val_loss: 2.6567 - val_acc: 0.2400\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2594 - acc: 0.5143 - val_loss: 2.6052 - val_acc: 0.2367\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2585 - acc: 0.5086 - val_loss: 2.6494 - val_acc: 0.2433\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2589 - acc: 0.5086 - val_loss: 2.6481 - val_acc: 0.2400\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2586 - acc: 0.5071 - val_loss: 2.6573 - val_acc: 0.2433\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2587 - acc: 0.5100 - val_loss: 2.6446 - val_acc: 0.2367\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2592 - acc: 0.5086 - val_loss: 2.6448 - val_acc: 0.2367\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2581 - acc: 0.5100 - val_loss: 2.6457 - val_acc: 0.2433\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2593 - acc: 0.5114 - val_loss: 2.6699 - val_acc: 0.2400\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2579 - acc: 0.5114 - val_loss: 2.6989 - val_acc: 0.2467\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2588 - acc: 0.5071 - val_loss: 2.6615 - val_acc: 0.2433\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2581 - acc: 0.5071 - val_loss: 2.6418 - val_acc: 0.2400\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2583 - acc: 0.5086 - val_loss: 2.6554 - val_acc: 0.2400\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2588 - acc: 0.5086 - val_loss: 2.6495 - val_acc: 0.2400\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2587 - acc: 0.5057 - val_loss: 2.6496 - val_acc: 0.2367\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2582 - acc: 0.5071 - val_loss: 2.6819 - val_acc: 0.2467\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2584 - acc: 0.5071 - val_loss: 2.6689 - val_acc: 0.2433\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2585 - acc: 0.5029 - val_loss: 2.6280 - val_acc: 0.2333\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2576 - acc: 0.5086 - val_loss: 2.6615 - val_acc: 0.2367\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2584 - acc: 0.5029 - val_loss: 2.6592 - val_acc: 0.2300\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2579 - acc: 0.5086 - val_loss: 2.6749 - val_acc: 0.2467\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2577 - acc: 0.5071 - val_loss: 2.6753 - val_acc: 0.2467\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2577 - acc: 0.5014 - val_loss: 2.6333 - val_acc: 0.2367\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2579 - acc: 0.5114 - val_loss: 2.6148 - val_acc: 0.2367\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2581 - acc: 0.5100 - val_loss: 2.6553 - val_acc: 0.2400\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.2577 - acc: 0.5100 - val_loss: 2.6566 - val_acc: 0.2400\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2575 - acc: 0.5071 - val_loss: 2.6555 - val_acc: 0.2433\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2580 - acc: 0.5014 - val_loss: 2.6452 - val_acc: 0.2400\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2581 - acc: 0.5114 - val_loss: 2.6733 - val_acc: 0.2433\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2579 - acc: 0.5114 - val_loss: 2.6683 - val_acc: 0.2433\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2572 - acc: 0.5086 - val_loss: 2.6661 - val_acc: 0.2400\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2581 - acc: 0.5043 - val_loss: 2.6318 - val_acc: 0.2367\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2573 - acc: 0.5071 - val_loss: 2.6495 - val_acc: 0.2400\n",
      "Epoch 2870/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2570 - acc: 0.5043 - val_loss: 2.7037 - val_acc: 0.2467\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2579 - acc: 0.5086 - val_loss: 2.6763 - val_acc: 0.2400\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2577 - acc: 0.5057 - val_loss: 2.6625 - val_acc: 0.2400\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2571 - acc: 0.5086 - val_loss: 2.6330 - val_acc: 0.2333\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2573 - acc: 0.5143 - val_loss: 2.6378 - val_acc: 0.2400\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2571 - acc: 0.5086 - val_loss: 2.6574 - val_acc: 0.2433\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2586 - acc: 0.5057 - val_loss: 2.6888 - val_acc: 0.2467\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2574 - acc: 0.5086 - val_loss: 2.6778 - val_acc: 0.2400\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2570 - acc: 0.5057 - val_loss: 2.6488 - val_acc: 0.2433\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2564 - acc: 0.5100 - val_loss: 2.6612 - val_acc: 0.2467\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2565 - acc: 0.5057 - val_loss: 2.6778 - val_acc: 0.2400\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2577 - acc: 0.5129 - val_loss: 2.6600 - val_acc: 0.2400\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2572 - acc: 0.5043 - val_loss: 2.6272 - val_acc: 0.2367\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2563 - acc: 0.5129 - val_loss: 2.5957 - val_acc: 0.2400\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2568 - acc: 0.5086 - val_loss: 2.7079 - val_acc: 0.2433\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2569 - acc: 0.5029 - val_loss: 2.6373 - val_acc: 0.2333\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.2570 - acc: 0.5100 - val_loss: 2.6678 - val_acc: 0.2433\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2567 - acc: 0.5171 - val_loss: 2.6717 - val_acc: 0.2467\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2566 - acc: 0.5043 - val_loss: 2.6556 - val_acc: 0.2433\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2570 - acc: 0.5114 - val_loss: 2.6270 - val_acc: 0.2367\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2568 - acc: 0.5129 - val_loss: 2.6444 - val_acc: 0.2400\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2571 - acc: 0.5071 - val_loss: 2.6620 - val_acc: 0.2433\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2570 - acc: 0.5029 - val_loss: 2.6621 - val_acc: 0.2433\n",
      "Epoch 2893/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.2575 - acc: 0.5057 - val_loss: 2.6587 - val_acc: 0.2433\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2565 - acc: 0.5057 - val_loss: 2.6901 - val_acc: 0.2467\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2562 - acc: 0.5100 - val_loss: 2.6721 - val_acc: 0.2400\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2565 - acc: 0.5071 - val_loss: 2.6716 - val_acc: 0.2400\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2562 - acc: 0.5129 - val_loss: 2.6949 - val_acc: 0.2400\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2557 - acc: 0.5071 - val_loss: 2.6859 - val_acc: 0.2400\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2568 - acc: 0.5143 - val_loss: 2.6686 - val_acc: 0.2433\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2558 - acc: 0.5100 - val_loss: 2.6703 - val_acc: 0.2433\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2561 - acc: 0.5129 - val_loss: 2.6581 - val_acc: 0.2400\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2563 - acc: 0.5100 - val_loss: 2.7008 - val_acc: 0.2433\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2565 - acc: 0.5071 - val_loss: 2.6542 - val_acc: 0.2367\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2560 - acc: 0.5100 - val_loss: 2.6548 - val_acc: 0.2367\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2557 - acc: 0.5114 - val_loss: 2.6754 - val_acc: 0.2433\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2560 - acc: 0.5071 - val_loss: 2.6708 - val_acc: 0.2400\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.2552 - acc: 0.5043 - val_loss: 2.6730 - val_acc: 0.2467\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2554 - acc: 0.5171 - val_loss: 2.6904 - val_acc: 0.2367\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2558 - acc: 0.5057 - val_loss: 2.6429 - val_acc: 0.2433\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2557 - acc: 0.5143 - val_loss: 2.6606 - val_acc: 0.2400\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2562 - acc: 0.5043 - val_loss: 2.6338 - val_acc: 0.2367\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2562 - acc: 0.5071 - val_loss: 2.6370 - val_acc: 0.2333\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2562 - acc: 0.5071 - val_loss: 2.6599 - val_acc: 0.2400\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2556 - acc: 0.5057 - val_loss: 2.6597 - val_acc: 0.2400\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2560 - acc: 0.5114 - val_loss: 2.6354 - val_acc: 0.2367\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 1.2556 - acc: 0.5057 - val_loss: 2.6891 - val_acc: 0.2433\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2554 - acc: 0.5143 - val_loss: 2.6663 - val_acc: 0.2433\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2555 - acc: 0.5114 - val_loss: 2.6739 - val_acc: 0.2433\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2549 - acc: 0.5100 - val_loss: 2.6812 - val_acc: 0.2400\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2554 - acc: 0.5100 - val_loss: 2.6562 - val_acc: 0.2367\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2551 - acc: 0.5143 - val_loss: 2.6476 - val_acc: 0.2400\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2549 - acc: 0.5057 - val_loss: 2.6757 - val_acc: 0.2400\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2557 - acc: 0.5129 - val_loss: 2.6603 - val_acc: 0.2367\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.2552 - acc: 0.5057 - val_loss: 2.6749 - val_acc: 0.2400\n",
      "Epoch 2925/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2548 - acc: 0.5100 - val_loss: 2.6990 - val_acc: 0.2433\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2549 - acc: 0.5100 - val_loss: 2.6726 - val_acc: 0.2433\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2551 - acc: 0.5143 - val_loss: 2.7131 - val_acc: 0.2467\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2550 - acc: 0.5114 - val_loss: 2.6608 - val_acc: 0.2367\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2547 - acc: 0.5100 - val_loss: 2.6737 - val_acc: 0.2433\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2539 - acc: 0.5029 - val_loss: 2.7046 - val_acc: 0.2467\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2551 - acc: 0.5100 - val_loss: 2.6888 - val_acc: 0.2400\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2547 - acc: 0.5043 - val_loss: 2.6662 - val_acc: 0.2400\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2544 - acc: 0.5100 - val_loss: 2.6667 - val_acc: 0.2367\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2554 - acc: 0.5114 - val_loss: 2.6889 - val_acc: 0.2400\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2556 - acc: 0.5100 - val_loss: 2.6660 - val_acc: 0.2400\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2542 - acc: 0.5114 - val_loss: 2.6761 - val_acc: 0.2433\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2549 - acc: 0.5114 - val_loss: 2.6884 - val_acc: 0.2400\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2557 - acc: 0.5100 - val_loss: 2.6689 - val_acc: 0.2400\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2546 - acc: 0.5100 - val_loss: 2.6822 - val_acc: 0.2467\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2546 - acc: 0.5114 - val_loss: 2.6676 - val_acc: 0.2333\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2536 - acc: 0.5100 - val_loss: 2.6612 - val_acc: 0.2400\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2567 - acc: 0.5114 - val_loss: 2.6821 - val_acc: 0.2367\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2541 - acc: 0.5129 - val_loss: 2.6974 - val_acc: 0.2400\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2541 - acc: 0.5143 - val_loss: 2.6786 - val_acc: 0.2400\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2543 - acc: 0.5071 - val_loss: 2.7003 - val_acc: 0.2467\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2539 - acc: 0.5071 - val_loss: 2.6974 - val_acc: 0.2400\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2544 - acc: 0.5129 - val_loss: 2.6642 - val_acc: 0.2433\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2541 - acc: 0.5057 - val_loss: 2.6837 - val_acc: 0.2400\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2549 - acc: 0.5129 - val_loss: 2.6570 - val_acc: 0.2333\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2537 - acc: 0.5157 - val_loss: 2.6724 - val_acc: 0.2433\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.2543 - acc: 0.5114 - val_loss: 2.7071 - val_acc: 0.2400\n",
      "Epoch 2952/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 227us/step - loss: 1.2541 - acc: 0.5100 - val_loss: 2.6655 - val_acc: 0.2333\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2537 - acc: 0.5043 - val_loss: 2.6891 - val_acc: 0.2433\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2554 - acc: 0.5057 - val_loss: 2.6799 - val_acc: 0.2367\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2538 - acc: 0.5114 - val_loss: 2.6488 - val_acc: 0.2367\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2542 - acc: 0.5129 - val_loss: 2.6939 - val_acc: 0.2400\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2538 - acc: 0.5129 - val_loss: 2.6865 - val_acc: 0.2400\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2541 - acc: 0.5057 - val_loss: 2.6789 - val_acc: 0.2433\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2539 - acc: 0.5100 - val_loss: 2.6703 - val_acc: 0.2367\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2541 - acc: 0.5143 - val_loss: 2.6741 - val_acc: 0.2400\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2533 - acc: 0.5157 - val_loss: 2.6709 - val_acc: 0.2367\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2538 - acc: 0.5071 - val_loss: 2.6897 - val_acc: 0.2400\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2535 - acc: 0.5114 - val_loss: 2.6821 - val_acc: 0.2367\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2534 - acc: 0.5071 - val_loss: 2.6762 - val_acc: 0.2367\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2539 - acc: 0.5100 - val_loss: 2.5944 - val_acc: 0.2333\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2540 - acc: 0.5086 - val_loss: 2.6586 - val_acc: 0.2300\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2536 - acc: 0.5086 - val_loss: 2.6573 - val_acc: 0.2400\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2534 - acc: 0.5071 - val_loss: 2.6939 - val_acc: 0.2400\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2533 - acc: 0.5114 - val_loss: 2.6888 - val_acc: 0.2400\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2526 - acc: 0.5100 - val_loss: 2.7058 - val_acc: 0.2433\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2532 - acc: 0.5086 - val_loss: 2.6568 - val_acc: 0.2400\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2533 - acc: 0.5086 - val_loss: 2.6669 - val_acc: 0.2400\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2535 - acc: 0.5114 - val_loss: 2.6767 - val_acc: 0.2367\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2525 - acc: 0.5129 - val_loss: 2.6768 - val_acc: 0.2400\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2527 - acc: 0.5114 - val_loss: 2.6846 - val_acc: 0.2433\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2530 - acc: 0.5129 - val_loss: 2.6894 - val_acc: 0.2367\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2523 - acc: 0.5114 - val_loss: 2.7018 - val_acc: 0.2400\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2530 - acc: 0.5143 - val_loss: 2.6898 - val_acc: 0.2433\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2529 - acc: 0.5171 - val_loss: 2.6565 - val_acc: 0.2400\n",
      "Epoch 2980/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2523 - acc: 0.5100 - val_loss: 2.6987 - val_acc: 0.2467\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2527 - acc: 0.5086 - val_loss: 2.6854 - val_acc: 0.2333\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2530 - acc: 0.5071 - val_loss: 2.6625 - val_acc: 0.2400\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2528 - acc: 0.5114 - val_loss: 2.6928 - val_acc: 0.2333\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2524 - acc: 0.5100 - val_loss: 2.6872 - val_acc: 0.2433\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.2523 - acc: 0.5100 - val_loss: 2.7030 - val_acc: 0.2467\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2527 - acc: 0.5143 - val_loss: 2.6866 - val_acc: 0.2367\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2525 - acc: 0.5129 - val_loss: 2.6977 - val_acc: 0.2400\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.2526 - acc: 0.5143 - val_loss: 2.6717 - val_acc: 0.2333\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.2522 - acc: 0.5014 - val_loss: 2.6777 - val_acc: 0.2400\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2523 - acc: 0.5129 - val_loss: 2.6918 - val_acc: 0.2433\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2525 - acc: 0.5143 - val_loss: 2.6787 - val_acc: 0.2400\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2519 - acc: 0.5157 - val_loss: 2.6807 - val_acc: 0.2400\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.2520 - acc: 0.5071 - val_loss: 2.6843 - val_acc: 0.2400\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2525 - acc: 0.5086 - val_loss: 2.6863 - val_acc: 0.2400\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.2516 - acc: 0.5100 - val_loss: 2.6901 - val_acc: 0.2467\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.2521 - acc: 0.5114 - val_loss: 2.7087 - val_acc: 0.2467\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2518 - acc: 0.5129 - val_loss: 2.6691 - val_acc: 0.2400\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.2523 - acc: 0.5129 - val_loss: 2.6969 - val_acc: 0.2333\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.2519 - acc: 0.5100 - val_loss: 2.6868 - val_acc: 0.2400\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.2524 - acc: 0.5114 - val_loss: 2.6829 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step\n",
      "\n",
      "loss : 2.971297388458252\n",
      "accuray : 0.2595\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 548us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 257us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.9469 - acc: 0.225 - 0s 244us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping() # 조기종료 콜백함수 정의\n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step\n",
      "\n",
      "loss : 1.9111000816345214\n",
      "accuray : 0.199\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 567us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 248us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 238us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 241us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 240us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 236us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 20) # 조기종료 콜백함수 정의\n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEKCAYAAAChTwphAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4VFX6xz8nPSENQgepgvQiyA8FwYIKdsSCoqirq65iWV17w3VdWbHsWlbXXhZ7WXFFdFFRUVRAwSC9SqgJkF5n5vz+eOdk7kwmU5IZJiH38zzz3Ln3nnvvmYjznbec91Vaa2xsbGxsbJoDcbGegI2NjY2NTajYomVjY2Nj02ywRcvGxsbGptlgi5aNjY2NTbPBFi0bGxsbm2aDLVo2NjY2Ns0GW7RsbGxsbJoNtmjZ2NjY2DQbbNGysbGxsWk2JMR6AuESFxenU1NTYz0NGxsbm2ZFeXm51lo3e0Ol2YlWamoqZWVlsZ6GjY2NTbNCKVUR6zlEgmavujY2NjY2LQdbtGxsbGxsmg22aNnY2NjYNBuaXUzLHzU1NeTl5VFZWRnrqTRbUlJS6Nq1K4mJibGeio2NjU29HBSilZeXR0ZGBj169EApFevpNDu01uzdu5e8vDx69uwZ6+nY2NjY1MtB4R6srKwkJyfHFqwGopQiJyfHtlRtbGyaPAeFaAG2YDUS++9nY2PTHDhoRCsYTmc5lZV5aO2I9VRsbGxaKMuXw6JFDbv2vvtgwYLIzqc50mJEy+WqpqZmFy5XVcTvXVhYyD//+c8GXXvyySdTWFgY8viZM2fy8MMPN+hZNjY2seVPf4Lf/S7868rKRLQaKngHEy1GtOLikgFwuSIftwkkWk6nM+C18+bNIzs7O+JzsrGxaXqsWwcbN0JVmL+dV60CrWHw4OjMqzlhi1YEuO2229i4cSPDhg3j5ptvZuHChRx77LFccMEFDHb/KzvzzDMZMWIEAwcO5Nlnn629tkePHhQUFLBlyxb69+/P73//ewYOHMiJJ55IRUXgqivLly9n9OjRDBkyhMmTJ7N//34AHn/8cQYMGMCQIUOYOnUqAF999RXDhg1j2LBhDB8+nJKSkoj/HWxsbOqnogK2bQOXCzZsCO/a3FzZ2qJ1kKS8W1m//gZKS5f7Ped0lqFUPHFxKWHdMz19GH36/L3e87NmzWLlypUsXy7PXbhwIT/++CMrV66sTSF/8cUXadOmDRUVFRxxxBFMmTKFnJwcn7mv54033uC5557j3HPP5b333uPCCy+s97nTp0/niSeeYPz48dxzzz3cd999/P3vf2fWrFls3ryZ5OTkWtfjww8/zFNPPcWYMWMoLS0lJSW8v4GNjU3j2LzZ837NGhg40Pv8jz/CGWfAzz9Dx47e53JzITUVeveO/jybOi3G0gJQKg5wHZBnjRo1ymvN0+OPP87QoUMZPXo027ZtY/369XWu6dmzJ8OGDQNgxIgRbNmypd77FxUVUVhYyPjx4wG4+OKL+frrrwEYMmQI06ZN49///jcJCfK7ZMyYMdx44408/vjjFBYW1h63sbE5MFitqzVr6p7/9lvYtQuWLq17LjdXRC4+PnrzA1BKTVRKrVVKbVBK3ebn/FVKqVyl1HKl1CKl1AD38ROUUsvc55YppY6L1hwPum+uQBZRZeVv1NQUkJ4+POop3q1atap9v3DhQhYsWMDixYtJS0vjmGOO8bsmKjk5ufZ9fHx8UPdgfXz88cd8/fXXzJ07l/vvv59ff/2V2267jVNOOYV58+YxevRoFixYQL9+/Rp0fxsbm/AxopWd7V+0jCW2ejWceqr3udxcOOWU6M5PKRUPPAWcAOQBS5RSc7XWqyzDXtdaP+MefzrwKDARKABO01rvUEoNAj4FukRjni3K0hK3oCviae8ZGRkBY0RFRUW0bt2atLQ01qxZw/fff9/oZ2ZlZdG6dWu++eYbAF577TXGjx+Py+Vi27ZtHHvssTz00EMUFhZSWlrKxo0bGTx4MLfeeisjR45kjb//a2xsDiI2b4Y33oj1LDxs2ABt2sARR/gXLeNY8T23ezfs2XNA4lmjgA1a601a62rgTeAM6wCtdbFltxWg3cd/1lrvcB//FUhRSiUTBQ46SysQ1mSMuLjI1djLyclhzJgxDBo0iEmTJnGKz0+iiRMn8swzzzBkyBAOO+wwRo8eHZHnvvLKK1x11VWUl5fTq1cvXnrpJZxOJxdeeCFFRUVorfnjH/9IdnY2d999N19++SXx8fEMGDCASZMmRWQONjZNlaeegkcegdNOg/T0WM8G1q+HQw+F/v3hxRclG9Dq8DGWlq9oRTAJI0EpZXU+Pqu1ftay3wXYZtnPA/7P9yZKqWuAG4EkwJ8bcArws9Y68uuLAKW1jsZ9o0arVq20bxPI1atX079//6DXulxVlJXlkpzcnaSkdtGaYrMl1L+jjU1z4Pzz4c03JUY0YkSsZwM9e8JRR8HYsXD11ZCXB13cDjStISND1mO1bg1793oE7bHH4MYbxeJq377hz1dKlWutWwU4fw5wktb6cvf+RcAorfW19Yy/wD3+YsuxgcBc4ESt9caGz7Z+Wo57sLIStXsfuFRUFhjb2Ng0LXa4nVUN8YQ7nSIkkaKqCn77TSwtE0q2zqugQASrRw/Yv1/2Dbm5IlaNEawQyQMOsex3BXbUMxbEfXim2VFKdQU+AKZHS7CgpYnW9u0kVCeitV0Y1sbmYKeholVVBWPGwOWXR24uW7bI+iyraK1e7TlvXIPGa2+dc27uAVuftQToo5TqqZRKAqYiVlMtSqk+lt1TgPXu49nAx8DtWutvoznJliNaaWkAxFfF25aWjU0TYPlyWXAbDbSGnTvlfbiidffd8MMPDS+ZtGwZ+CYHm8zBQw+VNViZmd7zMqJ18snec3Y64ddfD4xoaclQm4Fk/q0G3tZa/6qU+rM7UxBghlLqV6XUciSuZVyDM4BDgbvd6fDLlVJRsQ1bjmglJkJiIvGVkojR3GJ5NjYHEzt2wMiR8Nxz0bl/SYm42yA80fryS3j4YRGVjRuhujq85+7YAaNGwV//6n3cKlpKibXlT7TGjZNFxObcxo0i7AeqEobWep7Wuq/WurfW+gH3sXu01nPd76/XWg/UWg/TWh+rtf7VffwvWutW7uPmtScac2w5oqUUpKWhKh2ARjI6bWxsYsGiRWJF+FljHzIOBzz9tFg2vhjXYJcuUu/PEcIql6IimD4d+vSB2bNlfuGWW1q0SNyA//63d0xswwYRwrZtZb9/f2/R2rJFzmVmwmGHeVyHJnNwyJDw5nEw03JEC6BVK1RlDbiwXYQ2NjHEuN5++61h12/c6MnCu//+uueNaB13nFhLAYrL1PLhh5LR99xznmzDcF2L5nNt3iwuRsP69SKGJiOwXz/Yvl0sQjPeFNCxWmFvvilC5lvyqSXTskQrLQ0FtS7CWJJez8KR+o7b2DRXnE6YMgXee89zrCGiddtt8sXfp4+4y9auFatk7dq6Y62iBaGJz/z5Em86+mi5r+91V10l6eeB+OYbWTyckgJz5niOb9ggrkGDScZY5a41sXmzZA6ac1u2wIoV8je75hpxGdoIURMtpdQhSqkvlVKr3YG76/2MmaaU+sX9+k4pNTRa8wHAXVoprkrFXLRsbFoK770H778Pf/ub7BcXyxeyUqGLltMprsDkZIkZXXyx3GPKFBGEmhrv8SYJ49hjZWtNbPBTQQ2nEz79FE46SeaVng5du3quKy4WC+xPf6o/QaOoCH75RZIpTjsN3npL3JI1NSJCVtE68kiIi4OPPhJ34tat3paW1nDllfJ5r6/zzdmyiaal5QBu0lr3B0YD15jiihY2A+O11kOA+4FniSaJiZCUREJlPC5XecRue+utt3r105o5cyaPPPIIpaWlHH/88Rx++OEMHjyYDz/8MOR7aq25+eabGTRoEIMHD+att94CYOfOnYwbN45hw4YxaNAgvvnmG5xOJ5dccknt2MeC/Ry0sTlAaA2zZsn7JUvETbZ4sXxRH3cc7NsHpaXB75ObK8Jx++1iwTz9NHTrJl/wDoe4C63s2CHC0727rG8y4jNjBgwaVDfBYulSmcvEiZ5jVjedmXNKClx0kczFl++/lzFjx8IFF0B+vlhvM2eKKBrrDaBDB5gwAV5/XdyE1dUe0TLr+3/4QRpGdugQ/O/TkohaGSet9U5gp/t9iVJqNVImZJVlzHeWS75HFrM1jhtukFza+qioIN7lJCkFdHw6IZXNHTYM/l5/Id6pU6dyww03cPXVVwPw9ttvM3/+fFJSUvjggw/IzMykoKCA0aNHc/rpp4dUrPf9999n+fLlrFixgoKCAo444gjGjRvH66+/zkknncSdd96J0+mkvLyc5cuXs337dlauXAkQVidkG5tw0Ro+/xyOP967DJE/PvtMWm38+c9w773yJe1wSLXyc8+V+2zb5vmirg9j3Ywd633culDXWv95xw7o3NkzZs0aec7zz8vz58yBSy/1jJ8/XyyfE07wvvcrr8jnXbRI5vzBB7KW6tpr5ZzvHOPjYfRo+X2clSWWYHW1WIbnnus9/oIL4JJLJG4FHtEysa+4OLHsbLw5IDEtpVQPYDjwQ4BhlwGf1HP9FUqppUqppY5Q0oACER+Pcmn5l6gDdxUOleHDh7Nnzx527NjBihUraN26Nd26dUNrzR133MGQIUOYMGEC27dvZ/fu3SHdc9GiRZx//vnEx8fToUMHxo8fz5IlSzjiiCN46aWXmDlzJrm5uWRkZNCrVy82bdrEtddey/z588nMzIzI57Kx8cfixfLl7jb+AzJrlmTw3XorHHOMiMU338Dw4Z7kglBchIsWibuuWzfv4/5iTyCi1amTvO/XT7LxHnlE9vv0EVeltan4J5+I29Ha4q5/f0mU2LFDnj9sGJx4ItxyC7z6at3kjkWL5HOlp4tb79JLJSLx9tvw8styzMrkyWK5mXkZ0UpNlWddconnmI2HqBfMVUqlA+8BN/hUCLaOORYRrbH+zruLOj4LUnsw4AMDWESAOJ7Xr6e6KyS06UZSUmTWv5199tm8++677Nq1q7Zb8Jw5c8jPz2fZsmUkJibSo0cPvy1J/FHfOrJx48bx9ddf8/HHH3PRRRdx8803M336dFasWMGnn37KU089xdtvv82LL74Ykc9lY+PLrl2ynTMH3P/U/fLDD7BwITz6KCQliWXx+99LDOr66z0CFEy0tBahGz++rmWXmSkWlT/R+j93qdd+/cT198wzMG2aWEpTp0q24FlnSZ2/H38US9CKsdx++UU+y5VXyv7UqSLG33zjSZ6orhb34FVXea5/+GF46CGxuvyRmSmxr3fekc/Vvbvn3OLF0e+d1VyJqqWllEpEBGuO1vr9esYMAZ4HztBa743mfIDaZIz4qjiczrIgg0Nn6tSpvPnmm7z77rucffbZgLQkad++PYmJiXz55Zds3bo15PuNGzeOt956C6fTSX5+Pl9//TWjRo1i69attG/fnt///vdcdtll/PTTTxQUFOByuZgyZQr3338/P/30U8Q+l42NL/v3y3b+fO8aeb589ZVsL7lEtlOmyBe41uLm69RJvpiDidbWrSJCvq5Bg+9CXVMNw7gHjeuxqkqspLPPlg7As2bJ2P/9T7bWeJa5L4hLs6LC8/xBg8T1Z03I+OknSfA4+mjPsfj4+gXLcMEFsu3c2dsSS04Gu0+rf6L2Z1ESuHkBWK21frSeMd2A94GLtNbrojUXLxISIDmZhEoXFREUrYEDB1JSUkKXLl3o5PZLTJs2jdNOO42RI0cybNiwsJouTp48mcWLFzN06FCUUjz00EN07NiRV155hdmzZ5OYmEh6ejqvvvoq27dv59JLL8Xlkq7MDz74YMQ+l42NL/v2ydbhgHff9bYurOzZI+6v7GzZb91aMus+/FAEICFBXIfBRMvdMq5e0erf37OYVylxplRUeMe0AM48Ewa4U8FuuUUsp06dpHJGTo5U6LDSqZNUXn/3Xe/nx8dLtXaraLmbhjNmTODP4sukSfL3MRabTXCiqeVjgIuAXHedKoA7gG4A7u6X9wA5wD/dyQkOrfVIP/eKLBkZxO3bi3bV4HI5iIuLzJ8h1yxfd9O2bVsWL17sd2xpPSlT5rhSitmzZzN79myv8xdffDEXX3xxnets68rGUFkpX96+MZRIsX+/CE6fPuIirE+08vMlc8/q0nvgAYkLmYy4bt38i1ZlpYhQaqqIQ1aWWDj+6NdPhGrXLhEas0bLiFb37lLhYsoUzzUXXywZh8ZqPP74uu44U25pyRL5rNYsvrFjJQ62d68I3rvvSjwr3Ey/5GSJd2VkhHddSyaa2YOLIHBynrtvSwRrKYdIZiaqoIC4SnCllREXl3XAp2BjEy2mTJEv0ldfjc799+8Xq2naNLjrLnHfWeMxhvx8aOfTtm7gQO/qDt26SSzIl7POkjjTCy+IaI0ZI9l0/rBmEPoTLaXqZuElJ3vWjQXCiJavlWf2v/vOM+bhh4Pfzx9nnBF8jI2HllURw5CZiQYSyoloXMvGpimQm+upWRcNjGiZeMxtt8GTT0rsx5o/5E+0fOnWTVLR3Z5tQATgk0/k2JlnStWI+lyDULc/lREtkz3YGMy9fZ8/apQkl3zzjXxupQInpdhEjoMm1Ke1Dmn9EwAJCai0NBLKK6lyhrCysQVgV70/OHC5JAmhKoqlNY1o9ewpbrU33/SsNRo82FORfM+e4OuvunWTihG7dnkso1mzJM6zfr1k3z3xhKdlhz+6dJH8KiNaphpGJERr3Di594QJ3sdTUiQG9s03EuM75hhPF2Kb6HJQWFopKSns3bs3vC/ezEziKly4aspa/Be21pq9e/eSkpIS66nYNJKCAkmQ2LOnbmmjSLFvn4gWSAZhfr5YRiBWk8HEtALhm/a+Zo0s4J0xQ1ycf/ubVMwYGqDAm2+rjx07JJ08EmU8x46VtVq+68PMue+/lyryxuq0iT4HhaXVtWtX8vLyyM/PD/2iykrIL6C6BhIycomLC5KbepCTkpJC166NL0hiE1uMlQGwe7csyI00+/dD377yPiFBWmoYi8q45srKJIMvmHvQxMJ++00qSTz0kFgx113nGVNfLMtKv36eLENrNYxIUJ8DZ+xYmW9SkneSR3NGKTUR+AcQDzyvtZ7lc/4q4BrACZQCV2itV7nP3Y6st3UC12mtP43GHA8K0UpMTKRnuEvHKyvRRx1J3qlVqMeeoGvXGdGZnI3NAcSIhnkfLdEylpahY0fZGtE0vx9DiWmBiNa6dZK6ftVVwa/zpX9/yWT85JPIi1Z9mPT2k0+u+/dojiil4oGngBOAPGCJUmquESU3r7szv3F3M34UmOiuKzsVGAh0BhYopfpqHaGyQxYOCvdgg0hJQR09jpyfEiks/DLWs7GxiQi+ohVpXC4oLKz7JZ2cLBaXeeYed8/aYOKTmSnp7Bs3SjZiRoYUxQ2XSy6RWNrJJ0vWYSTiWcFo00YyNGfNCj62mTAK2KC13qSlS+6bgFduo09Vo1aAia2cAbypta7SWm8GNrjvF3FarmgBTJhA2qYayjd8jtau4ONtbJo40RatkhIRLn+WRefOnmcaSytYTAvE2nrhBam0/txzDROcLl1ErG64QWJ6ffqEf4+GcNFF3tXbmzldAEtUkjz3MS+UUtcopTYCDwHXhXNtJGjZouWu25L5XRGlpStiPBkbm8azY4cISnx840RryxZxtfnmKJlqGP5Ey7pGKlT3IHgyCC+9VNZnNZSUFGnSuG6dXR29HhJM4XH36wqf8/6id3Wy1LTWT2mtewO3AneFc20kaNmiNXgwuktHcn6AwsIvYj0bG5tGY+JYHTp4J2WEy113iavt7LOl6oPBVJBo06buNf4srVBE66ijpNrFP/7R8Pla6dOntsSojTcOrfVIy8u3f2EecIhlvysQ6KfPm8CZDby2wbRs0VIKNelUWi+LY/+eBbGejY1NozGFYq0C0hBWrRLL6aOPYMgQTxsOI1r1uQd37ZKWH/n5EucKJe38jjukkrpdyijmLAH6KKV6KqWSkMSKudYBSimr4/UUYL37/VxgqlIqWSnVE+gD/BiNSbZs0QKYNImEMhf6u69wuaK0sMXG5gBhMucaI1ouF6xdKxUevvxS7mPWYQUTLZdLBGvPnrp1BwMR6jib6KG1dgAzgE+B1cDbWutflVJ/dmcKAsxQSv3qrid7I3Cx+9pfgbeRJr/zgWuikTkIB0nKe6OYMAGdEE/rxRWUTF9GVtboWM/IxqZBOJ2eyhLJyVIXryHk5UF5uax9OvJIaa9hFv8GEy0QkQulhJNN00NrPQ+Y53PsHsv76wNc+wDwQPRmJ9iWVmYmesxo2vwAhYWfx3o2NjYNJj9fhMtYWgUF0pwwXFavlm2/frKwt2tXj2gFS8QAW7RsoostWkDcyaeTvglK1nwU66nY2DQYa3VzIyCmy3A4mHJIplistX3I/v1ieaWl1b3OtrRsDgS2aIF0YgMSFyzB4SgOMtjGpmliFS2rgFjZu1eqTgRizRqxpIzo+IpWmzb+Y1CmKsaOHRLTskXLJhrYogUwaBCurh3I+c7F/v126rtN88Ra3bw+0frnP2VBrHEB+mPNGrGyjDB17w7bt8uiXX8lnAyJiZJ8sXGjxMRCWVhsYxMutmiBpL6fdQ5tlsL+3+YGH29j0wQxAtWxY/2itXSpbK2t4n0xomXo1k1iZTt3BhYtkOeucK/Tty0tm2hgi5Ybdfa5xFUD8z5q8a1KbJonO3aIdZOYKHUAExLCF63CQomD+YoWSIdia1sSf3Tq5LHibNGyiQa2aBmOOgpn2wyyvyigvHxtrGdjYxM21urmcXFicVmrYuzcKWPi4uoXLZOEYW3eaK3EHoql5XDIe1u0bKKBLVqG+Hj06aeS8z3s3/nfWM/GxiZsfFty+C4wXrZMtmeeCZs2+V987Js5CHCIuzhPqKJlsGNaNtHAFi0LCeddQnwl1Mx7I9ZTsbEJG1PCyeArWkuXipU1w9067ttv695jzRpxL1rb06WnS8bg5s1QVOS/7qD1mQbb0rKJBrZoWTnmGJyZyaR+sgKnsyzWs7GxCRmHQzoVBxOt/v2l425amn8X4Zo1UnA2wadWTrdukJsrVd9DsbSSkuxagjbRwRYtK0lJOCYdTc63Tvbtmhd8vI1NE2HPHqn7Z+1F1amTJE5UVorYLF0KI0aIJTV6tKc9vRXfzEFDt25S1BZCE6127ex6gjbRwRYtHxKnzSCxBCrnPhPrqdg0I8rK4IwzpDp6Q3G5YPp0+K8lpFpdLe1BrHUEi4rg9NO911pt3y5bX0sLPPGr3bth5Eg5NnaspKYXW9bSFxfDhg31i1aZ2/kQLHsQ7HiWTfSImmgppQ5RSn2plFrtrgpcp9CiUqqfUmqxUqpKKdUk2rbFTTwZR3Yyye8vwuVyxHo6Ns2EJUtg7lx4/PGG3+PDD+G11+Cvf/Ucmz8f3nsPZs/2HHv7bWkZ8vLLnmOLF8t28GDPsWOPFTfg9ddLV18QSwtEtFwu+P57z/hrrxWL7MwzqYPJIITAotWhg1hYdjzLJlpE09JyADdprfsDo4FrlFIDfMbsQ9o1PxzFeYRHYiI1Z4wnZ1E1Rds/i/VsbJoJJuvunXcaVqRWa5g1S94vXizWEcDrr8t23jxPhfU5c2Q7f77n+k8+kbbv1gSKnj3h0UdhwQK4+WZJwhg2TM6NHi1xq/vvFyvt7bfh1VfhzjvhiCPqzq97d8/7QIkYCQnQpYu3xWdjE0miJlpa651a65/c70uQ/ixdfMbs0VovAZpUI6ukS/9EfCVUvR2hVqo2Bz1GtPbtg88a8Fvnyy/FGrr9dtl/4w0oKRHr7cgjRQjffx+2bYOvvxZR+OUXEZyKCli4ECZOrHvfK64QV+LGjTBggKfQbUYGvPAC/PSTNHm88koYNQruvtv//EK1tAA++ADuuy/0z/7Szy/xuw9/F/oFNi2aAxLTUkr1AIYDPzTw+iuUUkuVUksdjui77OKPPp7qTqkkv/e1XR3DJiTWrBHXXE6OxxIKh1mzxLV2zz1w9NFyj//8RwRp9mzJ6JszB958U6yyJ5+U6z79VESsstK/aCkFzz8vIjd+vPe56dPh55+hVy8p0zRnjiRp+CMc0Ro50nt8MBZuXchH6+wOC00BpdREpdRapdQGpdRtfs7fqJRapZT6RSn1uVKqu+XcQ+5Q0Gql1ONKRSkVR2sd1ReQDiwDzgowZibwp1Dul5aWpg8EJddM0q44dMmmzw/I82yaDy6X1o89pvVvv3mOde+u9QUXaP2HP2idmqp1SYnWW7dqfe+9Wu/bF/h+y5ZpDVrPmiX7Tz8t+717a92jhzxv5kytldK6Z0+tR42SY507a33OOVpff73WKSlal5fX/4ziYq2rq/2fczi03r8/8BydTq0TE7VOTg48riGc9855Ov2v6ZG/sY0XQJkO/F0dD2wEegFJwApggM+YY4E09/s/AG+53x8FfOu+RzywGDgm0PMa+oqqpaWUSgTeA+Zord+P5rMiTfKlt6BcUPnqQ7Geik0TY9cu+OMfPUkX5eVSl69fP7jgArGOZswQt9t998Hvfy/WUX28847Egq66SvbPPlv2N26E888Xa+n88+UemzfDtGlybOJEcUV+/LFYUamp9T8jI6N+Kyo+HrKzA39m0wwymJXVEKqcVVTUVET+xjbhMgrYoLXepLWuBt4EzrAO0Fp/qbUud+9+D3Q1p4AUROySgURgdzQmGc3sQQW8AKzWWj8aredEi8QRx1DRJ53kd7+yXYQ2XpgFu2Zx7rp1su3fH446Slxjr7wiMaQbb5TsP2umny+LFklWX1aW7LdtCyedJO8vuEC2ffuK2y0uDs49V45NnCjp7xs21LaEiyrdukVJtBxVOLWTGmeTCm23RLoA2yz7efjkIfhwGfAJgNZ6MfAlsNP9+lRrHaABTsNJCD6kwYwBLgJylVLL3cfuALoBaK2fUUp1BJYCmYBLKXUDYo42iU6M1eedRNZf3qN0+VzSh58R/AKbFoERrWXLxMrybU//9NMiJFdfLRbRsmVw3XUwbhz07u19r8pKScC47jrv4/d8ZrjGAAAgAElEQVTfL7GtQYM8xx55BFau9DRbPOEEsZKcTv/xrEhzxx0ikpGmylkFQKWjksT4esxBm0iQoJRaatl/Vmv9rGXfXwzK7y92pdSFwEhgvHv/UKA/Hsvrf0qpcVrrrxs/bW+iJlpa60X4/yNYx+zC8yGbHKmX3oN+4D1qXpoNtmjZuDGiVVMjgrNmjYjVoYfK8ZNP9h7/6qviKrz5ZskAtLJsmWQGjh3rfXz4cHlZGTdOXobsbLHstm8XSyzanHhidO5b5RDRqnBUkJFs136KIg6t9cgA5/OAQyz7XYE6ZZWVUhOAO4HxWusq9+HJwPda61L3mE+QpU4RFy27IkYAknoNoXRUG1Lf/wHtcsV6OjZNhB07PCWKFi0S0erZE1JS/I/v1g3OOUfS2n3/GZlSSkcd1bC5vPqqxLSac8kkq6VlE1OWAH2UUj2VUknAVMCrK65SajjwL+B0rfUey6nfgPFKqQR3LsN4ZJlTxLFFKwjO888kZbuD8s9fivVUbJoIO3dKmaJBgzyi5a/0kZWxY6XBom+Zp0WL5NqGVpDo0SP4s5sSX2/9mmvnXet1rNbSilEyxsvLX+aR7x6JybObElprBzAD+BQRnLe11r8qpf6slDrdPWw2khH+jlJquVLKiNq7SOZhLpJ1uEJrHZV1DLZoBaHVRffgTAbHy0/Eeio2TQTTt2rsWKkJuG5daKIF3pXVXS5pD3L00dGba1Nj3vp5PLnkSa/kJmNpVThiI1pzcufw0nL7RymA1nqe1rqv1rq31voB97F7tNZz3e8naK07aK2HuV+nu487tdZXaq37a60HaK1vjNYcbdEKQmKb7hQf35lWc39BF0chCm3T7LCKVkmJJFNYO/36o1cvKSZrFa1ffxXryzeedTBjrCojVNZjsXIPllaXUlZjtyJqLtiiFQKuGVeSUKqpePLOWE/FpglgFS1DMEtLKRlvbQdiBKwliZYRJqtA1VpaMXIPllSVUFpdGpNn24SPLVohkH3inygaEk/iky9LyphNi8XhkN5VnTpJEVnTij6UuNLYsdKy/rffZH/RIrmPtchtc2B/xX4u+c8l7K/YH/a1RqCMdWV9HytLq6S6hLJq29JqLtiiFQLx8WmUXHUsiTvLcL3171hPxyaG7N4tlSlMFfNjjpH3OTnBrzUW1bffQn6+1A0cN675Zf59vP5jXlnxCt9t+y74YB8CWloximmVVJVQ4ajApe0M4eaALVohkn7enZR1A+ff7gtck8emWbN0qccS8odZo2VE69FH4YsvQrv3kCGQni4uwssvl3jYnc3Q47xsxzIA9lc23NLyEq0YZg9qrSmpLgGgvKY8yGibpoAtWiGS1Xocu6a1JXHlVvj881hPxyZKTJ4cWEh8RattW+ljFQoJCbIe66WXpOXIrFneTRubC0t3SlGFfRX7wr7W1xXodDlxaqfXsQNJlbMKh7vZq+0ibB7YohUiSsURN/1KqtqC8y/3xno6Ng2ktFQ6+ZaU1D1XWQl5ebB+ff3X+4pWuIwdK8+ZMEHm0dxwupz8vPNngAbFtIww1ca2LFmEsXAPllR5/iHYGYTNA1u0wqBj99+x7VyI/+o7T39zm2bFwoVSnf3LL+uey8uT7ZYt9V+/Y4eUbGrfvmHPP/dcKW778styn+bG2r1ra7/cI+EetCZkxMLSMq5BsC2t5kIz/N8mdqSm9qLiouOpyYpD/+UvsZ6OTQMwwrSjTkU1Tyxr924phOuPnTulWWN8fMOef9hhMG+etKRvjizdIa7BOBXXMNHycQ96WVoxiGnZllbzwxatMOl06HXkTXGh5s2Ttq82zQojWjt31j1nTcCwWlv5+Z6VDmaNVktl2Y5lpCWmMbDdwEa5B/1ZWjFxD9qWVrPDFq0wyck5hfzzuuJMj4cHHoj1dGzCZPt22QaytECaLYK0/RgwAO66y3PdwSZaq/NX8/SSp0Mau3TnUg7vdDht09o2LBHDZ52W1dKKhXvQuqjYtrSaB7ZohYlS8XQ47A9sm+yU7n62tdWsCOYeTE6W90a0NmyAggKppu50Hpyi9dovr3H1vKupdlYHHOdwOVi+azkjOo2gdWrrBrkHA1pasXYP2pZWs8AWrQbQqdPl5J2bgDMruXkutGnBBBOtIUOkbb0Rrdxc2e7aJYuB8/OlisXBhFmfFMxyWlOwhvKackZ2HknrlNYNq4gRIKZV6YxxIoZtaTULbNFqAElJ7cnpPZWtU13wySfeBeVsYs5nn8FDD/k/F0y0uneXdh9W0YqLg4wMWUgMB5+lZSycveV7A44zSRi1ohXh7EHb0rIJBVu0Gki3breRd2YNjnbp0ofcrpLRZHjuOZg5s+5/kuJiWaeVkeGdXAEy1ipaJhEjNxf69IEpUzxryg820TIWzt6KwKK1bMcy0pPS6ZvTlzapbah0VIYtNIHWacU85d22tJoFtmg1kFatBtKm6xS2XOiQyqfz58d6SjZufvsNKiokdd2KsbJGjhSRsp4vKJBrunWTArZWS2vwYLjgAs/Yg020jPAUlBcEHLd+33r6te1HnIqjdWprILy1WlrrOu5Bs41TcTFbXJwcn0y8irctrWaCLVqNoHv3O9k+qZKartlw9922tdVEMFmAvouEjWgdcYRsrS5Cc40RrcJCyTTcuFFE69hjZX0WHHyiZYQjmHuwuKqY7JRsAFqnuEUrjLiWw+VAo72eaUQsMzkzNu7B6hIykjNoldTKtrQApdREpdRapdQGpdRtfs7fqJRapZT6RSn1uVKqu+VcN6XUZ0qp1e4xPaIxR1u0GkFGxnDadDyVzRdVw7Jl8OGHsZ5Si6eqSpImwGMtGYxojRol20CiBfDxx/I7ZPBgqRt40UWQlSX1Bg8mjIUTzD1YXFVMZnImQIMsLav7z9dNmJ2SHTP3YHpSOq0SW7V4S0spFQ88BUwCBgDnK6UG+Az7GRiptR4CvAtYo8evArO11v2BUcCeaMzTFq1G0r373ew8vpyaXm3F2nLZ7Q2ixd698MYbgccYYYL6RWvkSNkGE625c2Vritr+5S/wyy8Nr4bRVAnVPeglWg2wtPx1Kzbb7JTsmLkHM5LE0iqtafGNIEcBG7TWm7TW1cCbwBnWAVrrL7XWpl7M90BXALe4JWit/+ceV2oZF1Fs0WokmZmjaN1uEhsvqoSVK+Gtt2I9pYOWf/9bYktbt9Y/xt8CYcP27VIzsGtXER5f0UpNlb5YPXrIsQULIC0NevWS/eRkEbWDjVr3YCiWVpKIVpvUNkB4lpa/OoNGyLKSs2JmaWUkZ7QUSytBKbXU8rrC53wXYJtlP899rD4uAz5xv+8LFCql3ldK/ayUmu223CKOLVoRoEePe9k1rpTq/h3hhhsCV1y1aTD73MuIVq+uf4wRrXbt/FtaXbqIYHXo4F3K6bffRJCUgtatITNTXI2DBjXPwrbhUOseDBDT0lr7dQ+GUxXDyz3o9I5pZadkxySmVVpdWmtptYCYlkNrPdLyetbnvL92pH4D9UqpC4GRwGz3oQTgaOBPwBFAL+CS+iailBoU5txridr/jkqpQ5RSX7qDcr8qpeo0YlDC4+6g3y9KqcOjNZ9okpn5f7TOOYncOyvR1dVw2mmSX20TUQoLZbtmTf1jjBU2dqz/RIyuXeV95851LS1jRSnlcRE2x35X4WLEJJB7sKymDI2uFa2s5Cyg4e7BOpZWSlbs3IMtx9IKRh5wiGW/K1BnRaNSagJwJ3C61rrKcu3PbteiA/gPEOj7/Bml1I9KqauVUtnhTDKavyEdwE3uoNxo4Bo/Qb1JQB/36wogtAJoTZAePe6lpEshe546W0yBqVPB4Yj1tA4qQhGt336Djh2hXz9573R6zoUqWtCyRKt2cXEA92BxlfwIM6IVHxdPVnJWgxMx6sS0kmOXiNGCLK1gLAH6KKV6KqWSgKnAXOsApdRw4F+IYO3xuba1Uqqde/84YFV9D9JajwWmISK5VCn1ulLqhFAmGTXR0lrv1Fr/5H5fAqymrn/0DOBVLXwPZCulmmWRnKysI2nTZiLru72L4/GHpFLGH/5gp8FHkKIi2QYTrW7dJC5VU+MpkFtRIe5Ff6JVWSkZh927e+7TokQrBPegr2gBYdcfDBTTMinv+gD//1KbiGFbWrgtpBnAp8j39dta61+VUn9WSp3uHjYbSAfeUUotV0rNdV/rRFyDnyulchFX43NBnrceuAu4FRgPPK6UWqOUOivQdQkN/oRh4M7XHw784HOqvsCfn8YRTZ/evR9myZKhbJqwkb533ilV4Dt2hPvvj/XUDgqMpRUspjV4sEd0Nm8WETPiZfpYde4sC4qrqz1ZhVZLa+hQScwYOjSyn6EpYgRkX8U+nC4n8XF14+f+RKtNapsGuQcVymudVnJ8MqmJqWg0Na4akuKTGvxZwkFrXZuIUemotC0tQGs9D5jnc+wey/sJAa79HzAklOcopYYAlwKnAP8DTtNa/6SU6gwsBt6v79qoh5iVUunAe8ANWmvfQE9IgT+l1BUm48XRhF1urVoNpHPnq9ix4xlKbz0PLrtM8qSffz7WUzsoMKK1Z48nKcOKKcVkTVs3yRhGmKyWFoiFZU13N1x4oVybkxPZz9DU0FpT6agkOyUbjaawstDvOL+WVkrrBiViZKVkeVlayQnJpCSkAAe2/mCFowKXdnncgy3c0jrAPAn8BAzVWl9j8crtQKyveomqaCmlEhHBmqO19qecIQX+tNbPmoyXhIQDYhw2mJ497yMhIYuNm25EP/00HH883Hij/wqtNmFRVARtJNOatWvrnt+711OKyWQCBhOtHTvgv/+VjML+/T33MhmGBzvG+umaKX+Y+uJaRrSyUrJqjzXUPZiVnOXVVys5PpnUhFTgwDaCNMVyzeLi8pryA+6ebKlorcdprV/TWtf5D661fi3QtdHMHlTAC8BqrfWj9QybC0x3ZxGOBoq01s3SNWhITMyhR4+Z7N+/gILC/8Izz4gP6qabYj21Zk9hIfzf/8l7f3Etq8WUlCQCZTIIjWgZ96BpL5KbC88+K+u/OnaM2tSbLMayMaJVXwZhfZZWQ9yDgSytA5mMYYrlZiRnkJ6UjkbHJIOxJaKU6qOUetdd7mmTeYVybTQtrTHARcBx7oDdcqXUyUqpq5RSV7nHzAM2ARuQoN3VUZzPAaNz56tp1WowGzbcgLNnJ7j9dnjzTU+ZcJuwcbnE0ho2TAQpmGiBd4uRvDzIzob0dNk3ltb990NZGdx6a1Sn32QxX9JdM9yWVj3JGPWKVuX+kK2TWvdgso9ouWNacGDdg8bSMu5BsNuTHEBeQrLFHcCxSAmogBaWIZrZg4u01kprPURrPcz9mqe1fkZr/Yx7jHb7M3trrQdrrZdGaz4Hkri4BPr0eYqqqt/YuvWv8o3YuzdcfTWUlAS/gU0dSkslZtW2rbQK8ZeMYdZoGdEy1dpdLliyBA6xOKLbtpV6gtu2wemnw8CB0f8MTREjHqG6BzOSMmqPtUltQ7WzOmTrpNY9aLW0HGJpGfdgrCytVolu0bKTMQ4UqVrrzwGltd6qtZ6JpMkH5SBf6x87srOPpkOH6WzbNpty11bxQW3cCJMnS6kFm7AwSRhZWbIGqz5LKzXVU9C2Z0/JGpw1C378Ea67zjM2Ls7jIrytTi1r/xRXFbNyz8qGf4gmSKjuwaLKIlITUkmMT6w9Fm5VDKulVbtOy21p1SZiRMA9typ/Va3IBsK2tGJKpVIqDlivlJqhlJoMtA/lwpBESyl1vVIq0x17ekEp9ZNS6sTGzLgl0Lv3Q8TFpbF27eXoY8fDiy+Ki/DCC71XvdoExYhWdrYkTGzaVFf7raWYQERLa7jrLjjzTEnmtDJgAJxwAhx5ZGhz+Pv3f+eI546ISbmhaGFEon2r9iTEJQR0D1pdgxB+0Vx/Fd1rLa0IuQdd2sXo50fzyHePBB1bWi0Fcm1LKybcAKQB1wEjgAuBi0O5MFRL63fudPUTgXZIfv2s8OfZskhK6kCfPk9QVLSIrVsfhOnT4ZFH4N134eKLvVvnHgS88ELgNVSNwSpa/fqJ5m/cCAsXwl//CuXl9Ve16NhRuhkrnwUWH3zgqeQeCnnFeVQ6Klmxe0WjPktTwohHamIqbdPa1u8erPYjWmG2J/HNHtRae2JaEXIPFpQXUFJdwo6S4Nm6te5B29I6oLgL6Z7rrgSfp7W+VGs9xV1gIiihipb53/1k4CWt9Qr8r7Gy8aFDhwtp3/58tmyZSXHxD5L+/sADMGeOBFNKD452CBUV8Pvfw6P15Yk2ElMNw4gWwDXXwHHHwZ13SruRtWvrLhAeOVKqw/vrgZWaCikpoc/BfKEv3XFQhF4Bj2WTkpBCTmpOwOzBxlpalY5K4lRcrUBUOatqLa1IuQd3lkjy8b7K4C7LWvegbWkdUNzVM0a4M8zDJlTRWqaU+gwRrU+VUhmA3TgqBJRS9OnzT5KTu7Jq1QU4HCVwxx3y0/+zz2Qd1/7Q04ajzZNPijstGNdeC6+84tnftElccbm5oT/rkUdEw0PBGtM67DB5v3AhXHEFfPSRiFpRkXeyRVaWJGAcF1J4NzjmCz1WolVcVcz24u0RvWetpZWQSk5aTsBEDF/RCrc9ia9VVeWoqpM92FhLy1hYoQipsbTSk9JrhdS4DG2izs/Ah0qpi5RSZ5lXKBeGKlqXAbcBR7gbeyUiLkKbEEhMzKZ//39TWbmF9euvlYOXXw7vvQc//yyBlSYiXO+8I8IVKIu5ogKeflqMRcOGDbJdudK7D2ZVlf97aS2i9dhjoQmd1T2Yni5z/K97Gdypp0pzxrvugksuCX6vhmLiPct2LoveQwIwc+FMjn/1+Ije01g2KQkptE1rG56lFWYihq9VVemorGtpNTKmVStaIQhpSVUJqQmpJMQleCwt2z14oGgD7EUyBk9zv04N5cJQRetIYK3WutDdR+UuoKgBE22xZGePpXv3u9m9+xV273a33z3zTAms5OaKxeWvNtEBZvdusVg2bqx/zIoVElOyZvAZ0Sor8yzoLSqSeNLrr9e9R26up5/V3/4WfF7GPZjlLshwzTVwyime8zk5subKWvQ20hgrZFX+qph8uW0r3sau0l0RvacRidTEVHJSc8JKxMhMzkShwnIPpiSkkJyQXLvva3011j0YrqWVniQL92pjWrZ78IDgjmP5vn4XyrWhitbTQLlSaihwC7AVWQxmEwbdu99FZuZRrFt3FRUV7lWvp5wC//kPrFrVJCyuPe5mA0sDeMDMuW3bPCE5I1rgsZy++04spB98yyQjRfABzj9f1l37Nmz0pbBQuggnJgYeFy201hSUFzCg3QBc2hWTZIzCykLKayLbwdzLPZgq7kF/i4X9iVaciiM7JTts92AdSyuC7sGdpe6YVgjWnymWC9iW1gFGKfWSUupF31co14YqWg4t/5LPAP6htf4HkBHkGhsf4uIS6N9/DqBYtWoqLle1nJg0SSyulSvhxBM9vrADTHW1RzNDES2Adetku2GDpJCDR7S++cZzzpf58yVR4qGHZM3UI0EylAsLxTUYK0qqS3C4HJzU+yQgenGt/LJ8qp3Vfs8VVRZR46qhxhl+1um+in1+Bc/XPehwOeqscTJdi03jRyvh1B+sdFTWdQ9GuGCusbTMf69AmLYkIJ9foWxL68DxX+Bj9+tzIBMIKaAYqmiVKKVuR8oyfexOWYzRb97mTWpqD/r1e5GSkh/ZuPFPnhOTJkmMa8UKeV8e2V/UobDH0tJtWYCwzbJlUiIJPC7C9eth+HDo1csjWosWydZXtEpK5NzEiVIfcPp0SZe3Pn/3bslXMasCYi1axm02pMMQOqZ3jIpoaa0Z/PRgHl3sPwXTVGBviLV1/KvHc9cXdTNsrCnvOWlS0t43GaPSUYnD5ahjaYEkY4Qc03JWkZKQUitQtdmD8cnEqTiS4pMilogB1Fux3mC1tJRSdqX3A4jW+j3Law5wLjAolGtDFa3zgCpkvdYupOfV7AbN1oZ27c6ia9c/sn37E+zZ847nxKmnwltviT8tBguQjWh06SLC5PKTH1pWJp7M886TSuirV0uyxW+/waGHSi+rX36RYz/+KGM2b/Zu4vzFF7I/caLs33ijNGK0JnY88QQ8+KDHqisq8sSzYoFJUMhJzWFk55FRScYoqyljd9luNuzzY5oCRVUS2GuIaOUV57G1aGud48aySY5PJifVLVo+cS1/dQcNgeJgvhiBSo73iWm5Y1ypCakRiWmZ+weLa1ktLRAXYUu3tJRSE5VSa5VSG5RSdWrFKKVudBe5/UUp9blSqrvP+Uyl1Hal1JNhProP0C3oKEIULbdQzQGylFKnApVaazum1Qh69fobmZlHsnbt7ygr+9VzYvJk+PvfxV14880HdE67d8v25JPFGlq/vu6YFStEzI46SqyqNWtElLT2iNb69fDttyJcJ58sAmWK2YLEs9LT5R4gbsXDD/ckbGjteW9iXTG3tNzWR05aDiM7jWR1/uqIp0ebL//60s4bY2mV15T7LW1U4agQ15hStE2TxWy+GYQBRStAmrwvJhHD6gqsdlbXikxKQkqj3INOl5Ndpbvo11YW8gVzW5ZWl9ZaWiDJGC1ZtNwetKeAScAA4Hyl1ACfYT8DI7XWQ4B3gYd8zt8PfBXCs0qUUsXmBXyEdDAOSqhlnM4FfgTOQcy4H5RSZ4dyrY1/4uISGTjwHeLj08nNPYOaGouL5brr4PrrJR/8T3+KuMW1c6dYS6tWeYfPjKV18smy9eciNJbPyJGeGoDG/WdEy+mUZWgghT/AM0ZriWcdf7xUazdMmyb3XrcOvv/eI1ZNRrTcgtI2rS0jOo9Ao1m+a3lkn+H+8vdnuVQ6KmtjXeF+sbq0q17RqnRU1mbu1eceDCRabVPbhm5p+cSvzDops5+amEqls+HuwYLyApzaycD2Uv04mNuypNrb0kpPSm/p7sFRwAat9SatdTXwJpLHUIvW+kv3sieA75EeiAAopUYAHYDPgj1Ia52htc60vPpqrd8LZZKhugfvRNZoXay1no58uLtDvNamHpKTuzBw4PtUVW1j1arzcFkDx488AjNmyPbkkyOWDr91q5Q3GjhQXqNHe84ZS+uYY6RShL9kjGXLpNBs584iWuvWeRoyGtECCc8ddpjHmjKitX69zMG4Bg3nnSdlll5/XV4pKSJSRrSKimIrWlb34IhOIwBYtiOyLkLzDH9rpazxmXAtLRMn8mtp1VTUikZDLa2iqqKQkkOMe9A8r6hS3J3GPdhYS8vEswa2E9Gy3YNh0wXYZtnPcx+rj8uATwDcxW8fAUJyDymlJiulsiz72UqpM0O5NlTRitNaW8Lk7A3jWpsAZGUdSd++z7B//wI2bLjOk24cHy+BneefZ90XefzcY7JYYL/8AkiioT/3XTAeeUQsoVdegalTRXRM4dnduyWtPDtb+lb5E62lS2GEfGfTr59kHC5YIPGmnBxpG5KcLAkUY8fKOq20NI9omYzCY47xvm+XLnDssVJy6a23pMLVYYd5XI+FhbGNae2t2ItCkZ2STcf0jmSnZLN2r5/2yY15RgD3oPmCh/BFy4yvzz1o0s2zU7KJV/Hkl+V7jQkW04LQUsx912mZGJ1xD6YmpDYqEaOOaAVwD2qt/bsHD25LK0EptdTyusLnvL+ySn7LDLjX647Ek9twNTBPa73N33g/3Ku1rv1HrbUuBO4N5cJQhWe+UupTpdQlSqlLkDTFeSFeaxOETp0u5ZBDbmHHjqfZtu1h75OXXcYfhi9mQtV/KXvmNRg6lPIH/8Fxx4kVsyuMtab5+fD883DRRZKxN3GiCILpQ7VnD7R3NwcYOVKKdVg9k6WlkngxcqTsmxqAX3whYqWU9Kgyqe9jx8qxQw/1iNaiRVIH0JRisnLBBbKoOT9f3pt+WBUVIoKxtrTapLYhPi4epRSH5RwWedGyuAd910pZLa1wv1jN+Prcg8byiVNxtGvVjj1le7zGGHHx6x50W2ehxLV83YO+llZqYuMSMWpFq31wS6uspgyNbmmWlkNrPdLyetbnfB5gKYRGV6BO5WGl1ATE+3a61tr0WjgSmKGU2gI8jHSkD1RU3Z/2JITyIUJNxLgZeBYYAgwFntVat9Ber9GhV68HadfuPDZtuoXdu9+sPe5ywZI1meyrzuD5+/LgnHN48Y715OeL9XHZZYFLLll5/HHJ0rvlFtk3VdCNC273bujQQd6PHCkitdbyvbx8uTzLV7Sqq0WYDMZFePTRsj30UI9V+M03HjHzZcoUiXNlZ4ug9uwpC5j3ur8PY52IYWI+AIe1PYy1BZEVLeOWc2pnrVAYrPsNtbRKq0txurzjoxWOitqYFkCHVh3YU+4tWsHcg9a5B6LSUenlHjT3jVQihhGtblndSE1IDWhpmWK5piIGtAhLKxhLgD5KqZ5KqSRgKuDVB0EpNRz4FyJYtf9QtNbTtNbdtNY9gD8Br2qtA3WqW6qUelQp1Vsp1Usp9RgQkr89ZBefO5/+Rq31H7XWH4R6nU1oKBVHv34vk5V1NGvWTGfvXjFk16+XTL6kJHj4n60of/51Hk67l6P4lkcnzGPePKkDGIySEqnXN3myR2yMaJmyS3v2eERryBDZrlrlucevv3qfa9PGY5lZRevCC+HSSyW70JzbtEkaMm7cKKLlj+xsqdh+773iYuzZUzIPzXNj6h4s31vrCgPo26Yv20u2RzSD0JrQ4Jvc0JiYlnW873wrHZW17kGQvlq+llbARAxjaYWQjFHl8F6nVeseTIiMe3Bn6U7apbUjKT4p6Poxf5+pBVhaAdFaO4AZwKfAauBtrfWvSqk/K6VOdw+bDaQD7yilliulwmju48W1QDXwFvA2UAFcE8qFAUXLNy3R8ipxpynaNIJ33xWrxcR54uNTGDRoLq1aDWblyrPYt29BbQbf/fdDXh5MOS+BreXtuP24H5gx/12EKA4AACAASURBVBQmtl3CTTfpWhdffbzwglhm1i69nTtLWSSrpeUrQtaFwRs2SIJEF0to1gigVbROOEH6XRpr6tBDxRp7w11ysT7RArjnHrjhBnlvRPXnn2Uba/eg+YIGsbQA1u9tQGCxvmdUeKwVX8vFGtMK94vVOt7XgrMmYoCI1u7S3V5jiquKSYpPqhUXK0bIQ7G0TBknY1n5xrRSElIa7R7snNEZCF6pI684D4AumZ5/zK0SW7ylhdZ6njuTr7fW+gH3sXu01nPd7ydorTtorYe5X6f7ucfLWusZQZ5TprW+zeKqvENrHdIfP6Bo+UlLNK8MrXXdn102YfHxx5KNd8wxUqG8pkYqwg8d+hlpaX1ZufJ0vv02j9RU+OMfpezR/PkwaBCc/NkfUc88w7+KL8BZWcPDFy6HYvkdobXHpWZ45RUYNQqOOMJzLD5eCsxu3ixuyPx8j6WVkSHvfUWrd28pu2TwJ1q+mHMvvyw9rA4/PLS/jxGt5e7M8iblHswR0YpkXGtv+V4S4hJqn2clUpaWb1zL1z1Yn6Xlr4QT1J8m7w9TxikhLoE4FVf7mawxrcYmYtSKVkrrgDEts9C6e5ZnbaxZp+Wv9qJNZFFK/U8plW3Zb62U+jSUa+0MwBiyfr1YWhdfLH0h//hHOZ6YmMPQoQtISenOokVbGTy4hMREKWsEYi3FxSu48kq6/fAOF7b/H88vOow9XYbDlVdy01mb6dJF19YFXLVKvvinTas7B5PssG+fJF0YSwu8EyhA3vuK07BhknzRt2/9n7NPH9n++quk2Ida9LZbNxFIY2k1JffgoW0ORaFYt3dd5J5RsZferXvXPs9KYWUhcUr+d42kaFkTMUBEq6ymzMvi8Fcs15CWmEZqQmpQ96DWmmpnde1C5pSElDoxrdSE1EbHtEK1tLYWbkWh6lhaLu2iyllV73WBcOm6JWTKqssorS5tdHkqkAaXB5GgtnVnDAKgtd4PtA8wvhZbtA4Q+/eLO9DKhg0SH3rxRXGJPfUUzHPnZCYltWfQoC/YsGEoXbu+TnHxj5xzjlhmF1xgucmwYdzy1SlUqRQe7/4In726i8f+05OqKsXsW+QX8xtvyJf/uefWnVePHiJaZo2WsbTAW7RcLolH+YrW5ZdLrcF27er/7J07ezoEB3IN+pKYKLUJzRxiZWmV15RT4ajwcg+mJqbSLatbRC2tgvIC+ub0rX1vpaiqiOyUbFITUhucPQh+LK2aijoxLYD88nyva+oTLRBry+ra9IdZGG11Bfpdp9VA96DT5WR32e6wLK3OGZ1JivescG9MI8gHv3mQvk/09RLvGz+9kfQH08l4MINWf23Fl5u/DPu+BofLwcB/DuSmz25q8D2aGC6lVG3ZJqVUD+pJr/fFFq0DxC23wDnneJIeSkpEKIwIPPigZN1deqmnMsXWrZ0oL09nwIANrFhxAsXF33H44XUz7/r1g8mTFU/mncklrf/DwO4lXJr+Dq98mE3ef5by+utSgaJjx7rz6tkTCgokUQLqWlrbt0vt3h07JPXcV7QSEz0uwvqIixO3IoQnWiCian5cxkq0zBeR1dKCyGcQ7i0XSytOxfl1D2YlZ5GWmBZxS8vXPQh4uQiDilYI9QeNpWGsuuT45Iiu09pTtgeXdtEpvRMgohUoEWNr0Va6Z3s3X2toe5K1BWu5d+G9bNy/kTs+F3fI4m2Leez7xzir/1n8bcLfcGkXi/MWh3VfK9/+9i37K/cz5pAxDb5HE+NOYJFS6jWl1GtI6afbQ7nQFq0DwPbtntb07rXBtU0WjQikpEjB2KIisV609izuPfPMm0hK6sCKFSeyf/8Xfp9x++1y7d69ijkfZnD3p2NxEcdFU8rZtAmmtf+ftCWeP1/qJLnLp5u40Y8/ytZqaRm33saN3qWaGsKhh4p4HXlkeNeZ+SUleay1A4217qAVs1YrEi6bSkclZTVltGvVjjapbeqIgLG0WiW1otwR2ZiW1T3YoZX8AwhHtNqmtQ0a0zIuN6tV5W+dVqWjskF/T5PubiytNqltKKspq7dSx9bCrV7xLGhYI0itNTM+mUFaYhrTh07nuZ+eY/G2xVw972q6ZnbllTNf4ZYxt9Alo0ujrPKP1n1EUnwSJ/Y+scH3aEporecji5PXIhmENyEZhEGJmmi5m3rtUUqtrOd8a6XUB+5qwT8qpUIqS98ceewxT8V007bDiIARBhBLa9Ys+Ogjqd23bJlUkxg6tCPDhn1NSkoPcnNPYd++uvHKkSPh7rsl2WHoUOh5VCfOm1zDQtc4kqlk8pwp4h+cNEmUY8wYWL++VhS+/162vpaWmWtjRet3v5N09owwu7CZ+WVl+V/bdSAwrjqrexCgb05fSqtLI9JN2GrN5aTWdbcVVhaSlSKWVtjuwZog7sHGWlppOUGzB40FZXUP1gqZ5RjQoJiSr2i1Tm0N+K+K4XQ52Va8ra5oNcDSemfVOyzYtIC/HPcXnpj0BB3TOzJxzkSW71rOYyc9VrsOrG9O30ZZ5XPXzuXYHsd6VfBoziilLkf6aN3kfr0GzAzl2mhaWi8DEwOcvwNY7q4WPB34RxTnEjP27YN//UtKJvXoUVe0jNvMcN11MGGCJGV8/LH0qEpIgOTkjgwbtpC0tH7k5p7B3r3z6zzrz3+WTsCG2+6TL6PTpiSTuXuDPPy77yT/fcMGGD6cnj/IQmbTRqRNG8/1Zm5GtJKS4BDrevkwOP10mV+4GNFqCsVy67gHI5hBaCyVtmltxXLxtbQqxdJqqHswXsUD3qLldDmpcdV4WVrtWklwMixLK4SiuVUOESLzLOszreu0QIT0pk9vYvoH04N/ODcmhb1Thsc9CP6rYuws3YnD5ajjHjQCEyym9Xru66Q9kEb8n+M5793zGN5xOH8Y+QcykzN59KRHKa4q5sTeJzKl/5Taaxpjla8tWMv6fes5re9pYV/bhLkeOALYqrU+FhgO5Ae+RAipbEZD0Fp/7Q6u1ccA4EH32DVKqR5KqQ5a690Brml2PPWUVJa49VaxNKyi1aFDXcsjLk5ciYMHyxhTcR0gKaktQ4cuYMWKE1i58gwGDnyXtm3r/4c8eDC8/TaMGKHEhDJm1JFHSofk6dNpd/35pCWeRXFxEp06eaezZ2dLyaUNGySFvlcvEbYDSZMQrfrcg+61WmsL1nJMj2Ma94xyzzNy0nLYUrjF67yJabVKbNUg0UpPSselXV6iZW0AaUhLTCM9KT1sS2t/5X6cLifxcf7/gfi6B61rvnwtreKqYl74+QVqXDW8dMZL9d7Tyi+7fyErOauOpeUvrrW1sG66O0DHdAn6WhtJ+lJQXsC1n1zLYW0P49Q+pxIfF8+lwy6tneN5A89Da81xPY9DWVwDh7U9jMLKQgrKC2p/GITK3LWyfvfUvqeGdV0Tp1JrXamUQimV7NYAP8Xd6hLLmNYK4CwApdQooDuWMvcHA1qLlTVpkgjIkCFSFqmqyn/6uKFzZ09rjzE+cVeTDi8LkM9gy5b70X5SbQ3nnOOpTOFF167w2WeoK6+kZ42kbbdPLRGfZLHni81kEAaabzSxugdjhbXCu5WumV1JTUiNSNq79RltU9vWmz2YlpgW9uLi8ppy0hLTyEzO9BItk6lndQ+Ce4Fxmfx2rHJUUeWsCpqI4dKugJ2C/bkHDdaYFsD/Nv2PoqoiymvKWVOwJqTPuGznMg7vdHjtsoBaS8uPe7B2jZaPpdUtq5vXeX/cvuB2iiqLeG3ya9x/3P3MPGam132UUpw/+Hw6pHfwuq4xVvlH6z5iaIehdebbzMlzr9P6D/A/pdSH+Klz6I9YitYsoLVSajlS0uNnwOFvoFLqClOZ2OHwO6RJsnmzJGGc7l4zbnpNrV4dXATOOksqsJ/tp2tZYmIbhg//mg4dprFlyz3k5p5OTU3g1uJ+SUiAp5+mRz/5Aumw6TsJjnXvLqrpctXWDYyVaHXu7KlHGCv2lu8lMzmTxHjvBWZxKo4+OX0i7h7MScvxKprrdDlrF/g2xD1YVlNGq6RWdUTLN6PPYF1gbHpeBUvEsH4GfwR0D8Z7uwff/vXt2nNLd/hpNeBDtbOaFbtXMLLzyNpjbVLFz+3PPVifpdUqqRVt09rWnvfl+7zvef7n57lh9A0Mah9eCN4sZQg3rrW3fC/fbvv2YHMNorWerLUu1FrPRNpcvQBEtDVJxNFaF2utL9VaD0NiWu2AzfWMfdaU+0hIiJpHM+KY8kwmzdsUkv3hBxGzYCLQp4+3u85KfHwa/fq9Sp8+T7J//2f89NMRlJb6zXkJjFL0nCATaX/CMHj/fTEJr7gCxo2jT+sCtm2DsrLYiFZcHJxySvCswxpnDeNfHt+otTBWFmxawIhnR5Bfli/VMHysLEOkqr17uQdTc6hyVtVaVEY4slKyJHvQIlp/+fovTHt/WsBYidXSspZxMgt5re5B8BYtYz0Fcw9C4FJO/rIHDb7Hvtj8BRMPnUh6UjrLdtatofrVlq8Y/PTg2nJTK/espNpZ7SVagRIxthZtJSc1pzZb0Er3rO5+LS2ny8nVH19N54zO3Ds+pA4aXvTI7kFSfFLYVvm89fNwaRenH1anWtJBg9b6K631XHfjyaDETLTcTb/Myr7Lga+11gdVPcNFi8RCMK06+vT5f/bOOzzKKvvjnzstmUmZ9JACgVBCbwkdsVBEXNAV+6qr6+Iq6FqwrK4Fd0VdddX1Z9dd197XFbCiguiKSEJvAQIEQnovk8wkM/f3x807mUkmlYQ6n+eZh8xb7ntnSN7znnPP+R7lNfz3v03vjwQhBAkJixg9ehVOZzUbNkykqKjzWsZaCC52ZKxS1F29Gl57DXbuZMCLt7uPOxZGC5Qdve22to8pthWzJnsNPx36qVuu+emuT9mQt4G7vrmrhe6gJwkhCd2SPVhsKybYFIxJb2ohQqsZjrDAMCwG7+zBb/d/yztb3+H97e+3OnZr4cHWPK3YoFi30dpRpBSTB0S0/p+vGfS2kjF81WkBbkknaDKeTunk/JTzGdNrTAtPy95gZ8HyBWwr3MYnu9TvutaMU2vOCW0nYviq0dJICvNttF5Mf5GN+Rt5ctaTXcrg0+v0DIgY0OkHnOW7l9MruBep8antH3yK0JMp7+8Ca4EUIUSOEOJaIcT1QojrGw8ZAmwXQuwCzkFlk5xU/PijWpPSvCWjEYYMgW+/Ve+7ywhYrVNITc0gKGg427fP59Chpzt1vma03OnuQsDVV8PWrQxIa4rLDYjvXFjqaKJ5I756RnWF9Lx0BILXNr3GL4d/aZGEoRFpiaTaUe1WfOgqJbUlbmPVXM9Pq2fyFR7UEg1u++q2Vj97jaOm02taRTVFuKSL9Nx0dELH6F6jW517Z8KDzde0tPee20AlHaTFp7EpfxMNHh29n/jpCfaU7iHEFOJOUEjPTScsMIzk8KbFW6PeSJAxqNVEjOahQY0kaxLZ5dlenmtBdQF//u7PzEiewcXDfMjKdJDOeuUOp4Mv937J3EFz3YbdTw8aLSnlZVLKOCmlUUqZKKX8p5TyRSnli43710opB0opB0spL2jUnjppKCqCXbuaekppjBjhruttke5+JAQExDN69Cqioi4gK+tW9uy5GZerY+t/mvGMj2+2Iz6eAcufAsBAPUm/n6nkM9atg5tuUqmJxwlaf6TuMFoNrgY25W9iwdgFJIYmUlZX1mp4sCNeRkcothW7x2qunO7paWnhQe2mWlZbxsjYkeRX57Nk9RKfY9vqbQQZW65ptRUedEonZbVlZORlMDR6KBajpdW5dyQ86E7EaBYK9Mwi1IxnalwqCaEJpMalUttQy86inQAcKD/A0h+WMn/IfK4dcy3f7f+OGkcN6XnppMalemXrgW/9QSml8rTaMFq1DbVeBvjOb+7EVm/j2XOebXGNzjAochBZpVleRrgtvj/wPVWOqpNuPetI8ZvvHuJ//1P/Npct0npRRUV1f3KBXm9m2LAPSEy8jcOHn2Hr1l91KEFj+HBlf+bPb7kvIlIQHg594+wYtmxQKrYTJ6rmXJdd1hTrPMa4PS3HkRutHUU7qGuo4/S+p/P02cprbc1oaV5GR1pztIWninzz8KC2DqUVFzul0+3ZldWVcVbfs1gwdgHPrHuGrNKsFmN3NjyoFRgX1BSQnpvutVbkixBTCEad0T3fBcsW8FL6S17HaGtazRMxPD0tzTBqN2ntulqI8OYvb0YIwVNnP8W8lHnYnXZW7F7B1oKtPucYHtjSaJXUlmCrt7UZHoSmZI303HTe2PwGt0++3V3i0FVSIlOod9W3KGe49ctbeXD1gy2OX5a5DLPBzPTk6Ud03ZMNv9HqIX78UTUyTGv2t6QlY/TU+pAQOgYM+DuDBr1Mefl3bNgwgZqane2co1LjzWbf+8eOhbGnBcM336jK55deUmKE48apqunVq7v/g3SS7vS0tJtkWnwaFwy5gCdmPsG1Y6/1eWxnWnO0RYmt9fCg15pW443dVm+j3llPtaOacHM4N4y7Aad0sil/U4uxa+qbwoNV9iq3Gnlb4UGADXkbKKwpJC2ubaMlhFAZj7UlHK48zKsbX+Wpn5/yOqZ5eND9r4enNShyEA+c/gA3jLsBgIGRAwkxhZCRl8GK3StYlrmM+6fdT29rb6b2mYo1wMrDPz5Mvaveaz1LI8Ic0WJNq7XMQQ1tu7au9XXW1wDcPvl2n8d3Bs+6Po0Vu1fw9LqnWfL9Eq/1WCkly3cvZ0byjDa93O5GCDFbCJEphNgrhGjReVgIcZsQYkejktG3Qoikxu2jhRBrhRDbG/dd0lNz9ButHuLHH9U9PaBZ37yeNloa8fELGDXqOxoaysjISCMv77Uua+T95z9KiZ4pU2DZMpVZGBenJDuSk5Ua78CBMHcuvP9+k8LtUaQ717TSc9MJMYWo9iNCsHjyYkbGjvR5bGc697aFZ3hQS9fWvDfPNS1NashWb3Mbs/DAcBJCVIuNvOq8FmN7hgcl0p3I0Z6n9fke1XKgI0kAkWYl5bRi9wpA1SN5Zsq1Gh708LT0Oj1Lzljivr5O6BgbN5YfD/7IH7/4I0OihnDrJNW/x6g3MmfgHLYUKDFPn56Wj/BgazVaGs09rYy8DAZEDHD/nxwJ7rT3xnWt2vpa/vjFHxkcNZjE0EQWfb7IHTrcVriN7Irso5o1KITQA8+hcgyGApcJIYY2O2wjkNaoZPQR8FjjdhtwlZRyGEoJ6WnPflndid9o9QA2m6rRbb6eBWrdaOZMb6WLniIsbCppaZsIDZ1AZubv2LnzNzQ0VLR/YjNCQyGoZXYwREbCd98pqY8xY1QB2qWXKm/su+/g66+VSO+hQ0f+YdqhOz2tjLwMUuNTO7T43ZnOva3R4Gqgwl7hHsugMxAWGNYie1ALD4LynrQbcrg5nEhLJEad0aeag2d4EJq+o7bWtAC+yvoKvdAzKnZUu59BE81dtnuZ25Avz1zu3t9qeNBHN2RP0uLT2Fywmf3l+3luznNerUS0MGKEOYK+YX1bnOtL6b09Tys8MJxgU7DbuHUkPNpRoixRRJgj3Mb80R8fZX/5fp6f8zxPnf0Um/I38cL6F4AmFYxzB57bLdfuIOOBvVLKfY3p5+8B53keIKVcJaXUMoF+plEQQkq5W0q5p/HnXKAQVcbU7Zw4RU8nEG+8AQ0NvttwCKHu5UeLgIB4Ro1aycGDj7J//wNUVPzE0KFvY7V2U4uDXr2aRAWdTlWUfM89yvvSEEIZsgsuUC5mcrJKWexGBdwj8bT2lOzh1q9u5Z/z/kmEOYLN+Zu5afxNHTrXV3jwlYxXKLYVc/dpHeq04L6xeqbVR5ojm7IH7RWYDWZMepNXeFDzXiLMEeiEjriQuBZGy+lyUtdQ18JoJZDQangw0hyJTugorS1lVOyoFkatte9hQ94G8qryuCHtBr7d/y3Ldy9n8WTV/6kj2YO+0MJ+lw2/jDP7nem1b/aA2Rh0Bp9JGNDUU0tK6d6fXZGNxWhp1XMSQrhrtYpqijhYcbDDvwsdISUyhXe2vsPanLXsLNrp/lxSSmb1n8Vd39zFqxtfJbs8m/EJ491aikeJBMDzCTMHmNDG8dcCXzTf2KhwZAJaLrB2A35PqxuprFRdiG+4QRXDnnlm++ccDYTQk5T0Z8aM+REh9GzcOI2srLtwOrs5hV2vh+uvV1Iey5er6ur0dLj/frXthhuUm9m/P4wfD++805RKeYRoIqddMVrf7PuGz/Z8xu0rb2d70XbsTnuH62ICDYEEGYO8PK03t7zJixkvdvj6bgknj7T6KEuUV/ZgWKCKtGgFsbZ6m3u9RqtJigtuabQ0w6QpYkDTd9RaeFCv07sNqK+1Il9EmpVeot1pZ17KPOalzOPHgz+6DXJdQx0GncGt0edLg9AXcwbOYWHaQp46+6kW+8LN4Tw560numHyHz3MTQxOpbaj1+r/ZW7qX/uH928wCTApTae9aYXN3eVoAiyctZnrydJLDk7li5BU8PVsl+ggheGXuK8wfOp/k8GTO7HcmS05f0m3XbcSgKQs1vq5rtt/Xl+Iz1i+EuALVWuTxZtvjUIrt18i29OWOAL+n1U1IqZQbfvpJ3aPvvbfjbeWPFlbrRNLSNpKVtZhDhx6jqOgjBg16iYiIGd17oago+JWHuGdqqvpSsrPVa/NmeP55+M1vVMvmCy6ASy6BM87osvd1JOFBLRT01pa33Ns6c6PSkhA0cqtyOVx5mAZXAwZd+39iWhjQy9OyRLqLlivsFVgDlfiiOzzo8A4PgmrL0VxxQavpshgtWAPUGO2FB6FJFaOj34M2d2uAlal9pmIxWlj6w1K+2PMFvxn5G+xOu8+arPY8LWuglefOfa7V/TdNaN0Lcic+lGS6RWp3l+xmVK+2w519Qvvwc87P7oScMb3GtHl8Z5g/dD7zh/pI00VpH7756ze77Vo+aJBStvUfmgN49nFIxIceoBBiBqqJ4+lSSrvH9lDgM+BeKeXP3TPllvg9rW5i1SqVfPHMM/Dgg8efwdIwGEJJSXmFUaNWIYSBLVtmkpl5PQ0NVT17YZ1OhQTPOANuvlmtf332GZx1Frz5pvp3+nTYvr1Lw2vhQYfT4Q5FdZTsimwSQxPpG9aXt7a8hTXASv/wjhfReXbulVKSW5WLUzo5XHm4Q+e7VeQ90uo9x/T0tDzDg809rfiQ+BaelpZ04Rke1FLoaxtqEQiMupa/rNq6VkeNljb3cwaeg1FvZFzCOGKDYlm2W63N1DXUeXlVHV3TOhK0xAfNkDucDvaV7XOL17ZGUlgSpbWlrD6wmkGRg9wPDKcA64GBQoh+jWpFlwLLPA8QQowBXgLmSSkLPbabgE+AN6SUH/bkJP1Gq5t49FG1vHOt78zoo8rGvI2c9fpZTHttmtfr+hXXu48JDz+DtLTN9O59O9mHX+L81+LZerBHf9e80elUNsp776lK7Oeeg02bYPRoZcDOPReuvBLWrGk6p6IC1q6Fffugzrstu2a0oPPeVnZ5NgMjBvKP2aqlW2q87zWS1vAM5VXYK9whubbUwj1pLTxYZCvC6XJSUVfh9pI8swd9eVpldWVeLes1T0vLHgTv8KDZaPb5WWOCYjDoDIyIHdGhz6B5WlpyhE7o+NWgX/HFni/cDxKeYciOelpHQt+wvhh1RneK+b6yfTil023MWkNL0lh9YHW3hgaPd6SUDcCNwFfATuADKeV2IcRfhBBaGuPjQDDwoRBikxBCM2oXA9OAqxu3bxJCtC6jcgT4jVYX+eILePll1ZE4IwNWrlSNG49VS3hP3tn6Dj8c/AGDzuB+5Vfn81LGS143dL0+kP79Hycg8VU+y63m9f9dTFbWHTiddW2M3gNYLLBwoerb8oc/qN4thYXqSz79dJWGOWsWREfD5MlqTcxsViHIzZuBpvAg4CUK2xE0Lbp5KfO497R7+eP4P3bqfM/wYF5VU8p5a2rhzdG8I827AZiWNA1bvY0X0l/w6WnV1NdQVltGkDHInVGn9ZLynINneNBX9mDzJAyN3476LQ+e8WCL9a7WmJ48nWtGX+OVoj0zeSZVjiq2FW5rER70VafV3Rh0Bi+9P814dcTTAqWB2NE1vZMFKeXnUspBUsr+Usqljdvul1Iua/x5hpQyVko5uvE1r3H7W43qR6M9Xi2LBrsB/5pWF9i1S6lH1NaqsiSDQfV7uv769s89GmTkZTCm1xi+++137m3vbXuPyz6+jOzy7BZPzw696iPkDBjHoUNPUFLyBUOGvEFIyNijOm+io5XShkZtLbz6Kjz5pFIavuUWlZJZWqoM3IsvqlT7K6+kalqT8odPT0tKcDhaFM45nA7yqvLcT9d/PeuvnZ62ZyjPMzzXUU8ruzybXsG9vAzEeSnnMSN5Bvd+dy8u6XJ7Wp7hwdK6UreXBSoRQ5tDv3AlKKkpxVuMFrfQq6en1ZpRmj1gNrMHtNV43JvE0ET+dd6/vLZpXkpGbkbr4cEe9LRArWtpxkoLE3bU04LuTcLw0z34Pa1O4nCo/AGLBZ54An7+WaWwL1qk6pmONS7pIiMvo8UfW/NKf080L8FlnsSIEZ/R0FDKhg0T2L9/CS5X59aHuhWzWWkc7t+vjNRjj6nmZFdfDY88osKEd94Jb71F1bYMLI1eQ+XKFUpeSityrqhQxs5igWHDVAy3RH3mQxWHkMhW63Y6QpQlirK6MhpcDd5Gq4Oeli8tPCEEz57zLLZ6G1WOqlazB7X1LGjytDzn4A4PmoIw6AxYjJYmT6uhtkPp7F0lOTyZsMAw0nPTsTuPfngQYFDEIPaW7qXB1aASMizRXobeF3EhcRh1RgSiW5Mw/HQPfqPVSZYsgQ0bVDnS4sVqGebOO+H2I1d56RaySrOotFe2NFrNKv090dZUCmoKiIycw7hx24iJuZTs7AdZty6F/Pw3kdLZ85PvLOHhajHxiy+okg4SipSBrXz4AdVimICwJQAAIABJREFU5YorID8fZs+GX36BG29UocU331RhyEbxVICkctllJQ8tCaGstsxtMIZGD+24p9VKq4yUqBR3OreWDBCgD0Ag3NmDnjfgtoyW5qF56g/WNtR2OPzXFYQQpMalkp6Xjr2hlezBHgwPgvoONb2/zJLMDukH6oSO3tbepESldKkNiZ+exW+0OsHu3eoeee216p4ISr3ob39T98/jAS1Nt3ksvldwL0x6k29PqzG0pfVQMhojGDLkTUaN+gajMYpdu64iPT2VsrJve3j2XWTWLKriIkjQK2+k8v674KGHVJJHUhKsX68Ugf/xDyVD9dBD8PHH8M47ZBftBSBp/rVq/eyXXzp9ec/WHLlVuYQGhHbYaLmki4MVB1v19P487c9cMuwSZibPBJQh0NqTlNWWeRXJRpgjMOlNXkbLM3sQvI1WXUNdq2ta3UVafBpbC7ZSaa9ss/FjT6GtX+0u2c3ukt3trmdpLExbyC0TbunJqfnpIn6j1Qneflv9+9fOL3scNdJz0wk0BDI02lsyTCd09A7t3WZ4UDNaGuHh00lN/YUhQ97F6axg8+YZbN06j9rafT33AbpIldNGwpRzAKgc2EdJS331lWpg9t57TU8ZoFzkyZPhxhvJfu4hhITe869RIcgJE1T8Nyenw9f2bM2RV51HfEg8SdYkDlYcbFfvsaC6AIfT0arRshgtvHfhe4xLGOe1Tcse9AwPCiGID4n30h/0zB6EZp5Wfc+GB0E9PNW76tmUv+mYrWkBrMtZR2FNYYeN1uLJi/lD2h96cmp+uojfaHUQKZXROusspRV7vJKRl8Go2FEY9S1rb7RK/+Zo4cHmRguUanxs7KWMG7eT5OS/UV6+ivXrh5Gd/SguV/eoWRwpTpcTW73NLRrrTsSYMUPFby+80PsEvR5efx0cDrKrcogzhmN65V+wd6+qCv/PfyAlRf38889qIbM5NTXucKJnT63cqlziguNIsiZR11Dn8zv1pD0BV18EmYKoqa+htLbUy2hBy1qttsKDbSVidBdamLq2ofaYhAcjzZGEB4azfLfSQWwvCcPP8Y8/e7CDrF8PWVlKVq813t36Liv2rPDaJhAsGLuA0/ueDqji07/972/M6j+LsXEts/NWH1jNKxteafUaFoOFx2Y+5l7LyK/O58m1T/LA6Q9gNprJyMvgt6N+6/PcJGsSX+xtIRXm9rSKbcU4XU631I4nen0gffrcSUzM5ezdezP7999NXt4rJCXdQ2zsleh0phbnHC20DDmttqhDdVoDBsDKlWRvuJkkc6OBDwlRbvS116qFyqVL1ctsVooef2rs1LBmDZxzjlL+uOACos5SodhiWxG5VblM7j25aQ2xIpvY4NhWp9GegKsvLEYL5XXl2OptLZIK4oLj2FG0w/3eM3sQlNHKqlGScLUNtfQy9OrwdbtC37C+RJgjKK0tPSaJGEIIUqJS+DlHCTQcaU8sP8cev9HqIO+8o7KlfTVKBNhasJUrP7mSKEuU1+Jtia2Er7K+IvPGTCLMEXy440Pu/vZudhXv4t/n/7vFOPetuo8NeRvci+qeSCnJKstibNxYd8+hVzJe4fGfHkcndFw9+mqqHdWtpukmWZPIr85v8YTtVnNAUlJb4lUv1JzAwESGD/+YkpIvOHDgfjIzf8+BA38lOfkRYmIuPaLOrl1Fq9EKCQhp0eiwTSZP5mB6GWnWZt9X375qDaygQHXzfPNNuPtuVdB83nmqBUtiIgwaBM8/T+TzDrgHSv50M7mT7cTHnEGSTRnC7GsuYHx2kPrlcbnUGEFB8H//B9OmNXlav1kIZ8+Dq66C2NaNHCgDdLhKqW348rS+2feN+72t3kaAPsD9INI8PNjTnpaWjLFy30ovryo8MJwLhlzAaUk+WiF0MymRymjphZ7k8OQev56fnsUfHuwADQ1qWeTcc1U9VnOklCz6fBHWQCvbF25nz0173K/VV6+mrLaMe769hyp7Fbd+pfoBaWKcnhTbivnp0E8snrTYawzP14CIAe5QB+D++e9r/+7WzmutIFJ7+j9U4d0qpNhW7F6Qby+cpREZeQ5jx/7CiBGfYzSGs3Pn5WzcOJny8jXtn9zNaGoYIabOGS2XdHGo8lDrXk5srNJF/Phj+N3vlD7XlCmq5fQ33yhR4KIigj7/BhN69gyPwy6cxD/zGkmTVe+Z7HiLqiXr3x8GD1ZrZjabkqx6/nmyP32dsFoIzTygvLvERLXm5iskmZkJb71FUGE5h/P3ALRQK48PiafCXuFOwNDakmiEmkJV8bWU1FWWYrb3iKapF9pDVPPeWR9f/DETEyd2fKCsLNizp9PX19axksOTvVqb9AhSqt+XjAz1s5RKOPqWW7zVXfx0Gb/R6gCrVqmH7t/8xvf+t7a8xQ8Hf+DR6Y96SfEAjIwdyY3jb+TljJe57OPLyK3KZfaA2ewo2uG+sWh8vudzXNLllsJpjhCCuYPm8u3+b6l2VJNblcv63PXcPOFmgk3BLP1hKWaDmSHRQ3ye31qtVkltCYOjBgMdN1rafCIjzyE1NZ2UlH9RV5fNpk2ns2nTmZSVre5y08nO0lVPK786XyVBtLeepNOpGocbblAF0CtXQu9GXdHQUMT06USFxLJ1qMoijJt3OWF3P0ioMYTsi89WTzyffAIffaQWRtevV+ttixaRfXgHSQExcOAA7NihatCefFIZx7VrlWFculS1jx48GK68EsvOvRRI9ZnDy2u9phovgwHIe/YRcDiocdR4G63G70deegm1FSWYv/7Ot9J+bq6qou8GNKMV2JlQ4Pr16sFAo7pa1doNHqzUU4qKvI+vqWnVoGnrWF7rWZWVqtDy4MGOz6k5TqfKNq30+H377DO1hpqWpmoCx4+HadOUKOnpp8M118DGjbBunaqd6czfSG2tqjk8xfEbrQ7wxNsZGM9fxFeGhdzx9R1eN/byunJuX3k7ExImtNqS/cEzHiQ2OJbP9nzG78f8nhvSbsAlXS1aoy/fvZy44Lg222LMS5mHw+lgZdZKPtv9GQDXjrmWh896GIDRvUa3qizuq1bL3mCn2lHtzjb0ZbS+3Psl3x/4vtU5CaEnLu4aJkzIYsCAp7HZMtm8+Uw2bZpGaelXPW68uuppdWo9SadTyvQHDqiwYDMizZFsK9wGQPzl18P995MU3peDleqmuGL3ChZ+tpCFny3kzxmP4/j0P/DEE2SP7EPSkIkqOWTIEGUc//MflRQyebIqptZaBjz1FOzYgeXsJgX98IWLVVvpF16AG28k/jrVvyr3maUwahS2rF0E1TiUiv78+Vi/+A6XdHF97YdUWHQEFpSoOg6N779XN90+fVSb7ZdfbvldNDSo4xoa2v7OpITvviP1oX8CEPDuB/Bts7KJigol1/W9x+9XZaUKa8yZA9vUd8qTT6qau4svVnPq10+Fap9+uqmTdkqKarPQDG0dy505uGGDegi44w7VXvx//2v7cwCUl6uC9eeeU8Zu4ULlFU+YoObqcCj5sVtvVfN46SXVJNVuV/83RUVqQfztt9W1J05U3Q8efLDpGlVV6v/e8yHC6YQVK5QOZ0yM+h04xfGvabXDlswqvo48D0PfUj7JDKa0tpSssiz+c8l/ALjvu/sothXz+eWft9rp1hpo5ZW5r/DY/x7jkRmP4HCq0E9GXgZT+qhmjPYGO1/u/ZLLhl/WZsfcKb2nEBYYxrLdyyixldA3rC/DY4YzNHooX2V9xYzk1tuMJIYmIhBenpaWhDEkSnlnvozW4q8XYw2w8tO1LW8Inuj1ZhITbyYu7jry8v7JoUN/Y8uW2VitU0lOfhyrtROhoE7g6WlZA6zulh7t0ZXMvdZap0RaItlauBVoKvLVsjV3l+xm/gfzCdAHYNQbKa0tZWLiRH51221kP/ogZzY3mr/+tbqZrl7dFFb0KAQMymwKCYYLS5NKs8FA3NVzgGXk/fVOeOBDbOt/wmJFPdkHBzN+7yHiz9bxyYQQIgICmdinv0o+GT9eGcyPP1Y328WLYcsWVYS9dSs8/LBKVMnNhcsuU6Gu886Dd99ViSpZWeqGO2iQuimvWgWPPw7bttEnIpy5fZKYnGNTHmZamjLSlZUq5Olyqfdr1ihD/cgj6iZvtSrP87//VWoo8+er691/v6q5W7lS1d2ZzcqYffedMmAbNijZr0YGRQ7i9KTTOXfQuUp37aqrlAF4801lNM48U51/8CDk5akHhYUL1Rjvv68+17p1ap4aZrMyVikpyhO+9VZl6PfuVaUWs2apuXiydKn6PJs2qXXNd95R109JUQ345s5VRnriRLWvshJ+/3vVky48XD14zJrV8d/VkxUp5Qn1slgs8mgy+o47JEuQyzaslVJK+fCahyVLkJ/v/lxm5GZI3YM6ueizRZ0eN+6JOHnlf650v/9q71eSJcjlmcvbPffyjy+XkX+LlIEPBcqbPr+pU9dN+HuCvOqTq9zvt+RvkSxBvr/tfal/UC/v+eYer+NdLpe0LLXIiL9FdOo6UkrpdNplTs4L8scfY+WqVcht2y6U1dU7Oz1Oe7y5+U3JEuTu4t3yso8ukwOeGdCh8x794VHJEmRlXeURz+HCDy6ULEGyBFnjqJFSSrnos0Uy7NEwOfONmTL0kVCZV5Un7Q12GfpIqPz9p7+XpbZSyRLkE/97olPXun759e5rFRUekHLrVilzc6W0291jPvnTk1LabHL602Pl5BfSWh+ssFDK6Gi1+hIYKOXSpVLW1qp9DQ1S3nab2hcQIOWcOerYoCApr7tOSiGknDxZysWLpTQatRWcptfw4VK+9pqUNpsar7ZWykcflXLaNClnzZLy17+W8v77pfz8cymTk6VMTJQyI0Nd64orpPzgAzVOnz5SGgxSZma2nH92tpQVFernZcvU8Q891LTf5Wr6ed8+NfcpU6QsLlbbSkulnDdPypgYKadOVZ/RYFCfTfscqalS3neflGvWSFlQIGVlpfpuNO68Ux1nNKqxOordrr6LgAApo6KkDAuT8i9/kdJqlTIkRM0jOlrKN99Uxx4hQI08Du7hR/rye1pt8P2O7WwKfIqUmmuZO0Z5CYsnL+b1za9z0xc3EWWJIsoSxUNnPdTpsVPjU72SMZZnLsdsMDO93/Q2zlLMHTSXd7a+A+Clqt0RmtdqaZ5WtCWa6KDoFp5WSW0JtnobtnobJbaSFmt2baHTmUhIuJ7Y2Cs4dOgJcnL+TlHRf+jV62p6915MUNDQ9gfpAJqnFWwK7lx4sCKb8MDwbpHq0Wq1rAFW9xpSkjWJ8rpyVu5byTOzn6FXsEovnz1gNiv2rGDhuIXquM54euC1RhUWmQDRTX/GYdJIoCFQ1WqZzdiCAwg2Bbc+WHQ0vPWWClvdf7/y7DT0evj731W48MMPlcfTty+88Yby/mbMUFJZa9cqD+K++5SnkpGhpGLOPtvbMw0MhLvuUq/mfPCB8rImT1bnPPywWje8+GK1b9Ein2FZ+vRp+nnuXLjoIuU5HjigPK/6ejXfadOUR6rTKS8msvH3ODwcPv3Ue8zcXHjtNfXzJZeo8oi2ePhh5T2tWaPCmB3FZFJe3OTJyotbsUJ5XVdeqby03r2VhxnZ8b+5U4EeM1pCiH8BvwIKpZTDfey3Am8BfRrn8YSU8rWemk9nkVJy1Xs3giOEN65qivmb9Caem/McM96cQVZZFq+f/7pbzLQzpMWl8dnuz6h2VBNkDGLZ7mXMSJ7RIYWC2QNmu8VPpyVN69R1k6xJrM1Z637v2cspJiiGQpu30fI0cJklmUy2TO7U9QAMhmD69VtCQsJCsrMfJjf3BfLz/0Vo6BTi468jOvoi9PquKzO417Q6mYjRmuZfV9CknDxLFbSxR/ca7S5RAPXQ8cH2D/hox0fquE6K9WqiuSGmkBbrl5oqRm61KjC21dvaLGEAVMiprbDTpEnq1fyGfNFF6iYrhFr/ArXWNLnzvyOkpqrxb7xRqZloiS7PP68M5M03d2ycf/xDGav331dhv927lXH91a9UyPLVV70NnS/i49UcOoperwxOQYFa5+oMkZHK4BkMTZ1j+/ZVKtx+fNKTnta/gWeBN1rZvwjYIaWcK4SIBjKFEG9LKX3k+h59DpTkc1C/mhGVjzB+eJTXvunJ07lp/E3kVedx5cgruzR+anwqEsnGvI1kV2RzsOIgS89a2qFzwwLDuGLkFYQHhnc6hTfJmsSHOz50FxF7tnrXWqx74rn+lVmcyeTeXbghNWIyxTBw4NMkJd1Dfv4b5OW9wq5dv2Xv3puJjb2SPn3uJiCg83Ij1Y5qBMLd6LCuoQ6H09Hud3O48jB9rO3cwDqI5ml5Gq1x8ePoF9aPF8990cu4zBk4B73Qu4vIu+pptaZWnmRNYm+p0lSsqffOHux2Ro7svrEWLlTGK82jbi4y0jtZoT3i4lRXgMBAZQQqK9Ua1qefqoLw3/2u++bridHYeYOlYe5ZKa2TjR7LHpRSrgFK2zoECBGqGjW48dh20pGOHj9uPQDAOam+O7c+c84zfHjRh10uptVqqb7b/x23f3074xPGc/mIyzt8/mvnvcaTZ3ciFNFIUliSVwsNt6dljiQ2KLal0Wr0tATC3Y/oSDGZYujT53bGj9/F6NGriYiYQ27ui/zySwqHDj3ZaXmoKnsVwaZghBDuRoeeTSFbo6CmgNigtgt5O4oWNvU0Wv3C+7Hv5n1MSJzgdWyEOYIpfaZQZCvCbDATbYnu1LXcRivQt9EaGzeWzfmbqXfWY6u3uXUHj3uEUEkIhiN8lg4JafJaQkNVCO6TT1QI9BgUv59ICCFmCyEyhRB7hRB/8rH/NiHEDiHEFiHEt0KIJI99vxVC7Gl8+Zbl6QaOZcr7s8AQIBfYCtwspez5SscOkr5X3azHp3RP+Kg5cSFxJIQksPSHpRTWFPL8nOfbzBrsLprXapXUlhBkDCLAENCqpxVkDFLN9Bo7wHYXQgjCwk5n6NC3GTduB1braWRlLeaXXwZx8OAT1NeXdWicKkeVe12qeXfe1nBJF0U1Re2HzjqIr/BgW8wbpNYi+1j7dPrBRzNCzQuLNVLjUrE77Wwv2t6iuPiURKeD888/floxHKcIIfTAc8A5wFDgMiFE84XnjUCalHIk8BHwWOO5EcADwARgPPCAEKJHvvBjabTOBjYB8cBo4FkhhM82ikKI64QQ6UKI9Ib2akO6iR256qZ+2vCeMVqgQoT1rnquT7u+zdqs7qR5rVZJbYn7hhsTFEO1o9otsgpN6z4pkUdmtPaX7eeH7B9a3W+xDGDEiBWMGLGCgIA+7Nt3B2vXJpCZuYCqqra7dlc5qggxtW20thVu45fDTW1HymrLcEpntxktLTyodQ9uj7kpqoC8K2tq7YUHtWLe9Nx0v9Hy0xnGA3ullPsal2neA87zPEBKuUpKqd0gfga0mOjZwEopZamUsgxYCXS89XUnOJZG6xrgP43ZmHuB/cBgXwdKKV+WUqZJKdMMRxo66CAHyrLR2cOJCeu5JnDnDjyX5PDkDq9ldQd9w/qiEzp3qK/YVuwObWk38KKaJrWB7HLVVXdQpOoA63R1rRnkX9f8lQs+uKDNY5TCxrmMGfM9aWmbiIm5nIKCt8nIGEN6ehoHDz5OXV1LBYMqe/ue1tX/vZrfL/u9+73mUXaX0RoQMYC44DjGJ4zv0PFa7dBpfTqvvddeeLB/RH+sAVbW5azD4XS4Ezf8nPIYtIf/xlezQjISAE+Nt5zGba1xLaApcHf23C5zLFPeDwLTgR+EELFACnDcNGoqtGcTZOo5LwvgutTrWDB2wVEVmbUYLQyOGuxOty+xlbi9BO0GXlhT6KVSPiFhAimRKTicDrIrsrskOppXnUexrdjLwLRFcPAoBg9+lf79Hyc//98UFr7Dvn13sm/fnYSFnUFs7G+Jjp6PwRDSrqd1uPIwGXkZXjf57jZakZZIchfntn+gB6uvXt2la2lGqDWjpRM6xsaNZc1BpXXn97T8NNIgpfStpq3wdSPyKWcjhLgCSANO7+y5R0qPeVpCiHeBtUCKECJHCHGtEOJ6IcT1jYf8FZgshNgKfAvcJaUs7qn5dAaXC6r02cT0sNECjokqelp8Ghl5GUgpW4QHQSUogMrKK60tVeHBRimczOKuhQg1I3GwonNab0ZjOL1730pq6nomTNhL375/xW7PITPzGn76KY6dO6+m3JbvNoTWAKVo7Gm0VuxW7WLK6sqora/1mk9bbUOOVzQj1NqaFqj/Y82b9hstPx0kB+jt8T4RlXPghRBiBvBnYJ6U0t6Zc7uDnswevExKGSelNEopE6WU/5RSviilfLFxf66UcpaUcoSUcriU8q2emktnOXhQIkOzO10/c6KQGpdKfnU+uVW5Kjzow9OCJgOjhQeBFutaNY4aVmatbPea2pjttaDfWbSTrNIsn/vM5v707Xsv48fvZsyYH4mNvZzi4k8ord5LQ80vVFau9+lpLdu9zP2z1tW3uz2to0l7a1qAV3sav9Hy00HWAwOFEP2EECbgUmCZ5wFCiDHASyiD5Zm19RUwSwgR3piAMatxW7fjF8z1Qfr2MgioZnDcyWm0tBvausPrKK8rb7Gm5TYw5U3afNGWaMICw1qkvT/2v8eY9dasNvX+pJQtxmyNaz69hj9++cc2jxFCYLVOISXlZSZPzsNOMCZZzoYN49m3U60bl9So8HqNo4Zv933r1lbMq2oyWgLhNtgnEomhiQSbghke06Jm341ne5oTJuXdzzFFStkA3IgyNjuBD6SU24UQfxFCaNI7j6NKlD4UQmwSQixrPLcUFT1b3/j6S+O2bscv4+SDdbvUjTW1/8lptEb3Go1O6NwekhYetBgtBJuCW3hFSdYk1QHWRwbhp5lKAmd/2X63TFFzKu2VbpHg9jytvOo86jtRp6XXW6hpaCC593UkJydQUPAuOmDXvofZHrWHzfax2J12/pD6B2756hZ3fVphTSFRliifXZqPd6IsUVTd3XYdWnJ4MmGBYZTXlfs9LT8dRkr5OfB5s233e/zcqiK3lPJfwL96bnYKv6flg62H1I11RJ+T02hZjBaGRg/ly6wvAby8Dc9arezybIw6I3EhKo07JSrFa03rYMVBNhdsVse2YYy0NbL2jgOVzagVPHeEBlcDdQ11WAMj6dPnTsaN20hoQCg68xhKS7/irfV/ItggGG1UvZkOVWS553QihgY7ihDC7VH7jZafkwm/0fLB3mJ1Y+3bTbp0xyNp8WkcKD8A4CWC62W0KrLpbe3tLnoeFDGIw1WHqXZUA0rkV8Mz7Fdpr2Rz/mb3e208g87QZniwrqHOLczrya7iXa02p9TmomUPAoQGhkHgCCZMPMj6ilCmxSVhtG/GKCA981527PgNuRV7TmqjBU0hQn/Ku5+TCb/R8kGeLRu9y+wOm52MpMU1LdR7fs5+Yf1Iz02nxFaiCos9klFG9RoFwH93/RdQTSsHRgwkPDDcy4N67H+PMemfk6h3qjCfZnCGxwxv09PSjFVNfQ11DXXu7ee+cy63fnWrz3M8e2lpaKK5n2R+QXFtJVeNf5RJk7KJC4mjRtef0tLPOVy+DX3derKy7qKg4D1qa30nf5zIzEiegVFn7LBKhx8/JwJ+o9WMsjKwGbOJ1Ccdk3T0o4WnAodnePDuqXdTaa/knm/vUYXFHt7mnIFzGJ8wntu/vp2cyhxWHVjFvJR5qt2JhzHaWriV2oZaDlcdBpqM1vj48eRV5bnXt5rjGRbUDJiUkkMVh1iXs87nOZ5dizVCA0I5XHWY276+jbFxY7lw6IUIIUgI7Uu1SGTSpFwqnRaizFZycp5i587LWLduABs3nk5h4Ue4XMeNBOYRMSN5BqV3lfqNlp+TCr/RakZmJhCWTULIyRsaBBgVOwq9UEkInuHBEbEj+OOEP/LKhlc4XHXYy9PSCR3PzXmOwppCznn7HBxOB3MHzSXJ6t2jS1v30rZpRistPg2JMkK+0Hp7ef5cYa+g3lVPVlkWZbUttQhb87R+OfwLeVV5PD/neXeyRXxIPHlVeTRIHZUOG8P73sBpp1WTmrqB5OTHsNsPsmPHRaxdG0dm5vWUlX2HlF1TADleaLOXlh8/JyB+o9WMXbsAazaDYk5uo2U2mhkWM4wAfUCLlOglZyxxZwI2r1VLi0/j+rTr2Va4jfDAcKb0maKMVkU2UkrqncrAQFPSRWFNIRHmCPpH9Pfa3hzPtSzN6yqobkri8GyaqdGapwXw+7G/91JYjw+JJ7cqlyKbkqmKCYpBpzMREjKGPn3uYMKEvQwfvozw8JkUFLzF5s3TWbs2kT17bqGmZpfvL9KPHz9HFb/RasamHTUQVMzwxJPbaAGckXQG/SP6twiDhgaE8vTspwEYFjOsxXlLz1pKbFAs5w8+H4POQFJYEtWOasrqyjhQfoCGxvCap6cVExTTpDDfSjKGr/CgZwJGRq4Po+XD0+od2ptoSzSPTH/E69i44Dgq7BXsL9sPtCwsFkJPVNRchg59hylTChk69ANCQyeRm/sC69cPY+fOKykt/YqcnP9j9+6FFBa+f8J7Yn78nGj467SakbHnIIyGfuEnv9H628y/uWWNmnPxsIuZ2meqz/WQcHM42xdu92orD8oYaetY4O1pxQTF0NvaG4Fo3dPyER7UjJZe6EnPS29xji9Pa+lZS7nntHtayBxpn0VL028re1CvtxATcxExMRfhcBRx6NDjHD78LAUFSrhFpzOTm/sCZvMAEhNvIybmEozG1mWV/Pjx0z34jVYzduZlw+iutYw40Qg0BBJoCGx1f1sL+J7rYJ7iupoE08CIgW7jVFBTwPCY4Zj0JuJC4toMDwYaAqlrqHN7XZrRmtR7Uoc9rQBDAAGGgFY/z8a8jUDHJZxMpmj693+M3r0XU129maCg4ZhMsRQVfcLBg4+wZ89C9u69mYiI2URFnU9ExDld6sDsx4+f9jmljVb6BqNoAAAcjUlEQVS9s5703HR3OKuqCkpCVgEt13L8tI6np5VZkkmUJYrRvUazKV/1wSqsKSTGEuM+ttXwYG0xvYJ7UWIraREenN1/Nveuulep0lsiOVx5mH1l+9hWuA3oWMKBZrQ2Fah5dbZOy2SKJSJilvt9TMyFREfPp7p6E4WF71BY+B4lJap2LSRkPLGxlxMdfQkBAb6VQvz48dN5Tmmj9dz651rW/0wFsy7YnybcCaIsUZgNZg5WHGR3yW5SIlNIsiaxLHMZDqeD0tpSt4FICkvyasboiWeblOLaJk8rwhzBpN6TAJWMMTBiICNeGEFNfQ2gQoNmg7ndeWr/p9sLtxNoCOyWzDohBCEhYwgJGUNy8mPU1GyhpOQzioo+ZO/eW9i791aCg0dhtU4jLOxMwsPPxGCwHvF1/fg5VTkpjFZ9fT05OTnU1dW1f7AHo/Sj+Oacb9xrHzab8rZiY/TsztzdztknB4GBgSQmJmI0Grs8hhDCXauVWZLJOQPOISksSbV8L9wONLUASbIm8fGOj3FJl1tpQ6OktsQddnR7Wja1HjY2biygkjGe/eVZAJZfthyzwazWyjpQUxcWGEaAPgC7096lNvftIYQgOHgUwcGjSEq6h5qaHRQVfUx5+ffk5b3C4cPPAHpCQ8cTEpJGcPBowsNnEBjYp1vn4cfPycxJYbRycnIICQmhb9++Hb4RNTgbqCmoIS44joRQ1WAzOxtKTTB6BJzEdcVupJSUlJSQk5NDv379jmisJGsSWwu3kl+d7/a0ANbnrgeaQnFJ1iTqXfXkVeW5v3eNYlsxAyIGIBBeiRixQbGEBYYxIGIAz6c/T05lDo/PfJxfDfpVp+YohCA+JJ795fuPioRTUNBQgoKGAvfhcjmorPyZ0tKvKS9fTX7+azid1YAgPHwmvXpdTUTE2f5kDj9+2uGkMFp1dXWdMligilZBPX1r2GxgNp8aBgu09vaRFBUVHfFYSdYkvspS7XNSolLcyRnrDzczWh5JG82Nlmd4cE/pHkAZrRExIwClpff+9vcZGj2Umyfc3KV5akYrNujoNn/U6UyEhU0jLGwaAFK6sNkyKSx8j/z819i583JAR0hIGiEh47BYBhMUNJyQkDQMBn+BsB8/GieF0YLOdwAuryvHqDO607alhNpaiDp55QZ90l0hMs9sy0GRg0gIUQapuafVP1wVGP948Ecm957sPqfeWU+FvYIoS5TytBrDgwXVBUzvNx2ASYmTeH/7+zw35zmM+q6FM7V1rWMtliuEjqCgIfTr9yB9+97f6IWtpKzsGwoK3sDp1FqP6AgOHkV09Hx69fqdPyvRzynPKVlc7JIuKuwVWAOt7pu2wwEul/K0Okt5eTnPP/98l+YyZ84cysvLu3Tu8YQWDtQJHf3D+2MNtGINsLqz+zQjMShyEGf3P5uH1jzkbsgIUFqr+sVFmiOJtERSYa/AVm+jrK7Mfe4f0v7Ahus2cEbfM7o8z+PFaHkihB6rdQr9+i1h7NgfmTq1gkmTDjNixOckJf0ZvT6I/fvv5eef+7Blyzns37+E4uIV2O2tN97046crCCFmCyEyhRB7hRB/8rF/mhBigxCiQQhxYbN9jwkhtgshdgohnhE9JN560nhanaHaXo1LurxCg7WNNbZHYrQWLlzYYp/T6USvb73R4Oeff97qvhMJzdPqF9bPXSOVFJbEloItGHVGrAEqY04Iwf+d838Mf2E4t6+8nbcveBtoKib2rP/SNAw1AxNoCGRM3JgjmufxaLSaI4QgICCegIB4IiPPAcBm201e3iuUlHxOaenXgAuAgIDehISkEhQ0nKCgkUREnI3BEHoMZ+/nREUIoQeeA2YCOcB6IcQyKeUOj8MOAlcDtzc7dzIwBRjZuOlH4HRgdXfP85T0tMrt5eiEjlBT0x/3kRitP/3pT2RlZTF69GjuuOMOVq9ezZlnnsnll1/OiBFqPeb8888nNTWVYcOG8fLLL7vP7du3L8XFxRw4cIAhQ4awYMEChg0bxqxZs6itbalWsXz5ciZMmMCYMWOYMWMGBQVKm6+6upprrrmGESNGMHLkSD7++GMAvvzyS8aOHcuoUaOYPn165z9cB9E8rUGRg1psiwmK8QpDDowcyF1T7uKdre+war+qi9PCgVGWKHerlJ3FO93ndxdxwXHdPubRwGIZRP/+jzN+/HamTq1g9Ogf6N//SUJDJ2Oz7SI7+xF27LiYn36KZfv2SyksfJ+6uoNIKY/11P2cOIwH9kop90kpHcB7wHmeB0gpD0gpt6A9NXnsAgIBExAAGIECeoCTztO65RbYtKntY2rqI9ERhdnYZLPr6sDphCAf/fJGj4ann259vEcffZRt27axqfHCq1ev5pdffmHbtm3urLx//etfREREUFtby7hx45g/fz6RkZFe4+zZs4d3332XV155hYsvvpiPP/6YK664wuuYqVOn8vPPPyOE4NVXX+Wxxx7j73//O3/961+xWq1s3boVgLKyMoqKiliwYAFr1qyhX79+lJaWtv3FHAHxIfFYjBaGxwx3b/M0Ws25e+rdvLnlTe5bdR8/9vvRrYDh2SZlZ1H3G62+YX0BSAxN7LYxjzYGQzBhYVMJC5vq3uZ01lFdnUFBgSpyLip6HwCTKY7g4FEEBY3AYhmM2dwfi2UwJtPRTUTxc0KQAHi2YMgBJrRyrBdSyrVCiFVAHiCAZ6WUO7t/iieh0WofiUu6MOhNXludTtB1o985fvx4rzTyZ555hk8++QSAQ4cOsWfPnhZGq1+/fowePRqA1NRUDhw40GLcnJwcLrnkEvLy8nA4HO5rfPPNN7z33nvu48LDw1m+fDnTpk1zHxMR0XPp1HqdnjVXr6FfeNNn1kKGWo2WJ2ajmYuGXsQ/1v0Dh9PhMzy4o1hFJboz029qn6l8e9W3nJ50ereNeTyg1wditU7Bap3CgAFPU1OzhcrKn6ms/IWami2NbVaa+piFhKQRFXU+UVHnY7EMPal7x/lxYxBCeAp4viylfNnjva9fgg656kKIAcAQQHsaXCmEmCalXNO1qbbOSWe02vKIABwN9WwpzCTJmkR0UDQA9fWweTPExUFCQtvnd5QgD5dt9erVfPPNN6xduxaLxcIZZ5zhsxA6IKBJL0+v1/sMD950003cdtttzJs3j9WrV7NkyRJA1Vw1v/H42taTeDaWhLY9LVBtThxOB9sKt3mFB0Xj305PeFpCCM7qd1a3jXc8otMZCQlJJSQklYSERQC4XA3Y7Qeprc2iqiqd4uJP2b//XvbvvxezeSAREedgNg8gMDAJkykWgyGSgIAE9PouxMv9HK80SCnT2tifA/T2eJ8I5HZw7F8DP0spqwGEEF8AEwG/0TpS7E47ACYPT6ussbdgeHjXxgwJCaGqqqrV/RUVFYSHh2OxWNi1axc///xz1y7UOFZCo2V9/fXX3dtnzZrFs88+y9ONVrusrIxJkyaxaNEi9u/f7w4P9qS31RzN09J0B5uTGqeMXHpuOsW2YgINgaoEQVUhsKd0Dya9yd0fy0/X0ekMmM3JmM3JRETMJCnpbuz2wxQXf0px8Sfk5b2Cy1Xb7JwgYmOvID7+eoKDR/m9sZOf9cBAIUQ/4DBwKXB5B889CCwQQjyC8thOB9pxIbpGjyViCCH+JYQoFEJsa2X/HUKITY2vbUIIpxCix++oWqt3T6NVWqoSMCyWro0ZGRnJlClTGD58OHfccUeL/bNnz6ahoYGRI0dy3333MXHixK5dCFiyZAkXXXQRp512GlEeRWX33nsvZWVlDB8+nFGjRrFq1Sqio6N5+eWXueCCCxg1ahSXXHJJl6/bFfqFqVBhazqOyeHJhAWGkZGboSScGtezLEYLgYZAGlwNLZI4/HQfAQEJJCQsZNSolZx2Wg2TJxcwduw6RoxYweDBrxMTczEFBa+TkTGGn36KYfPm2Rw8+DccjsL2B/dzwiGlbABuBL4CdgIfSCm3CyH+IoSYByCEGCeEyAEuAl4SQmxvPP0jIAvYCmwGNkspl/fEPEVPZRcJIaYB1cAbUsrh7Rw7F7hVStlu3CYoKEjW1NR4bdu5cydDhgzp0LzyqvI4XHWYMb3GoNfpsdth61YVFow7Res2O/P9dZaVWSsZnzAea6BvkdiZb86ktLaUxNBEssuz2XS9Smbp/VRvcipzGBs3lozrWrYk8XN0qK8vo6joQyor11FVlU5NzRaEMBIRMRuns4ba2j3o9aGEhZ1BePiZhIZOIiDALzZ9PCKEsEkpfaSanVj0WHhQSrlGCNG3g4dfBrzbU3PxxOF0YNAZ0OtU7ZSWUHcUo2anFDP7z2xzf2pcKk+ufRKB8ErCiDRHklOZc8Klpp9sGI3hxMdfR3z8dQDU1OwiN/dFSkqWYTTGEBZ2Og5HEfn5r5Gb+xwAAQGJBAWNxGweQFDQcKKjL8Ro7GLs3Y+fZhzzNS0hhAWYjXJLexy7094iNBgcDAEtewb6OQqkxadR76pnY/5G5g+Z796uGbCjrRHop22CggYzcODTDBzovVzhcjmoqtpAVdU6KivXYbPtpKJiDU5nNXv3/pHo6IuxWqdiMvUiICAes3mAv0WLny5xzI0WMBf4n5Sy1SIiIcR1wHUAJpOptcM6hMPpcHfrtdlUUXEff2eIY0ZavEpmckmXu6gYcP/s97RODHQ6E1brRKzWpvVaKSXV1ZvJy3uZgoK3KCh4w+scozGGiIjZxMZeQVjY6TQ0VOJ0VhMY2BslzuDHT0uOB6N1Ke2EBhtrCV4GtabV1QtJKXE4HW5JoSPNGvRz5CRZk4gwR1BaW+pVWKz97DdaJy6qQeZoQkKeZ8CAf+BwFOBw5GO3H6K2dg81NdsoLv60hTHT60OxWqcQEpJKQEASZnM/QkIm+NXu/QDH2GgJIayo1Mgr2ju2O2hwNeCSLnd4sLJSKWAcQf9DP0eIEIK0+DS+zvra72mdxOh0RgIDEwkMTASaSoWczjpKSpZjs+3EYAhDpzNTXb2B8vLvKS39Ck0tSAgDoaGTCQ2diNk8ALN5IEFBwzCZoo/NB/JzzOgxoyWEeBc4A4hqTJF8AKVHhZTyxcbDfg18LaWs8TlIN+OZ7l5fDzU1EO9PdDrmpMal8nXW1y0SMcBvtE529PpAYmIu8rnP5arH4cjFZttNefl3lJauJCfnaS9lD6MxttFw6TEao4iPX0BU1Hx0uuMhiOSnJ+jJ7MHLOnDMv4F/99QcmqMZrQB9AJWVapv1GK0FBwcHU11dfWwufpyhrWt5elqaWok/EePURXlnSQQGJhERMZPk5EeQ0ondnoPNlklNzXZqarbR0FCOlE5stu3s2HEpgYF9CQ4eixA6DIYIIiJmER4+069+f5JwSj2OuNUwDCYKKsFg6HpBsZ/u41eDfsXTZz/tJa80L2Uez57zLKN6jTqGM/NzvCGE3sOQzfLaJ6WLkpLlHD78LLW1u5HShd1+mLy8lxHCgMkUj8kUi8kUR2BgP8zmflit0xrVPk7JhhcnJKeU0XI4HeiEDr3QU1EBoaHQHWILd911F0lJSe5+WkuWLCEkJIQ//OEPnHfeeZSVlVFfX89DDz3Eeeed1+ZY559/PocOHaKuro6bb76Z665T9TFffvkl99xzD06nk6ioKL799luqq6u56aabSE9PRwjBAw88wPz589sc/3jEpDdx88SbvbYFm4JZNH7RMZqRnxMRIXRERZ1HVFTT35jL1UBl5U+Ula2kru4gDkcBdXX7KCv7FpdLrUoYjbEEB49GpzMiRAAmUwwmUxx6vUr80OstREX9GpPJH6o+HugxRYyeoj1FjFu+vIVN+b57k9Q21OKSLgJ1QdhsEBjYsSSM0b1G8/Ts1mW0Nm7cyC233ML3338PwNChQ/nyyy+Jj4/HZrMRGhpKcXExEydOZM+ePQghWg0PavqAWguT77//HpfLxdixY71ajERERHDXXXdht9u99AbDu5AK2ZOKGH78HI9IKXE48igr+4bS0i+orc1CygZcrjocjgIaGrwrcIQwEh09n/DwswkISCAgoDdm84ATau3Mr4hxAiKlRIcOp1O9N3TTpx8zZgyFhYXk5uZSVFREeHg4ffr0ob6+nnvuuYc1a9ag0+k4fPgwBQUF9OrVq9WxfLUwKSoq8tlixFc7Ej9+/LSP1h26V6+r6NXrqhb7XS47LpfqxGC355Cb+wr5+f+msPA9jzFMBAUNJShoBEFBw7FYhhIQkEhAQCJGY6RfM7OHOOmMVpseUd5GwgMjqMlNQggYOrT7rnvhhRfy0UcfkZ+fz6WXXgrA22+/TVFRERkZGRiNRvr27euzJYlGay1MWmsxcrRbj/jxc6qg0wWg0ymZHIPBysCBT9O//2PY7TnY7YepqztATc1Wamq2Ulb2HQUFbzY730xAQB/M5mSCgoZhsQxr/HcwBkPIsfhIJw0nndFqDafLiVM6KSs24awFj/6M3cKll17KggULKC4udocJKyoqiImJwWg0smrVKrKzs9sco7UWJq21GPHVjsTvbfnx0zPodCZ3exc4zWtffX0pNttuHI7D2O051NUdwm7Pxmbb09iA0+4+1mSKb0wm6UdQ0AhCQsY0emnxfiWQDnDKGK2iUpXuLlwmBg9WeoPdybBhw6iqqiIhIYG4Rrn43/zmN8ydO5e0tDRGjx7N4MGD2xxj9uzZvPjii4wcOZKUlBR3CxPPFiMul4uYmBhWrlzJvffey6JFixg+fDh6vZ4HHniACy64oHs/mB8/ftrFaIzwkrDyxOVqoK5uHzU1O7DZtlNbm0VdXTYVFf+jsPAd93FCGAkI6ENgYO/GMGMSgYF9MZv7ExQ0ApMpyuf4pxonXSJGa5TUlLO/Yi+DIgYTGuiXg/HEn4jhx8+xob6+nOrqTdTW7qaubj91dQc8PLUcwOk+1mSKo3fvxfTuvbhL1/InYpxgBBgMhAWGYTb65dz9+PFzfGA0hhEefgbh4We02OdyNWC35zTqNG6lunoLJlPPSvgIIWYD/wD0wKtSykeb7Z+G6kg8ErhUSvmRx74+wKtAb0ACc6SUB7p7jqeM0QoOCGZAwIBjPQ0/fvz46RA6nQGzuS9mc18iItruS9cdCLWg9hwwE8gB1gshlkkpd3gcdhC4GrjdxxBvAEullCuFEMFowpHdzCljtPz48ePHT5uMB/ZK+f/t3W2MXFUdx/HvT7d2W6q2NWC0a2yrVXmItBWSKmoImEiRtLyAUKnYKAlvMILRCE01Rt4ZfE4QqqIUaQDBgg2JSl1JDS/a0pbaB0qlggmL1W5WWsUHoPXvi3OmHbb7MH3YvffM/D7JZGfu3Dv5/++ZO/+9586cE88CSLoPWAwcKVqNMydJrylIks4CuiJiXV5vzMaoa5uxS0q7NlcX3m9mls0Anm963JeXteI9wAFJayQ9KelWjdFXIduiaHV3dzMwMOAP4OMUEQwMDNDd3V11KGY29rokbW66XTfo+aF+9Nnqh2oX6XcAXwLOB2aTuhFPubboHuzp6aGvr4/+/v6qQylOd3c3PT09VYdhZmPvUEScN8LzfaQvUTT0AH9p8bX7gCebuhYfBhYAd55IoCNpi6I1YcKEI0McmZnZCXkCmCNpFvACaVb5q49j22mSTo+IfuAiYPNYBNkW3YNmZnZyIuIQ8DngN8Bu4OcRsUvSLZIWAUg6P0/qeyWwUtKuvO1hUtdgr6QdpK7GH41FnG3x42IzMxtZu/y42GdaZmZWjOLOtPLvA/5zgpt3AYdOYThVaYc8nEM9OId6GI8cJkVE8ScqxRWtkyFp8yjfnilCO+ThHOrBOdRDO+QwXoqvumZm1jlctMzMrBidVrR+WHUAp0g75OEc6sE51EM75DAuOuqalpmZla3TzrTMzKxgHVO0JF0iaY+kvZJurjqeVkh6h6THJO2WtEvSDXn5dEnrJD2T/06rOtbRSHp9Hv35kfx4lqSNOYf7Jb2h6hhHImmqpAclPZ3b44OltYOkL+T30U5J90rqLqEdJP1E0n5JO5uWDbnvlXw/H+fbJc2vLvKjhsnh1vx+2i7pIUlTm55bnnPYI+nj1URdTx1RtJomN1sInAV8Ms//UneHgC9GxJmkwSevz3HfDPRGxBygNz+uuxtIQ8M0fAP4Ts7hReDaSqJq3feAX0fE+4BzSbkU0w6SZgCfB86LiHNIM9MuoYx2uAu4ZNCy4fb9QmBOvl0H3D5OMY7mLo7NYR1wTkS8H/gjsByOzE21BDg7b/ODsZrmo0QdUbRomtwsIl4BGpOb1VpE7IuIrfn+P0kflDNIsa/Kq60CLq8mwtZI6gE+QZqKG0kiDajZmKq71jlIehPwUfKI1RHxSkQcoLB2IP2AdZKkLmAysI8C2iEifg/8fdDi4fb9YuDuSDYAUyW9bXwiHd5QOUTEo3m8P4ANpFHVIeVwX0S8HBHPAXtJn2FG5xStk5ncrBYkzQTmARuBt0bEPkiFDTijusha8l3gyxydfvstwIGmA7bu7TEb6Ad+mrs4fyzpNApqh4h4Afgmabr0fcBBYAtltUOz4fZ9qcf6Z4Ff5ful5jAuOqVonczkZpWTNAX4BXBjRPyj6niOh6TLgP0RsaV58RCr1rk9uoD5wO0RMQ/4FzXuChxKvuazGJgFvB04jdSVNlid26EVpb23kLSCdClgdWPREKvVOofx1ClF62QmN6uUpAmkgrU6ItbkxX9rdHnkv/uriq8FFwCLJP2Z1C17EenMa2rupoL6t0cf0BcRG/PjB0lFrKR2+BjwXET0R8SrwBrgQ5TVDs2G2/dFHeuSlgGXAUvj6O+PisphvHVK0ToyuVn+dtQSYG3FMY0qX/u5E9gdEd9uemotsCzfXwb8crxja1VELI+InoiYSdrvv4uIpcBjwBV5tbrn8FfgeUnvzYsuBp6ioHYgdQsukDQ5v68aORTTDoMMt+/XAp/O3yJcABxsdCPWjaRLgJuARRHx76an1gJLJE1UmpBxDrCpihhrKSI64gZcSvqGzp+AFVXH02LMHyZ1C2wHtuXbpaRrQr3AM/nv9KpjbTGfC4FH8v3ZpANxL/AAMLHq+EaJfS5pJtbtwMPAtNLaAfg68DSwE/gZMLGEdgDuJV2He5V0FnLtcPue1LV2Wz7Od5C+LVnXHPaSrl01ju07mtZfkXPYAyysOv463TwihpmZFaNTugfNzKwNuGiZmVkxXLTMzKwYLlpmZlYMFy0zMyuGi5bZOJJ0YWOkezM7fi5aZmZWDBctsyFI+pSkTZK2SVqZ5wN7SdK3JG2V1Cvp9LzuXEkbmuZFaszt9G5Jv5X0h7zNu/LLT2mam2t1HqHCzFrgomU2iKQzgauACyJiLnAYWEoaZHZrRMwH1gNfy5vcDdwUaV6kHU3LVwO3RcS5pHH+GsMJzQNuJM3tNps0PqOZtaBr9FXMOs7FwAeAJ/JJ0CTSgKz/A+7P69wDrJH0ZmBqRKzPy1cBD0h6IzAjIh4CiIj/AuTX2xQRffnxNmAm8PjYp2VWPhcts2MJWBURy1+zUPrqoPVGGgNtpC6/l5vuH8bHoVnL3D1odqxe4ApJZwBImi7pnaTjpTEi+tXA4xFxEHhR0kfy8muA9ZHmPeuTdHl+jYmSJo9rFmZtyP/hmQ0SEU9J+grwqKTXkUbmvp40+ePZkraQZv69Km+yDLgjF6Vngc/k5dcAKyXdkl/jynFMw6wteZR3sxZJeikiplQdh1knc/egmZkVw2daZmZWDJ9pmZlZMVy0zMysGC5aZmZWDBctMzMrhouWmZkVw0XLzMyK8X8h35+iq2lYfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 25us/step\n",
      "\n",
      "loss : 1.8416430473327636\n",
      "accuray : 0.2717\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
